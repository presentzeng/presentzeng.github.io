[{"title":"《代码整洁之道-Clean Code》读书笔记","url":"/2022/02/27/代码整洁之道/","content":"\n## 整洁代码\n\n《修改代码的艺术》一书作者对整洁代码的描述：我可以列出我留意到的整洁代码的所有特点，但其中有一条是根本性的，整洁的代码总是看起来像某种特别在意他的人写的，几乎没有改进的余地，代码的作者什么都想到了，如果你企图改进它，总会回到原点，赞叹某人留给的代码——全心投入某人留给你的代码。\n\n## 函数\n\n这本书关于函数的介绍和其他架构书差不多，主要就是两个点：1. 短小，2. 抽象层次一致性。\n\n## 注释\n\n毫无疑问，注释是代码中的坏味道。\n\n对于一部分注释，我们可以使用类似 4.4.8 这种变量的方式，通过新增两个变量，来解释我们的内容。\n那种生成的注释和我们注释掉的代码，我的建议是：不要留。\n\n## 格式\n\n相关函数：按照本书的说明，若某个函数调用了另外一个，就应该把它们放到一起，而且调用者应该尽可能放在被调用者上面。我自己之前的习惯是调用者在被调用者的下面，目前又思考了一下，像作者这样组织，可能可读性反而更高。\n\n> 因为这样设计可以像报纸一样，最重要的概念先出现，并且希望以包括最小的细节表述他们，期望底层的细节后出现。\n\n## 错误处理\n\n**使用异常而非返回码**： 在 《代码精进之路》的读书笔记中，也提及了类似的思路，这个书里面又提到了使用异常而非返回码这一点，并且给出了一个新的理由，返回码意味着我们需要立即处理，这个步骤可能很容易被遗忘，而且会让我们的代码变得比较乱。\n\n关于返回 null 值：有的时候，我们在数据处理中出现问题，可能会返回一个 null 或者 undefined。但是我建议相对于此，我们更应该直接抛出异常，返回 null 值意味着依赖调用者来做空检查，而且你不知道这个 null 究竟什么时候才会引发错误，这样会有较高的不稳定性。\n\n## 类的组织\n\n对于类的组织中，属性顺序的一个建议：依次是公共静态常量、私有静态变量、公共函数、私有函数。\n\n**类的权责**：对于一个类来说，我们不希望它被定义的太长，当然这个不能单纯地使用代码行数来判断，我们应该使用类的权责来判断，当一个类的名称越含糊，该类越有可能拥有更多权责，比如它的名称包含了诸如 Processor、Manager 或 Super，那么这种现象往往说明有不恰当的权责聚集的情况出现。\n\n**如何把类拆的短小**：我给出一个切实可行的办法，可以先从类的复杂函数入手，我们在把函数拆分的过程中，发现某些部分拆分成函数之后会传递大量的参数给它，否则很难拆分，那么传递给它这个函数的参数就可以被整合进新的小类的实体变量，这样我们就无需传递参数，同时也完成了拆分。\n\n","tags":["读书笔记"]},{"title":"使用 fst-json 自动生成更快的 json 序列化方法","url":"/2022/02/11/fst-json/","content":"\n> fst-json 的全称是 \"fast-safe-typescript json\"，它的本质就是直接使用你定义好的 Typescript 文件，来生成更加高效的序列化方法。\n> 其目的是利用现有的资源（开发过程编写的 Typescript 文件），在编译和开发阶段尽可能提高运行时性能，同时这个过程并没有额外的开发负担。\n\ngithub: https://github.com/aircloud/fst-json/blob/master/README.zh-cn.md\n\n知乎：https://zhuanlan.zhihu.com/p/466572196\n\n## 背景\n\n由于 JSON schema 这个概念是由 fastify 引入，我们先对此进行介绍。\n\n[fastify](https://github.com/fastify/fastify) 是一个高性能 Node.JS 服务端框架，其特点就是高性能，而之所以高性能主要的原因就是它引入了 JSON schema，通过对参数增加约束，来获得更快的序列化速度。\n\n同时，fastify 也开源了一个独立的 json 序列化库 [fast-json-stringify](https://github.com/fastify/fast-json-stringify)，可以在**非 fastify 的项目中使用**。\n\n在 fastify 中，JSON schema 的大致写法如下：\n\n```\nconst schema = {\n  schema: {\n    response: {\n      200: {\n        type: 'object',\n        properties: {\n          hello: {\n            type: 'string'\n          }\n        }\n      }\n    }\n  }\n}\nfastify\n  .get('/', schema, function (req, reply) {\n    reply\n      .send({ hello: 'world' })\n  })\n```\n\n我们可以看出，这一套写法不仅会带来额外的学习成本，而且由于目前大多数项目开发都是采用 Typescript，这套定义也会和我们的 Typescript 定义有所重复。\n\n事实上，虽然上面的示例代码比较短小，但是在实际的项目中，接口比较多的情况下，这些代码的开发量和额外的学习/维护成本还是不容小视的。\n\n那么有没有可能直接使用 Typescript，而不用重新定义 JSON schema 呢？\n\n答案是有的。\n\n[fst-json](https://github.com/aircloud/fst-json/blob/master/README.zh-cn.md) 就是这样一个工具，它可以通过复用我们在 Typescript 中定义的 schema，通过工具自动生成 fastify 需要的 schema，这样我们就无需额外维护 schema 定义了。\n\n## 使用方式\n\n接下来，我们简单介绍 fst-json 的使用方式，首先安装（全局或者安装到项目中）：\n\n```\nnpm i fst-json -g\n```\n\n假设我们项目采用了 Typescript，事先已经有了 schema 文件：\n\n```\nexport interface HellWorld {\n  attr1: string;\n  attr2: string;\n  attr3?: string;\n}\n```\n\n我们在项目目录下新建 .fstconfig.js，用于声明配置，配置如下：\n\n```\nmodule.exports = {\n  sourceFiles: [\n    './src/schema/*.ts'\n  ],\n  distFile: \"./src/schema-dist.ts\",\n  format: 'fastify'\n}\n```\n\n之后我们运行：\n\n```\nfst-json gen\n```\n\n然后此时会生成一个 `src/schema-dist.ts`，这里会有自动生成的 JSON schema 定义，接下来我们在项目中可以同时使用 JSON schema 定义和我们之前定义好的 Typescript 类型：\n\n```\nimport * as schemas from './schema-dist';\nimport type { HellWorld  } from \"./schema\";\n\nconst schema = {\n  schema: {\n    response: {\n      200: schemas.HellWorldSchema\n    }\n  }\n}\n\nserver\n  .get('/', schema, function (req, reply) {\n    let res: HellWorld = {\n      attr1: 'hello', \n      attr2: 'world', \n      attr3: 'optional'\n    }\n\n    reply\n      .send(res);\n  })\n```\n\n当然，fst-json 不仅仅可以在 fastify 中使用，也可以在任何其他需要 JSON 加速的地方使用，用法也都很简单，可以参考这个 [HelloWorld](https://github.com/aircloud/fst-json/tree/master/examples/helloworld)\n\n## 原理和优势\n\nfst-json，实际上是通过对 Typescript 进行语法树解析，针对 export 导出的各种类型生成对应的 fast-json-stringify 的 JSON schema，所以运行速度和手写是没有区别的。因此，它不仅仅能完全使用 fast-json-stringify 的效率优势，除了减少重复开发量以外还有如下优点：\n\n* **根据 schema 进行字段校验：** 首先会进行 Tyepscript 语法校验，另外当缺失必须的属性（例如，当定义 interface 时没有被 `?` 修饰符修饰的属性缺失）的时候也会直接报错。\n* **过滤不需要的 schema 字段：** 例如当把 Node.JS 当作 BFF 层的时候，可以严格按照 Typescript 的定义来返回字段，避免返回不需要的字段，从而避免上游服务的敏感字段被直接透传出去，也意味着从接口层面开始，真正做到 Fully Typed。\n* **更快的序列化速度：** 根据 [fast-json-stringify](https://github.com/fastify/fast-json-stringify/issues) 的测试，能达到接近 2 倍的 JSON 序列化速度。\n\n目前，fst-json 对常用的各类 interface、class、type 等类型定义都进行了支持，并且增加了各类 examples 和 90% 的覆盖率测试。\n\n当然，由于 Typescript 的写法比较灵活。出于 JSON schema 本身的局限性，我们无法覆盖所有场景，所以也可以参考这里的[注意事项](https://github.com/aircloud/fst-json/blob/master/README.zh-cn.md#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9)，有针对性的对比较容易出问题的写法进行规避。\n\n### 局限性\n\nfst-json 只是语法解析和生成工具，具体的运行时，实际上就是在使用 fast-json-stringify，也因此项目中需要安装 fast-json-stringify 依赖。\n\n另外，针对 fast-json-stringify 的测试，在比较小的 payload 的情况下，它的速度是有优势的，当 payload 过大的时候，它的优势不再明显，甚至还不如 JSON.stringify。官方的描述是：\n\n> fast-json-stringify is significantly faster than JSON.stringify() for small payloads.\n> Its performance advantage shrinks as your payload grows.\n\n不过事实上，这个时候你仍然可以使用 fst-json 做一些事情，例如笔者使用 fst-json 来做 bff 层对下游服务接口的持续集成兼容测试，在 Typescript 已经提前定义好了的情况下，每次测试的时候只需要请求依赖服务并且把响应字段序列化，如果没有报错并且字段序列化之后也没有变成 null（在比较复杂的接口定义中，如果个别属性定义类型和返回类型不一致，fast-json-stringify 是会直接转换成 null），就说明接口是没有变化的。可以有效避免依赖服务接口变化，却又没有及时同步到位造成暗坑的情况。\n\n\n另外，其实目前 fast-json-stringify 生成序列化代码还是在运行时做的，这里的问题可能在于代码不透明，以及运行时开销和风险，笔者是希望将它的生成代码变成编译时去做，不过这样的话实际上有一点重复造轮子的错觉，所以目前还没有做这个事情。\n\n---\n\n最后 [fst-json](https://github.com/aircloud/fst-json/) 作为一个开源不久的小项目，肯定还有些需要优化和完善的地方，欢迎 star 支持和提出建议。\n\n","tags":["前端综合"]},{"title":"《代码精进之路》与《代码整洁之道》-读书笔记","url":"/2022/01/30/《代码精进之路》与《代码整洁之道》读书笔记/","content":"\n本文通过对部分重点内容罗列的方式对此两本书的读书笔记进行记录。\n\n> 《代码整洁之道-程序员的职业素养》\n\n## 软件开发原则\n\n所有软件项目的根本指导原则是，软件要**易于修改**。如果违背这条原则搭建僵化的结构，就破坏了构建整个行业的经济模型。\n\n## 必备技能\n\n软件开发人员必须精通的事项：\n\n* 设计模式：必须能描述 GOF 书中的全部 24 种模式和，同时还要有 POSA 书中的多数模型的实践经验。\n* 设计原则：必须了解 SOLID 原则，而且要深刻理解组件设计原则。\n* 方法：必须理解 XP、Scrum、精益、看板、瀑布、结构化和分析以及结构化编程。\n* 实践：必须掌握测试驱动开发，面向对象设计，结构化编程，持续集成和结对编程。\n* 工作：必须了解如何使用 UML 图，DFD 图，结构图，Petri 网络图，状态迁移图表，流程图和决策表。\n\n## 不要说“我试试”\n\n* 这种类型的描述并不是承诺，实际上并没有实际意义。\n* 而且这通常意味着你之前评估周期的时候**并没有竭尽全力**，否则为什么在压缩周期的讨论中还要再说“我试试”呢。\n\n## 重新定义“完成”\n\n* 有的时候，我们自欺欺人的认为任务已经完成的足够好了，然后转入下一项任务。我们会给自己找借口说，其他还没来得及完成的工作可以等到时间更充裕的时候来处理。甚至有的时候，我们会把代码提交定义为”任务完成“。这样显然是错误的。\n* 真正的任务完成，是已经通过了测试，并且上线完成等。\n\n## 寻求帮助\n\n* 编程并非易事。越年轻的程序员可能越没有感觉，毕竟代码只不过是一堆 if 和 while 语句而已。但是随着经验增长，你会开始意识到把这些 if 和 while 语句组装在一起并非易事。不能期望将他们简单的组装到一起就能得到最好的代码。相反，必须小心谨慎地将系统分解为易于理解的单元，同时使得这些单元之间的联系越少越好。\n* 因此，仅凭一己之力很难写出足够优秀的代码，即使你的技艺足够高超。**也一定能从另外一名程序员的思考和想法中获益。**\n\n## 重新认识争论\n\n* 凡是不能在 5 分钟内解决的争论，都不能通过辩论来解决。争论之所以要花费这么长时间，是因为争论双方都拿不出足够有力的证据，这个时候争论依据的不是事实，而是信念。\n\n## 团队\n\n* 成员需要克服个体差异性，默契配合，彼此信任，形成真正有凝聚力的团队，是需要一些时间的。可能需要 6 个月，甚至一年，但是，凝聚力一旦形成，就会产生一种神奇的魔力。团队成员会一起做计划，一起解决问题，一起面对问题，**一起解决一切**。\n\n> 《代码精进之路》\n\n## 命名\n\n一般来说我们都知道命名应该有可读性，但是像这里介绍这么详细的并不多。\n\n例如我们针对命名可以通过固定分段限定词的方式进行统一：\n\n* `[动作][对象][范畴]`，来统一我们的命名，例如 `getRevenueTotal(获取总收入)`。\n\n## 注释\n\n* 注释如果是对执行过程的简单复述，那么这样的注释不应该存在。\n* 我们可以通过函数和中间变量的封装，来减少可以避免的注释。\n\n## 错误和错误码\n\n我们可以通过以下几种方式处理错误（中后台系统比较合适）：\n\n1. 程序运行期间的错误，一般我们可以通过 Error 打印到日志中，而且这类错误，最好和报警系统进行对接，直接输出到报警系统中。\n2. API/服务调用错误，这种错误一般通过错误码返回给调用端的同时，也需要在日志做好记录。\n\n> 关于错误码：错误码我们可以使用数字或者显示化错误码，数字的坏处即我们需要额外维护错误码表，调用者可能并非我们团队，有可能造成沟通障碍。\n> 因此，更建议使用**显示化错误码**，并且可以做一个约定：P 代表参数异常，B 代表业务异常，S 代表系统异常，例如：P_Customer_NameIsNull 客户姓名不能为空\n\n## 代码中的破窗效应\n\n破窗效应在代码中很常见，通常在我们完成一个功能的时候，都是基于现有代码的改动，如果你可以基于一个现有代码的不良设计完成功能（例如，在已经很混乱的事件订阅类增加一个 Enum、在已经很冗长的 Http 请求列表复制一个新的出来），那么大概率你会这样做而不是重构，**特别是当这个不良设计不是你最初写的时候，就更加可以心安理得的改代码而没有任何负罪感，甚至在 Code Review 的时候都可以有充足的理由：它已经是这样了，这次先上，将来找个时间整体重构才行。**\n\n## SLAP\n\nSLAP：Single Level of Abstraction Principle，抽象层次一致性\n\nSLAP 要求函数体中的内容必须在同一个抽象层次上，如果高层次抽象和低层次细节杂糅在一起，就会显得凌乱，难以理解。\n\n## 如何述职\n\n* 方法1: **提出问题，定义问题，分析问题，解决问题，最后展望未来**。这个也是麦肯锡常用的方法。\n* 方法2: 我们说事情的时候，应该像电影镜头一样，先由远拉近，再由近拉远。从宏观背景，到怎么做的，到结果和思考。\n\n\n","tags":["读书笔记"]},{"title":"《重构》-读书笔记","url":"/2022/01/02/重构-读书笔记/","content":"\n## 开始重构\n\n如果你要给程序添加一个特性，但发现代码因缺乏良好的结构而不易于进行更改，那就先重构那个程序，使其比较容易添加该特性，然后再添加该特性。\n重构前，先检查自己是否有一套可靠的测试集，这些测试必须有自我检视的能力。\n\n> 事实上很多时候，测试集都是被我们忽略的\n\n营地法则：保证你离开的时候代码库一定比原来的更加健壮。\n\n什么是重构？根据重构这本书的定义，如果有人说他们的代码在重构过程中有一两天的时间是不可用的，基本上可以确定，他们在做的事情不是重构。\n\n## 何时重构\n\n事不过三法则（Rule of Three）：第一次做某件事情的时候只管去做，第二次做某件事情的时候会产生反感，但无论如何还是可以去做，第三次再做类似的事情，你就应该重构。\n\n> 在《代码精进之路》这本书中，也提到了这个原则。\n\n另外的一个时机是，每次要修改时，首先令修改很容易（警告：这件事有时候会很难），然后再进行这次的修改。\n\n> 比如，笔者最近在做一个长链接客户端 SDK，最初这个 SDK 功能很简单，我直接加功能即可，后面有一次当我要修改的时候，我发现这个 SDK 的修改已经变得异常复杂了，这个时候我知道我应该重构了。\n\n## 重构法则\n\n这里对一些我们实际场景中遇到，但是通常会被我们忽视的一些法则进行列举。\n\n### 霰弹式修改 \n\n如果我们代码中的模块特别多，如果我们每次遇到一个变化都需要在不同的小模块中做许多小修改，我们所面临的坏味道就是霰弹式修改。\n这个时候我们需要思考重构，最好我们不同的模块都是正交的。\n\n### 慎重注释\n\n有的时候，我们写注释是因为这段对应的代码逻辑很糟糕。\n因此当你感觉需要撰写注释的时候，请先尝试重构，试着将所有的注释变成多余。\n\n### 提炼变量\n\n对于复杂语句，提炼变量可以增加可读性。\n\n","tags":["读书笔记"]},{"title":"《架构整洁之道》-读书笔记","url":"/2021/12/26/架构整洁之道-读书笔记/","content":"\n这本书之前刚工作的时候略有耳闻，不过当时简单翻阅了下，并没有什么共鸣，可能是编程经验太少导致，但最近我再重读这本书的时候，感觉之前自己或所在团队确实踩了不少类似的坑，也渐渐了解到，很多复杂的项目和工程背后，其实往往是一些最朴素的道理，软件工程的发展也并没有上层框架的发展那么快。\n\n也因此，本篇博客作为一个读书笔记性质，可能有些地方也并非足够连贯。\n\n## 如何看待软件架构设计\n\n软件架构设计的终极目标：用最小的人力成本来满足构建和维护该系统的需求。\n\n很多时候，对于一个系统，一开始我们的开发效率接近 100%，然而伴随产品的每次发布，生产力直线下降。工程师的大部分时间都是消耗在对现有系统的修修补补上面，而不是真正完成实际的功能。拆东墙补西墙，周而往复。公司需要的人力成本也因此变多了，但是效益却没有提升。\n\n初级工程师总是会犯的一个问题是：持续低估良好的设计，整洁的代码的重要性，并且普遍采用一种话术来欺骗自己：我们可以未来在重构代码，产品上线最重要。而实际上，产品上线之后疲于应付新需求已经很累了，就很难有重构的时机。\n\n实际上，一般软件开发都会被设计成如下三个阶段，这可能并没有错：\n\n1. 先让代码工作起来\n2. 试图让它变好：通过优化和重构，让人更好地理解代码，并且适应新需求。\n3. 试着让它运行的更快\n\n所以，我们确实需要理解整洁架构的重要性，避免我们在 1 和 2 循环往复。\n\n软件设计的第一条原则：不管是为了可测试性还是其他什么东西——**是不变的，就不要依赖于多变的东西。**\n\n## 软件系统\n\n软件系统的价值维度：行为和架构。\n\n**变更的实施难度应该和变更的范畴成等比关系，而与变更的具体行为无关**。\n> 有的时候，产品经理会表示，我就改一个小点，为什么需要几天时间？开发人员会找一大堆理由，通常不会提及架构的不合理性。实际上这种现象在我毕业入职的第一家公司时有发生。\n\n## 编程范式\n\n目前，我们主要有三个编程范式：结构化编程，面向对象编程，函数式编程。这些编程范式都是在 20 世纪被提出来的，而且在有限的时间中估计也不会新增编程范式了。\n\n* 结构化编程：if/then/else 和 do/while/util\n* 面向对象编程\n* 函数式编程：值不可变，对赋值进行了限制和规范\n\n三个编程范式，分别限制了 goto 语句、函数指针和赋值语句的使用。\n\n### 结构化编程\n\n程序员可以用代码将一些已经证明可用的结构串联起来，只要自行证明这些额外代码是正确的，就可以推导出整个程序的正确性。\n\ngoto 语句，让我们的程序很难被分成这种小块。\n\n关于验证：科学理论和科学定律的特点：他们可以被证伪，但是没有办法被证明，实际上现有的编程大部分也采用了这种理念，我们没用使用完整的形式化证明，而是使用测试用例，测试没有问题后，即发布到线上。\n\n### 面向对象\n\n* 封装、继承、多态都不是面向对象创造出来的，但是确实使用起来更方便了。\n* 依赖反转也通常是面向对象的特点。\n* 独立部署：当某个组件的源代码需要修改，仅仅需要重新部署该组件即可，不需要修改其他组件。\n\n**面向对象编程就是以多态为手段来对源代码中的依赖关系进行控制的能力，这种能力让软件架构师能够构建出某种插件结构，让高层策略性的组件和底层实现的组件相分离，底层组件可以被编译成插件，实现独立于高层组件的开发和部署。**\n\n### 函数式编程\n\n* 所有的竞争问题、死锁问题、并发更新问题都是由可变变量导致的，如果变量永远不能被篡改，那就不可能产生竞争或并发更新的问题。如果锁的状态是不可变的，那就永远不会产生死锁问题。\n* 一个个架构设计良好的应用程序应该将状态修改的部分和不需要修改状态的部分隔离承担度的组件，然后通过合适的机制保护可变量。\n* 软件架构师应该着力于将大部分处理逻辑都归于不可变组件中，可变状态组件的逻辑越少越好。\n\n一种函数式编程理念的开发方式：\n事件溯源：我们只存储事务记录，不存储具体状态，当需要计算具体状态的时候，我们只需要重头开始计算所有的事务即可。同时，我们也把 CURD 变成了 CR。\n\n\n## SOLID 原则\n\n我们为软件构建中层结构的主要目标：\n\n1. 使软件可容忍被改动。\n2. 使软件更容易被理解。\n3. 构建可在多个软件系统中复用的组件。\n\nSOLID 原则 分为以下几点：\n\n* SRP：单一职责原则，任何一个软件模块都应该有且只有一个被修改的原因。避免多人为了不同的目的修改同一份原代码文件。\n* OCP：开放封闭原则，通过新增代码来修改原有的行为，而非只靠修改源代码。\n* LSP：里氏替换原则，组件方便被替换，每一处使用父类对象的地方，可以使用其子类对象进行替换，而保持其行为不变。\n* ISP：接口隔离原则，避免不必要的依赖。\n* DIP：依赖反转原则，高层代码不应该依赖底层细节。如果我们想要设计一个灵活的系统，在源代码层次的依赖关系中就应该多引用抽象类型，而非具体实现。\n  * 优秀的软件架构师会花费很大力气来设计接口，以减少未来对其进行的改动。毕竟在不修改借口的情况下为软件增加新的功能是软件设计的基础常识。\n\n> 实际上我们在实现 TS 库代码的时候经常用到 DIP，比如我们底层代码需要用到上层的一个功能，我们通常定义一个抽象类或者抽象函数，然后由上层来实现，这种场景即是 DIP。\n> 例如，在我们写一个库的时候，通常会定义一个抽象，然后由外层传入实现这个 log，而不是在库代码中直接依赖某种 log 实现（可以有一个默认的实现），这个即是 DIP 的一个运用。\n\n## 组件构建原则\n\n组件是软件的部署单元。\n\n* REP：复用/发布原则：软件复用的最小粒度应等同于其发布的最小粒度。\n* CCP：共同闭包原则：我们应该将那些会同时修改，并且为相同目的而修改的类放到同一个组件中，而将不会同时修改，并且不会为了相同目的而修改的那些类放到不同的组件中。\n  * **对于大部分项目来说，可维护性的重要性远远大于复用性**（精髓所在，以前一直觉得复用重要，但回头想想，对于一个项目而言，维护成本才是最直观的指标，这里设计修改所需要的人力成本，最终还是利益如何最大化的问题）\n* CRP：共同复用原则：实际上是 LSP 原则的一个普适版，LSP 原则是建议我们不要依赖带有不需要函数的类，CRP 原则则是建议我们不要依赖带有不需要的类的组件。\n\nREP 和 CCP 是粘合性原则，他们会让组件变得更大，而 CRP 是排除性原则，它会尽量让组件更小。\n\n组件耦合原则：\n\n* 无依赖环原则：整体依赖应该是一个有向无环图。\n* 稳定依赖原则：**依赖关系必须要指向更稳定的方向。**我们可以通过组件的依赖和被依赖的关系计算它的位置稳定性。\n* 稳定抽象原则：一个组件的抽象化程度应该与其稳定性保持一致。稳定的组件应该是抽象的，那么它的稳定性就不会影响到扩展性。\n\n## 软件架构流程\n\n整体包括：运行、维护、开发、部署\n\n什么是软件架构师？软件架构师实际上应该是能力最强的一群程序员，他们通常会在自身承接编程任务的同时，逐渐引导整个团队向一个能够最大化生产力的系统设计方向演进。所以我们有时候误以为架构师就不写代码了，这当然是错的。\n\n软件架构设计的三个工作：组件的切分，组件的组合，以及组件的相互通信。\n\n软件架构设计的终极目标：最大化程序员的生产力，最小化系统的总运营成本。\n\n关于部署：一般一个系统的部署成本越高，它的可用性就越低\n\n> 例如在系统早期开发中，我们可能会决定采用某种微服务架构，但当我们实际部署这个系统的时候，我们就会发现微服务的数量已经庞大到令人生畏，这也就是笔者之前所在公司遇到的问题：一开始通过 golang 微服务实现整个系统，后面决定私有化部署后，迁移成本巨大，不得不进行了微服务的合并。\n\n运行：**对于一个因架构设计糟糕而效率低下的系统，我们通常只需要增加更多的存储器与服务器，就能够让它圆满的完成任务。另外，硬件也远远比人力便宜，这也是软件架构对系统运行的影响远远没有它对开发、部署、维护的影响那么深刻的原因**\n笔者现在确实应该意识到这个问题。\n\n基于以上设计的架构：UI 界面 - 系统独有的业务能力 - 领域普适的业务能力 - 数据库\n\n重复：*架构师经常会钻进一个牛角尖：害怕重复*。虽然软件代码编写的原则是 `don't repeat yourself`，但是有的时候，对于两个后期发展偏差很大的组件，如果只是存在一些暂时的重复，是我们完全可以容忍的。我们应该根据实际情况来决定是否要重复。\n\n## 划分边界\n\n软件开发技术发展史，就是一个如何想法设法方便增加插件，从而构建一个可扩展，可维护的系统架构的故事，系统的核心业务逻辑必须和其他组件隔离，保持独立，而这些其他组件要么是可以去掉的，要么是有多重实现的。\n同时，插件部分的变更实际上不应该影响系统核心逻辑的变更。\n\n> 这里举例：比如说当我们设计一个多节点 server，它依赖一个分布式存储系统，我们不应该在 server 中把这个分布式存储系统默认为 redis, 而应该定义接口能力即可。\n\n如何分层：本质上，所有的软件系统都是一组策略语句的集合。我们需要将这些策略彼此分离，并且将它们按照变更的方式进行重新分组。其中变更的原因，时间和层次相同的策略应该分到一个组件中。反之，变更原因、时间和层次不同的策略应该分属不同的组件。最终它们是一个有向无环图。\n\n## 整洁架构\n\n* 六边形架构\n* DCI 架构\n* BCE 架构\n\n这些架构通常有以下特点：\n1. 独立于框架\n2. 可被测试：这些系统的业务逻辑可以脱离 UI、数据库、Web服务以及其他外部元素来进行测试。\n3. 独立于 UI，并且比较方便地在不改动业务逻辑的情况下改动 UI\n4. 独立于数据库，以及独立于其他外部机构\n\n谦卑对象模式：\n\n谦卑对象的解读：我们可以将软件模块分为两组，一组是谦卑组，另外一组不是。谦卑组的模块通常比较难写代码进行测试，比如 GUI，这部分代码应该越简单越好。\n\n门户模式：Facade Pattern\n外部只能看到 Facade，然后 Facade 内部的 implement 可以有一个或者多个。\n> 这种模式在我们重构项目的时候挺有用的，我们可以实现一个 Facade 类，然后默默把里面的实现灰度或者直接换掉。\n\n## 服务和架构\n\n实际上，服务本身只是一种比函数调用成本稍微高的，分割应用程序的一种形式，与数据库无关。\n\n**服务真的解耦了么？因为通常服务不能彼此访问变量，我们会认为这种设计自然就解耦了。但实际上，任何形式的共享数据都会导致强耦合，比如它们依赖同一种数据结构、同一个 schema。而且在这种情况下，它们的 dev ops 也并不是独立的。**\n\n---\n\n<完>\n","tags":["读书笔记","架构"]},{"title":"React Conf 2021 内容概要","url":"/2021/12/08/ReactConf2021/","content":"\n原文：https://zhuanlan.zhihu.com/p/447103166","tags":["React"]},{"title":"PC 开发技术选型：Electron 不是银弹","url":"/2021/09/16/electron可能不是你的解药/","content":"\n[Electron](https://www.electronjs.org/docs) (类似的还有 nw.js）是一个使用 JavaScript、HTML 和 CSS 构建桌面应用程序的框架。 嵌入了 Chromium 和 Node.js。\n\n也就是说，我们几乎可以使用纯 web 技术，来创建跨平台的 windows 和 macOS 的原生应用，并通过 Node.js addon 能力接入 native 模块。目前市面上，也有一大批知名的应用是使用 Electron 开发的，比如：VS Code、Atom、Microsoft Teams 等（*在 macOS 上面一个简单的判断应用是否使用了 Electron 的办法：在应用的 Contents/Frameworks 里面搜索是否有 Electron Framework.framework*）。\n\n但实际上，这篇文章是希望你在选用 Electron 框架前，需要进行慎重的考虑和评估。国内有很多公司，包括一些一线互联网公司的项目是一开始为了快速迭代选择了 Electron，后续实在无法进一步优化，全部推到重来，这实际上反而不利于整体的项目迭代。\n\n# 架构选型\n\n一般来说，笔者认为有以下几个场景，不适合使用 Electron 进行开发：\n\n## 1. 无页面或者少量页面的应用\n\n这一点很好理解，Electron 的便利性主要体现在页面相关的开发，如果你的应用几乎没有页面，比如只在顶部状态栏区域有一个按钮，显然就没有必要使用 Electron，直接使用原生的技术栈即可。\n\n## 2. 对安装包体积限制较为严格的应用\n\nElectron 由于自身携带的基础设施，导致即使你的业务代码不多，初始安装包也会比较大（毕竟接近一个浏览器的大小），在没有你的业务代码的情况下，未经优化的安装包达到了 60MB 左右，而且通常你需要把 node_modules 一起打进去，所以即使你的业务并不复杂，也很容易产生一个接近 100MB 的安装包。\n\n因此，如果你的业务需要比较极致的包体积优化，那么 Electron 可能并不是一个合适的选择。\n\n## 3. 多窗口应用\n\nElectron 的进程模型为一个主进程 + 若干渲染进程，每一个渲染进程用于展示一个页面，**即使你的页面是 Hello World，内存占用也达到 50 MB 左右**。\n\n也就是说，如果你的应用需要同时展示多个窗口，那么就需要多个渲染进程，这样整体的内存占用就会上涨很多，而实际上我们使用原生或者其他的类 cef 的方案，是可以做到一个进程对应多个窗口的。\n\n## 4. 性能消耗较高并且需要高度定制优化的应用：比如视频类应用\n\nElectron 基于 web 架构，所以使用 Electron 开发的应用性能一般来说和 web 比较接近，当然，我们可以通过 Node.js addon 加持的方式让部分场景下性能更高（比如直接使用 c++ 实现一些计算密集型的模块，或者独立出一个非 UI 进程，来处理非 UI 逻辑），不过页面 UI 相关的还是会受限制于 web 的天花板。\n\n所以，一般来说，以下两种情况可能不适用于 Electron：\n\n1. 在 web 场景下，UI 元素操作比较卡顿，达到瓶颈，必须采用性能更高的原生 UI。不过我建议**不要轻易下这个结论**，一般情况下这种性能问题都是写的代码不够极致，建议先从 web 的角度进行性能优化（比如，长列表场景我们可以[通过压缩合成层优化性能](http://niexiaotao.cn/2021/09/04/%E9%80%9A%E8%BF%87%E5%8E%8B%E7%BC%A9%E5%90%88%E6%88%90%E5%B1%82%E4%BC%98%E5%8C%96%E6%80%A7%E8%83%BD/)来数十倍地提高性能）。\n\n2. 对某一项技术有深度依赖，而这项技术在 web 方面存在性能上的天花板。事实上这种情况也并不多见，其中一个合理的场景是视频相关的应用，比如视频会议，或者视频播放器，这类由于 Chrome 本身的渲染流水线的限制，使用 video 标签或者使用 WebGL 都会存在一些性能问题，这个时候我们需要更深入的去进行相关能力的定制，就需要从 Electron 的框架中跳脱出来，或者针对 Electron 进行二次开发。\n\n> 关于 WebGL: 实际上很多 web 开发者会把 WebGL 当作部分场景下性能优化的银弹，但实际上 WebGL 目前存在诸多困境：WebGL 1.0 虽然已经普及，但是其作为 OpenGL ES 2.0 的子集，性能上已经并不特别适用现代硬件架构；而 WebGL 2.0 目前仍然在普及中并且各家厂商意见无法一致；Web GPU 可能是一个更好的解决方案，底层直接对接 D3D12、metal、vulkan 等更底层更先进的图形框架，但目前成熟度不高。\n\n如果你的应用在经过以上分析之后，认为仍然可以使用 Electron 进行开发，那么恭喜你拥有了一个如此高效率的开发方案（如果不行，建议你可以选择其他的解决方案，比如 [QT](https://www.qt.io/)）。\n\n当然在此基础上，我们仍然需要进行充足的性能优化和稳健的架构设计，来让我们应用的可靠性变得更高。\n\n# 性能优化\n\n和 web 不同的是，我们的 native 应用需要更加关注如下三个指标：\n\n## 1. cpu\n\ncpu 占用相关的问题，我们在 web 技术栈中一般也会关注，不过更多的是关注函数的调用耗时，是否存在同步调用的耗时过长导致卡顿等问题。\n\n而在桌面应用程序的场景中，我们需要从整个应用的维度关注 cpu 消耗，并且需要更加重视。\n\n另外一个原因是，在网页场景中，页面的 cpu 占用通常不会特别直观地被用户发现（因为系统层面通常只会体现在浏览器占用 cpu 较多），而在现在的原生场景，用户可以直接在任务管理器中看到我们的应用，如果我们的应用持续有一个较高的 cpu 占用，就会比较容易被用户发现，甚至触发系统告警提示强杀应用，这对我们应用的口碑也是一个比较负面的影响。\n\n## 2. 内存\n\n在桌面应用程序中，内存的使用方式有了一个明显的变化：\n\n原有的 web 页面，通常是用完即走，而对于 native 应用用户一般会打开很久，这也就意味着我们如果一旦产生内存泄漏或者内存占用比较高的情况，对用户的影响是持续并且被不断放大的。\n\n对于 cpu 和内存的分析，我们可以通过以下方式：\n\n1. 开发阶段通过 visual studio 或 instruments 来详细分析我们开发的功能的 cpu 和内存分配情况，发现问题。\n2. 测试发布阶段通过第三方内存分析工具，流程化的分析 cpu 和内存占用并产出报告。\n3. 线上阶段持续监控 cpu 和内存消耗情况，并且上报数据进行统计和监控告警。\n\n## 3. crash 率\n\n实际上在前端领域基本上没有 \"crash\" 这个说法，不过对于 native 应用来说，即使我们的应用是完全采用前端技术栈，也可能存在 crash (crash 在 Electron 的代码），一般这个时候用户的体验是闪退，相对来说算是严重影响用户体验的问题，因此值得我们足够的重视。\n\n对于 crash 问题我们应该做好以下三点：\n\n1. 运行时 crash 监听机制，一般是 sentry 或者直接使用其依赖的 crash_pad。\n2. 符号管理机制，管理我们原生模块，和我们用到的 Electron 对应版本的符号。\n3. 运行时 crash 上报告警机制。\n\n# 架构优化\n\n除了上述性能指标和监控手段，我们可以通过一定的架构优化，来增强系统的可靠性。\n\n## 通过 Node.js addon 或者独立进程的方式原生实现非 UI 内容\n\n这里的作用主要是希望能够借助原生模块的高性能优化 cpu 的占用。\n\nElectron 让我们开发 ui 相关的页面变得非常高效，但是一些逻辑部分，或者和操作系统进行交互的部分，我们还是需要原生开发的手段，毕竟即使使用了 Node.js，也无法直接进行系统调用。\n\n这里我们可以采用 Node.js addon 的方式或者独立进程+进程间通信的方式，两者的好处分别是：\n\naddon：\n\n1. 方便进行内存共享。\n\n独立进程：\n\n1. 通常会增加可靠性，独立进程挂掉后可以单独重启，不影响用户界面。\n2. 需要防止大块的内存重复占用，可以通过共享内存等方式来进行优化。\n\n## 减少或者禁止在渲染进程使用 remote\n\n有的时候，即使 electron 的技术选型适合你的项目，但如果滥用 remote 也会造成整个应用的大量不稳定与卡顿。\n\n实际上，我们可以通过阅读 electron 的源代码发现，remote 模块只是对 IPC 消息的同步封装，方便渲染进程调用主进程的对象和方法，而不必显式发送消息进行进程间通信。所以，由于其屏蔽了内部的进程间通信，在调用的时候基本无感主进程的存在和 IPC 的风险，但事实上这却有卡顿甚至卡死渲染进程的风险。\n\n另外，去掉 remote 还有另外一个好处，就是方便我们项目的 PC 版本和 web 版本进行同构，具有更高的可维护性。\n\n所以针对一般的项目，笔者建议能禁用就禁用 remote，规避此隐患。\n\n## 其他优化\n\n我们可以在代码编写和打包的过程中，做一些其他的优化，在这里，大部分前端的优化比如动态加载、代码分割、图片缓存等大多也都适用 electron 的情况，除此之外，还有一些优化则是：\n\n1. 避免重复打包：\n   * **避免 node_modules 和 webpack 重复的打包和引入**，对于 webpack 我们可以使用 webpack-bundle-analyzer 来分析打包体积进行优化\n   * 减少无关文件的打包，可以通过配置针对 electron-builder 的 config 去除无关内容打包，同时可以使用 [node-prune](https://github.com/tj/node-prune) 来去除无用的 node_modules 小文件。\n\n2. **v8-code-cache**: \n   * 可以使用 [v8-compile-cache](https://github.com/zertosh/v8-compile-cache) 来进行一定的编译优化\n\n3. 更多可以参考 VSCode 的相关分享：https://www.youtube.com/watch?v=r0OeHRUCCb4","tags":["前端综合"]},{"title":"我们应该如何进行 Code Review ?","url":"/2021/09/05/一些代码提交MR的重点关注内容整理/","content":"\n笔者在日常工作中会发现，时常会存在一些比较显而易见或者已知的一类问题，在开发者提交代码以及相关同学 Review 中均未被发现。实际上，代码开发者在某些时候会提交较多代码，而此时 Reviewer 面对较多代码的 Review 的时候，很可能会漏掉一些 Review 的要点，甚至可能会感到无所适从。本文希望，针对一些非场景化的内容，整理出一些较为普适的一些原则，从而帮助 Reviewer（以及开发者本身）解决一些通用的问题。\n\n## 隐私性原则\n\n隐私通常涉及到法律合规，因此可能是最重要的一环。\n\n### 用户的隐私不可泄漏\n\n比如在开发功能打日志的时候，我们应该不能泄漏用户的隐私，例如用户的自定义信息、聊天信息等。\n\n这一部分建议在团队内部形成一个统一的规范文档，在开发和 Review 的过程中，大家都可以以此为依据。\n\n### 自己的隐私不可泄漏\n\n很多时候，我们虽然注意到了用户的隐私，但是自己的隐私却没有注意，这里主要是我们的一些 appKey、密钥等内容。无论是在以下哪些场景，我们都需要格外注意：\n\n* 对产物进行二次分发，例如分发到内部或外部 npm、github 以及其他团队，特别是外网可访问的情况更需要注意。\n* 直接给到用户使用，例如在 Web 环境使用，或者打包到桌面端应用，尽量避免用户直接接触到这些内容。\n\n## 可读性/维护性\n\n### 代码提交的注释\n\n对于 bug fix：很多时候我们是在处理一个边界问题，或者某种兜底，这个时候 fix 的代码可能比较难以理解，在这种情况下我们最好是写明注释，如果有相关的文档和 bug 单，我们也可以一并贴到注释中。另外，如果我们的 bug fix 是一个临时方案，请在代码中写明 TODO，来提醒自己和别人这个地方后续还会继续更改。\n\n对于新功能添加：一般我们需要在关键入口处写明功能的说明文档链接、完善相关关键路径的注释，同时删除功能开发中的冗余代码：例如我们在开发过程中测试用到但是最终却没有用到的大段注释掉的代码，以及大段的注释和 TODO，我们都需要在最终提交的时候**删除掉**，如果需要找回建议使用 git 的能力，可以适当进行注释备注。\n\n另外，对于注释来说，禁止出现模糊的词汇，例如 `感觉`，`好像`，`大概` 等这种模糊的词汇，而是要培养自己严谨的意识，已经提交的代码必须有严格的佐证。\n\n### 代码的通用性\n\n当我们提交一个功能，或者修复一个问题的时候，很多时候我们只是从这个问题的角度护发，但是并没有从全局的角度出发，例如：\n\n* 当我们新增一个上报的时候，有没有考虑把整个上报聚合到一起，或者架构上支持更方便的上报能力？\n* 当我们新增一个通用能力的时候，有没有考虑到其他模块或项目也可能有类似需求，我们是否可以将其单独抽离成一个独立的包进行分发？\n* 当我们遇到一个问题有多种修复方案的时候，有没有综合考虑，哪一种方案对后续维护的同学更加友好（比如，最好是高内聚、低耦合的设计）？\n\n这里的大体原则，就是我们需要从整体性的角度出发，不断地迭代让整个架构更加夯实，而不是出个问题贴一个创可贴，新增功能又贴一个创可贴。\n\n### 配置化\n\n这里的配置化，比较典型的比如是：多语言文案、项目 Settings 配置等。\n\n* 一般来说，配置化的内容最好是走云端下发。\n* 如果不具备云端下发的环境，或者我们的配置**比较敏感不适合直接下发**，可以考虑在代码中创建配置文件的方式。\n\n如果我们在 Review 中发现有可以配置化的内容但是却直接写死在代码里面了，应当需要提出质疑。\n\n### 代码精简\n\n代码精简对后期的可维护性是非常重要的，代码精简的一个比价有效的办法就是充分理解业务，写出精简不多余的代码，不过这一点在 MR 中可能会比较难进行 Review，因为一般来说提交代码的同学本身是对这部分业务是理解的最透彻的。\n\n但是有一点代码的 Reviewer 会比较容易判断，如果我们提交的代码里面有两处以上超过三行的极其相似的代码，我们就应当重新审视是否可以进行一定程度的抽离，建议不要由于一时的效率允许不符合规范的代码合入，这些在后期都可能演化成代码屎山。\n\nRust 代码精简的一些建议：\n\n* 避免任何一次多余的 Clone。\n* 文件头部引用中去除没有必要的引用。\n* 避免多余的日志，同时避免在日志里面加太长的前缀内容（有的时候一行日志里面有多半都是元信息，而且这些元信息还是有所重复的）。\n* 避免多余的 pub，应该有一个理念就是默认的内容不要 pub 出去，就像 c++ 的成员方法默认是 private 一样。\n* 重复代码使用宏来替代。\n\n## 重视性能\n\n### 防止泄漏\n\n在考察性能之前，我们需要保证自己的代码没有泄漏，因为泄漏造成的恶劣性通常比性能差更严重，而且通常需要更长的时间来排查。\n\n这里主要的检查点可以是：\n\n* addListener 之后是否及时释放了。\n* setInterval/setTimeout 等定时器调用是否存在多次调用的可能性，以及是否可能无法释放。\n* 分配在堆上的内存是否释放了。\n* 是否有 detach dom 泄漏。\n\n### 防止死锁\n\n这一点如果是前端开发，一般没有机会遇到，但如果你用 rust、c++ 等语言，都很有可能出现死锁的风险（严格来说，死锁并不能直接归类到性能）。\n\n对于死锁的防止，我建议团队内的基础设施部分先配置好死锁检测和上报机制（例如 parking_lot 提供了死锁检查的能力）。\n\n一些死锁相关的 Review 建议：\n\n1. 用到锁的地方，尽可能通过工具函数进行封装，类似 getter 和 setter，增加原子性，减少调用代码直接解锁的场景。\n2. 锁的粒度不应该太大，**我们应该是对数据进行加锁，而不是对过程进行加锁**，锁粒度过大很容易出现死锁的风险。\n3. 在函数脱离控制权之前，例如准备开始调用到其他外部函数了，这个时候最好把持有的锁都释放掉，防止外部函数再次用到造成锁重入。\n\n### 性能报告\n\n关于这一部分，也建议团队基建先行，有一个比较标准的性能测试方法，这样大家在做性能测试的时候，不会那么有压力。比较反对的一种方式就是团队内部不同成员都有自己的一套性能测试方法，这样有些新同学缺乏必要的上下文，自然不了解如何去做性能测试。\n\n一般来说，我们涉及到比较大的功能都要进行一些性能报告，相关的指标可以是：\n\n1. 整体包体积的增加幅度。\n2. 初始化响应速度的变化。\n3. 运行该功能一段时间的 CPU 消耗。\n4. 运行该功能一段时间的 内存 消耗。\n5. 运行该功能较长时间的 CPU/内存 消耗。\n\n不过，具体这一部分还是建议团队内部根据项目的实际情况有一个统一的标准，并且将性能测试方法标准化，而不要成为一个负担。\n\n## 兼容性\n\n在兼容性这方面，无论是 web 开发还是桌面客户端开发，都需要重点关注，这里其实细分为两个维度：\n\n* 版本支持，例如我们可能会实现约定好支持到 Chrome 的哪个版本（针对 web）或者 macOS 的哪个版本（针对 macOS 桌面端），并且如果提交涉及到兼容性改动需要重点测试所支持的最低版本。\n* 异常情况支持，这一点可能大多数时候都会被大家忽略，这里举一个例子就是 webgl 的支持，实际上，虽然大多数时候浏览器已经支持到了 webgl，但是仍然有不少场景，webgl 会初始化失败，这个原因可能和用户的硬件比如系统显卡有关，如果我们的项目只有 webgl 实现，我们需要考虑是否放弃 webgl 初始化失败的场景（从商业化的角度，一般来说都是希望不要放弃），或者说为此增加软渲染降级。\n\n所以，在 Code Review 环节，针对可能出现兼容性风险的地方，我们需要确认是否已经进行了兼容性测试。","tags":["编程综合"]},{"title":"web 页面内存分析与生产环境禁用 console","url":"/2021/09/04/生产环境禁用console的意义/","content":"\n## 背景\n\n我们在开发前端页面中，建议在生产环境中将所有的 console 禁用，并通过自定义的日志函数进行日志输出，即使无法禁用，也需要自定义文本过滤函数，严格控制 console 的输出。\n\n但实际上，笔者经历的项目中很多都没有办法做到这一点，虽然我们知道，禁用 console 的主要原因除了信息泄漏的风险外，还有就是 console 打印的内容无法被内存回收。但仍然总是会有一些同学对禁用 console 的必要性表示质疑，在本篇文章中，本文通过两个实际遇到的比较严重的例子，来解释禁用 console 的必要性。\n\n> 出于保密性考虑，例子本身已经脱敏，本文使用示例代码模拟原始场景。\n\n## 页面内存\n\n在具体例子讲解之前，我们需要先对页面内存有一个认知，在前端开发中，我们虽然开发的只是在 Chrome 等浏览器中浏览的页面，但是对页面的 cpu 和 内存占用也需要时刻保持关注。\n\ncpu 和 内存一般是针对进程级别，chrome 的进程模型比较复杂，一般情况下，我们可以认为同域的页面有比较大的概率进行进程复用。\n\nChrome 提供了一些手段，让我们可以监控页面的 cpu 和内存，例如：\n\nPerformance Monitor 可以让我们直观地监测页面的 cpu、js heap 的分配情况等：\n\n![chrome_monitor](/img/chrome_monitor.png)\n\nChrome 自身提供了一个任务管理器（More Tools -> Task Manager），可以让我们关注各个页面的性能情况：\n\n![chrome_task_manager](/img/chrome_task_manager.png)\n\n除了实时监控以外，Chrome DevTools 的 Memory 等 tab 也可以让我们对内存占用进行取样分析，以及内存泄漏分析：\n\n* 一般来说，我们可以通过对两次 heap snapshot，然后搜索关键变量的数目与引用关系是否符合预期，来证明是否存在内存泄漏。\n* 除此之外，我们使用 WeakMap 来跟踪我们的实例，也可以辅助进行一定的内存泄漏分析。\n\n\n## 使用 console.log 打印 dom 元素造成死循环 OOM \n\n之前笔者负责的一个页面，在某个版本出现了一个问题：打开页面后不久，在什么操作也没有做的情况下直接卡死无响应。\n\n一般来说，js 导致网页无响应的可能性并不多，我们首先怀疑是因为死循环导致的。\n\n不过我们通过对比上次和这一次的代码，发现变动极小（实际上，我们一开始都忽略了 console.log），我们通过在 Chrome 的 devTools 里面打断点，最终定位发现是卡死在第三方库 sentry 的 console.log 中。\n\n最终我们定位出真正的原因：其中一处 try catch 在 catch 到错误之后，会 console.log 打印包括 dom 在内的一些内容，而我们使用的 console.log 被 sentry 进行了覆盖，它的覆盖方法大致如下（这个确实有点坑，以至于我们直接查看 console.log 仍然是 [native code]， 不过最新版本的 Chrome 这个代码已经不能完全 work）：\n\n```\nlet __native_console = console.log;\nconsole.log = function() {\n  // 递归遍历各个属性\n  __native_console(...arguments);\n}\nconsole.log.prototype.__native_console = __native_console;\nconsole.log.prototype.toString = function() { \n  if (this.__native_console) return this.__native_console.toString();\n  return this.toString();\n}\n// TODO: 2021.09 @niexiaotao 补充一下最新的实现\n```\n\n**这里之所以死循环，是因为 React 中 FiberNode 是 Dom 的其中一个属性，console.log 递归遍历到了 FiberNode，其本质是一个双向链表，最终造成无限递归死循环**。\n\n我们可以比较方便的随便找个 React 项目验证这一点：\n\n![React Fiber](/img/chrome_fiber.png)\n\n## detached dom 过多导致页面内存持续上涨\n\n另外笔者接触到的一个比较严重的问题，是之前某项目的一个页面，随着使用时间增加，页面的内存使用量快速持续增加，最终导致卡顿和崩溃。\n\n这个问题的定位过程也比较艰辛，最终发现其中的一个主要原因是 **console.log 打印了 dom 节点，导致 detached dom 持续增多并且无法被回收，最终导致严重问题**。\n\n关于 detached dom 的问题我们可以使用[通过压缩合成层优化性能](http://niexiaotao.cn/2021/09/04/%E9%80%9A%E8%BF%87%E5%8E%8B%E7%BC%A9%E5%90%88%E6%88%90%E5%B1%82%E4%BC%98%E5%8C%96%E6%80%A7%E8%83%BD/) 这里的 demo，简单修改：\n\n将原本需要挂载到 dom 的节点直接进行打印：\n\n```\nfor(let i = 0; i < totalListCount; i += 1) {\n  let fragment = document.createElement(\"div\");\n  fragment.classList.add(\"li\");\n  fragment.innerHTML = `<p>this is the ${i} element</p>`;\n  console.log(fragment);\n  // list.appendChild(fragment);\n}\n```\n\n我们很容易看到这样就产生了 500 个 detach 节点，并且在页面的生命周期内，无法进行释放：\n\n![detach console](/img/chrome_detach_console.png)\n\n## 总结\n\n实际上，在生产环境使用 console.log 造成的问题远不止上面的两例，而且这类问题通常排查起来都会比较艰难，因此，建议大家落实在生产环境禁用 console。\n\n\n","tags":["javascript","性能优化"]},{"title":"通过优化合成层优化性能","url":"/2021/09/04/通过压缩合成层优化性能/","content":"\n## 背景\n\nWeb 性能优化特别是长列表滚动优化是一个老生常谈的问题，一般我们的思路是通过虚拟滚动、GPU 加速、fragment 复用等方式优化性能。\n\n在本篇文章中，主要介绍一个压缩合成层的思路来进行性能优化，关于合成层的文章网上也有一些（附录部分有列出），不过大部分文章会对合成层创建的原因进行冗长的介绍，本文会跳过这些部分。原因是我们通过 devTools 可以比较方便的针对具体情况分析创建合成层的原因，另外一个原因是 blink 已经把创建合成层的原因写到了一个文件中（[传送门](https://source.chromium.org/chromium/chromium/src/+/master:third_party/blink/renderer/platform/graphics/compositing_reasons.cc)），我们直接参考就行，也没有必要去全都记住。\n\n\n## 合成层是什么\n\n对于 blink 渲染引擎的渲染流程，大致可以分为以下几个阶段：\n\n```\nDom Tree -> Layout Object -> Paint Layer -> Graphics Layers Tree -> Paint\n```\n\n我们对以上过程进行一个简述：\n\n* Dom Tree 到 Render Tree 这个过程，基本是一一对应的，除了一些 display:none 的元素。\n* Layout Object 会按照一定条件创建 Paint Layer。\n* Paint Layer 在到 Graphics Layer 的过程中，会创建合成层（Composite Layer），会对应独立的 Graphics Layer。\n* Graphics Layer 会把结果渲染到纹理，最终通过 Chrome 的渲染层以及系统进行上屏。\n\n实际上我们可以发现，合成层的多少会比较影响我们的渲染性能，合成层比较多的情况下，当我们对页面进行交互（比如滚动），触发重新渲染，就会有卡顿的风险。\n\n## 分析合成层\n\nChrome 的 DevTools 工具可以让我们比较方便地进行合成层分析，例如我们通过一个 demo 来进行分析：\n\n![合成层示例](/img/composite_reason.png)\n\n在上图中，我们会发现这个 demo 的合成层比较多，我们点进去可以查看到是因为 overflow 导致创建了新的合成层。\n\n也就是说，对该 demo 而言我们可以尝试在这些 Demo 中去掉或者修改 overflow 的相关设置，从而进行合成层优化。\n\n## 优化合成层\n\n我们尝试去掉 `overflow: scroll;`。（ Demo 源代码会在本文最后给出）\n\n然后我们设置页面的列表元素为 500 个，通过模拟页面持续滚动，来检查去掉前后的性能。\n\n去掉前，cpu 保持在 50%+，这实际上已经是一个比较高的数值了：\n\n![合成层cpu](/img/composite_cpu_1.png)\n\n去掉后，cpu 保持在 2% 左右：\n\n![去除合成层cpu](/img/composite_cpu_2.png)\n\n我们可以看到，优化后有巨大的性能提升，这种量级的性能提升，会远超虚拟滚动等方案（其实我个人是不建议采用虚拟滚动的，非常难维护，而且你很难做到浏览器原生滚动的丝滑水准）。\n\n## 附录\n\n示例代码：\n\n```\n<!DOCTYPE html>\n<html lang=\"zh-CN\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0,minimal-ui:ios\">\n  <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n  <title>Document</title>\n  <style >\n    .container {\n      width: 100vw;\n      height: 100vh;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n    }\n    .list {\n      width: 500px;\n      height: 90vh;\n      overflow: scroll;\n    }\n    .li {\n      width: 100%;\n      height: 50px;\n      border-bottom: 2px;\n      border-style: solid;\n      border-color: grey;\n      /* overflow: scroll; */\n    }\n  </style>\n</head>\n<body>\n  <div class=\"container\">\n    <div class=\"list\">\n    </div>\n  </div>\n</body>\n<script>\n  const totalListCount = 500;\n  const list = document.querySelector(\".list\");\n\n  for(let i = 0; i < totalListCount; i += 1) {\n    let fragment = document.createElement(\"div\");\n    fragment.classList.add(\"li\");\n    fragment.innerHTML = `<p>this is the ${i} element</p>`;\n    list.appendChild(fragment);\n  }\n  let curr = 0;\n  const renderScroll = function () {\n    curr += 5;\n    if (curr >= totalListCount) curr = 0;\n    list.children[curr].scrollIntoView();\n    window.requestAnimationFrame(renderScroll)\n  };\n  renderScroll();\n</script>\n</html>\n```\n\n参考：\n\n- Compositing Layers: https://zhuanlan.zhihu.com/p/88288584\n- 前端性能优化之 Composite: https://segmentfault.com/a/1190000015917498","tags":["性能优化"]},{"title":"了解 StackOverFlow 上面最受欢迎的语言 Rust","url":"/2021/09/02/了解 StackOverFlow 上面最受欢迎的语言 Rust/","content":"\n本文希望从宏观角度，来介绍和分析 Rust 语言。\n\nRust 是一门**专注安全**的现代系统编程语言，发布于 2015 年。\n\n自从 2015 年发布起，Rust 就一直是 StackOverFlow 上面最受欢迎的语言，而且和第二名还能拉开不小的差距，例如最近两年的统计数据：\n\n[2020](https://insights.stackoverflow.com/survey/2020#most-loved-dreaded-and-wanted):\n![2020_rust](/img/rust_2020.png)\n\n[2021](https://insights.stackoverflow.com/survey/2021#most-loved-dreaded-and-wanted-language-love-dread):\n![2021_rust](/img/rust_2021.png)\n\n接下来笔者通过性能、可靠性、生产力、面向前端友好等几个维度来介绍 Rust，之后会对 Rust 的部分重点语言特性进行介绍。\n\n## 性能\n\n首先作为一种编译型语言，可以直接将编译产物作为二进制可执行文件部署，无需随程序一起分发解释器和大量的依赖项，因此相对于 Python、Ruby 以及 Javascript 等解释型语言，会效率更高。\n\n同时，Rust 提供了大量的零成本抽象（如泛型、async/await、迭代和闭包等），在保证开发效率的同时避免了运行时开销。\n\n一般来说，Rust 的性能和 C/C++ 相似，无虚拟机，无 GC，运行时仅依赖 libc，**在需要高性能场景中使用已经足够**。\n\n## 可靠性\n\n在一个 c++ 项目中，我们经常会遇到各类 crash，处理这些 crash 通常会花费大量的人力。\n\n而在一个 Rust 项目中，如果规范使用基本上在编译阶段就可以避免几乎所有的 crash，也就是说，**使用 Rust 的项目只要编译通过，就只有逻辑错误，不会再有 crash**（自身使用了 unsafe 除外）。\n\nRust 之所以能做到这一点，得益于其设计的所有权、生命周期、Option 机制以及智能指针等，这一点我们在下文的语言特性中也会更详细地分开介绍。\n\n> 实际上，笔者现在负责的项目中 Rust 和 C++ 大约各有一半的代码，在这其中 Rust 几乎没有出现过 crash，而 c++ 基本上每双周（一个迭代）都会新增一些种类的 crash。\n\n## 生产力\n\n### 代码开发效率\n\n得益于 Rust 的大量零成本抽象，以及 Rust 提供的高度灵活的宏机制，我们的代码开发效率还是比较高的。就笔者的体验而言，使用 Rust 完成功能的开发效率略低于 Typescript，但是远高于 c++（和 Typescript 相比，Rust 通常会需要花费额外的一些时间来解决编译问题，但是换来的是高性能和稳定性，我认为这是值得的）。\n\n另外随着 Rust 语言的逐渐成熟，配套的 IDE 和编辑器（Clion、VSCode）也逐渐成熟，日常代码开发提示、以及代码调试等都非常方便。\n\n### 包管理系统\n\n另外值得一提的是，Rust 的包管理系统非常强大，这一点我认为 Rust 也参考了 npm，包管理系统的使用体验也和 npm 比较接近，新增一个依赖，只需要在 Cargo.toml 配置文件中新增一行配置即可。方便的包管理系统，让我们可以方便地复用[社区各类优秀的资源](https://crates.io/)。\n\n相对来说，c++ 这类老牌语言的包分发和管理就会麻烦很多，甚至在一个项目内也会比较麻烦。\n\n### 现有资源的复用\n\n这一点主要是 Rust 和 C/C++ 的互相调用，Rust 支持调用 C 接口和封装成 C 接口被其他语言所调用，因此对于现有的项目，如果可以提供一层 C 接口的封装，就会比较方便地被 Rust 直接调用。\n\n## 面向前端友好\n\n我认为 Rust 面向前端友好主要体现在两个方面：\n\n### 虽然学习路线陡峭，但和 Typescript 相近点较多\n\n很多人劝退 Rust 理由之一是其学习曲线陡峭，但是实际上前端同学学习 Rust 会比学习 C++ 容易的多，一方面，Rust 的很多机制（async/await、类的设计、包管理）等都和 Typescript 有相似之处，另外一方面写 Rust 只要编译能够通过基本上能够保证你代码质量的下限，也就是说基本上可以上线生产环境。而 C++ 新手写出来的代码通常会有各种 crash 隐患，而且排查通常较为困难，导致容易背锅，这一点来说对新手非常不友好。\n\n### 面向 WASM 友好\n\n对于 WebAssembly，笔者并不推荐 AssemblyScript，因为其虽然是 “Typescript”，但是使用起来和 Typescript 相差太多，而且无法完全直接使用 JavaScript 的第三方库，调试等也并不是很方便。\n\n而剩余的几类语言中（Rust、C++、Kotin、Golang），相对来说 Rust 和 C++ 的 wasm 编译都较为成熟，Rust 更是在设计之初即考虑支持 WebAssembly 并且将其作为一个主要亮点，被 Rust 官方团队直接维护（包含了勤劳的 Alex Crichton，其也是 tokio 的作者）。因此我们使用 Rust 编译 WebAssembly 非常方便，并且可以直接使用大多数第三方 Rust 库，使用体验和 Rust Native 开发基本上没有差异。\n\n目前笔者的项目中，有一部分模块即使用了 Rust + WebAssembly，同时支持了 Windows/Mac/iOS/Android/Web 五种平台，并且几乎都做到了最高性能。\n\n> 当然不得不承认，Rust 编译 WebAssembly 在使用到 C++ 的资源时也并不是十分方便，Rust 的 WASM 编译器和 Emscripten 也有诸多差异，适配起来会比较头疼，如果现有项目主要是 C++，还是建议直接使用 Emscripten。\n\n## 重点语言特性\n\nRust 拥有大多现代语言具备的特性，比如 RAII、动态数据类型等，另外还有不少设计是 Rust 中独有的，下面我们对一些 Rust 中比较独特的语言特性进行一些介绍。\n\n### 所有权\n\nRust 的所有权机制，即一个值同一个时刻只能被一个变量所引用，我们来看一个简单的例子：\n\n```\nlet a = \"hello\".to_string();\nlet b = a;\nprintln!(\"a: {:?}\", a); // 提示报错：value borrowed here after move\n```\n\n因为我们把 a 对应的数据的所有权给到了 b，也就是说 a 不再拥有对应的数据的所有权，因此也无法访问，**这种机制保证了数据安全，能够有效避免悬垂指针的发生**。\n\n当然，对于实现了 Copy（一般来说，都是存储在栈上面的简单数据类型），在赋值阶段会自动拷贝，或者对于没有实现 Copy，但是实现了 Clone（需要主动调用）的类型我们显式调用 Clone，都可以编译通过，这些设计给我们的日常开发中带来了极大的便利：\n\n```\nlet a: i32 = 1024;\nlet b = a;\nprintln!(\"a: {:?}\", a); // pass\n\nlet a = \"hello\".to_string();\nlet b = a.clone();\nprintln!(\"a: {:?}\", a); // pass\n```\n### 智能指针\n\n在 Rust 中，一般情况下并没有空指针的概念，并不像 c++ 有 nullptr、java 有 null，Rust 中如果表示一个可空的内容只能使用 Option（有点类似 C++ 的 std::optional）。\n\n除了 Option，Rust 还封装了若干种高级指针，并对不同类型的指针的行为进行限制，以提高其安全性：\n\n* Box：用于在堆上存储数据，**单一所有权**（即一般情况下不会存在一个指针乱飞的情况），可以用于封装在编译时未知大小的类型。\n* Rc：引用计数指针，不支持多线程\n* Arc：多线程版本的引用计数指针\n* RefCell：保持内部可变性的指针，即我们如果希望多个所有者共同拥有并且都可以修改的指针，需要结合 Rc 或 Arc 加 RefCell 一起使用。‘\n\nRust 还提供了一些其他类型的智能指针，在这里不再过多介绍，虽然这里的大部分概念 c++ 也存在，但是 Rust 基本只能是强制你使用这些内容，而无法使用不安全的裸指针。\n\n### 多态\n\nRust 中的多态有基于泛型的静态派发和基于 trait 的动态派发。\n\n* 静态派发：是一种零成本抽象，在 C++ 中也有类似的概念，静态派发是通过对不同类型的调用在编译期间生成不同版本的代码来实现的，不会引入运行时开销（但请注意可能会造成代码体积膨胀）。\n* 动态派发：有些场景下，我们没有办法在编译期间确定变量的实际类型，进而无法确定其占用内存大小，Rust 也提供了 trait 机制来实现动态派发，同时 Rust 将此类 trait 使用 dyn 进行显式指定：\n\n```\n// 动态派发：\ntrait Speak {\n    fn hello(&self);\n}\nstruct Human;\nimpl Speak for Human {\n    fn hello(&self) {\n        println!(\"hello, I am a Human\");\n    }\n}\nfn test_hello(someone: Box<dyn Speak>) {\n    someone.hello();\n}\nfn main() {\n    let human = Human {};\n    test_hello(Box::new(human));\n}\n```\n\n### 宏\n\nRust 中的宏的能力非常强大，其不同于 C/C++ 中的宏简单地按字符串替换代码，而是基于语法树进行操作，在编译阶段被展开成源代码进行嵌入。\n\n具体 Rust 中的宏也分为声明宏和过程宏，能够实现的需求非常多样，在一个大型项目中，我们可以通过宏的使用解放生产力，并且使代码更清晰。不过，宏这一部分的具体学习相对比较复杂，在这里便不再进行举例。\n\n---\n\n综合来说，Rust 作为一个比较先进的语言，没有太多的历史包袱，从各个语言中吸收了不少的优质特性，比较适合我们在新项目的技术选型中作为一个考虑因素。\n\n## 如何开始学习 rust\n\n### 起步\n\nrust 本身的文档和学习资料官方提供的比较全面，一个必读的内容是[“The Rust Programming Language”](https://doc.rust-lang.org/book/)。\n\n不过，rust 的官方文档读起来可能略有枯燥，这个时候我建议可以先开始读*张汉东*的《Rust 编程之道》，相对来说更加深入浅出，不过还是后续还是建议读一遍文档。\n\n### 项目应用\n\n在我们将上述内容读完之后（如果每天两个小时的话，大约需要一个月的时间），具备了一定的 Rust 语言基础，可能需要思考下如何在现有项目中落地，我个人的一个建议是：\n\n* 如果现有项目是偏 web 的，可以先考虑通过 wasm 来落地，相对来说上手成本很低，我之前也对[入门 Rust 开发 WebAssembly](https://zhuanlan.zhihu.com/p/104299612)有所总结。\n* 如果现有项目是偏 native 的，可以考虑将部分新模块、或者 crash 告警比较多的逻辑部分，使用 rust 实现并且通过 C FFI 和现有模块进行交互，渐进式引入 Rust 技术栈。\n\n","tags":["Rust"]},{"title":"一些性能相关的 JavaScript 代码编写建议规范","url":"/2021/08/29/一些性能相关的 JavaScript 代码编写建议规范/","content":"\n本文对一些日常编写 JavaScript 的过程中，一些有助于提高代码性能的规范进行罗列。\n\n> 本文比较零碎，不作为规范提议，仅作为交流参考。\n\n### 1. 使用解构赋值，减少中间变量。\n\n对于一些比如变量替换的场景，我们使用解构赋值，可以省略中间变量，整体代码也会更加清晰。\n\n```\nlet a = 3;\nlet b = 4;\n[b, a] = [a, b];\n```\n\n### 2. 通过条件判断提前返回\n\n这里主要是提醒大家如何写好 if 语句。\n\n实际上， 在编写复杂的 if 语句之前，我们应该考虑是否可以**逻辑外化**：\n\n即尽可能的将代码的复杂逻辑向外推，例如抽离成多个函数，而不是在程序里面进行过多判断。有一种比较典型的不合理的重用是把大量的逻辑都堆叠到一个函数里面，然后提供一个很复杂的功能。我认为更好的做法应当是分离成更多的模块。\n\n经过以上思考之后，我们可能还有一些 if 语句，一般的原则是：\n\n* if 语句先简单，后复杂。\n* if 语句，可以提前返回即提前返回，减少复杂的嵌套。\n\n```\n// nice:\nif (condition1) {\n  // do something\n  return;\n}\n\nif (condition2) {\n  // do something\n  return;\n}\n\nother_function();\n\n// bad:\nif (condition1) {\n  // do something\n} else {\n  if (condition2) {\n    // do something\n  } else {\n    other_function();\n  }\n}\n```\n\n### 3. 尽量避免在循环体内包裹函数表达式\n\n函数表达式会生成对应的函数对象，如果我们在循环体内去做这个事情，很可能会造成额外的浪费。\n\n```\n// nice:\nfunction callback() {\n}\n\nconst len = nodelist.length;\nfor(let i = 0; i < len; i += 1) {\n  addListener(nodelist[i], callback);\n}\n\n// bad:\nfor(let i = 0; i < nodelist.length; i += 1) {\n  addListener(nodelist[i], function() {});\n}\n```\n\n### 4. 对循环体内的不变值，在循环体外使用缓存\n\n这一条其实是对上一条的补充，实际上是同样的原理，即希望我们在循环体内尽量保持逻辑的简单，减少重复的 cpu 时间和内存的消耗。\n\n### 5. 清空数组使用 .length = 0\n\n这样写可以方便我们清空一个 const 数组。\n\n```\nconst a = [1,2,3,4];\n// 如果使用 a = [] 会报错\na.length = 0;\n```\n\n### 6. 不得为了编写方便，将并行的 io 串行化\n\n虽然现在 JavaScript 有了 async/await，但是我发现很多同学会对此滥用，一个很常见的清空就是将可以并行的操作串行化了:\n\n```\nlet res1 = await process1();\nlet res2 = await process2();\nnext(res1, res2);\n```\n\n这个时候，虽然写代码方便，但是这样写是不可取的，Promise 提供了若干的方便我们处理并行任务的[方法](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Promise#)，我认为这些都是必须要了解的。\n\n\n### 7. 禁止直接使用 eval\n\neval 的安全性非常差，事实上有很多已知的 xss 等漏洞都和 eval 有关，所以我们在实际场景中避免使用 eval。\n\n如下为一个例子，使用了 eval 函数，由于其执行代码的作用域为本地作用域，所以对我们的本地变量进行了修改并且可以生效：\n\n```\nlet tip = \"请重新登录\"\nlet otherCode = `tip = \"请前往 xxx.com 重新登录\"`\neval(otherCode);\n```\n\n一些取代方式：\n\n我们可以使用 `new Function` 的方式来代替 eval，这样至少可以进行作用域的隔离，相对会安全一些（但是请注意其仍然会可能影响到全局变量）。\n\n### 8. 浏览器环境中，尽量避免使用 document.all、document.querySelectorAll\n\n类似的 all 相关操作都要避免使用，由于我们很难控制随着项目发展内容会有多少，所以我们最好一开始就不要留下随着项目内容增加性能越来越差的隐患。\n\n### 9. 获取元素的样式，尽量使用 getComputedStyle 或 currentStyle\n\n通过 style 只能获得内联定义或通过 JavaScript 直接定义的样式，通过 CSS class 设置的样式无法直接获取。\n\n### 10. 尽可能通过为元素添加预定义的 ClassName 来改变元素样式，避免直接操作 style 进行设置。\n\n直接操作 style，会比较混乱，而且有的时候还会忘记写单位，导致实际上不管用。\n\n","tags":["javascript"]},{"title":"如何让你的精力更多的用于提高技术深度","url":"/2021/07/26/如何让你的精力更多的用于提高技术深度/","content":"\n[知乎版本](https://zhuanlan.zhihu.com/p/395177123)\n\n题目所述，就是我最近很久一段时间都在用来思考的问题。\n\n先说下个人的背景，目前已经毕业三年，第一年主要做前端开发，大约在两年前，我的主要精力从前端转向了 Rust，而后又开始在公司参与开发 c++。\n\n在这三年里面，自己持续面临着一个问题，这个问题就是，如何从一个繁忙而重复的工作中，持续提升自己的技术深度。\n\n因为我发现，当在一个公司久了以后，随着参与的业务增多，问题和 OnCall 也随之增多，另外随着你对业务的熟悉，会有越来越多的新同学向你问问题。处理这些问题会占据越来越多的精力。当然，如果你比较“幸运”中途业务黄掉或架构彻底变化了，你去参与新的项目，有可能能获得一次接近重新开始的机会，但大多数时候，你可能都没有这么幸运。\n\n当这些问题处理的久了以后，你会发现甚至连完成工作都需要加班来解决，就更没有时间来进行技术的提升了，长此以往，焦虑感便倍增。\n\n不过，最近我在思考这些问题的过程中，也渐渐总结了一些缓解的办法，接下来便和大家进行分享。\n\n**这里的核心点在于，减少犯错误的机会，提高处理问题的效率，释放出自己的更多时间**\n\n## 1. 提高对代码的要求，写更好的代码\n\n我最近处理的众多问题，粗略估算，有大约 1/3 都是由于开发者代码水平不足带来的技术债务（即代码逻辑错误、边界情况未考虑、性能与稳定性不足等）。\n\n我这里主要针对的是 PC 客户端，还有很多问题和特殊机器、其他模块干扰项、硬件驱动等关系密切，如果是纯前端项目，这个比例只会更高。\n\n因为写代码的时候，并没有采用最合理的方式，导致有出现问题的隐患，如果你的问题出现的概率比较高，大概率会比较幸运地较早发现，但如果出现的概率低，甚至灰度阶段都没有暴露，那么当初几行代码的问题，会让自己之后花加倍的时间来去处理，甚至还可能面临更多后果。\n\n那么，如何让自己写出更好的代码呢，我认为可以做到以下几点：\n\n* **请熟读文档**，比如如果是在开发 Vue 项目，那么请至少把 Vue 的文档看一遍，React 同理，这样你会更加清楚，框架到底提供了那些能力，什么时候使用更合适的 API 来完成一个目标。\n* 注重注释，对于一些特殊处理的情况，注释是很有必要的，最好附上文档，否则可能时间久了，自己都不知道为什么这样去处理，会让修复问题花费更多的时间。\n* 除非迫不得已，不要提交带有已知优化项的代码，例如重复代码并没有完全处理、代码在某些情况还可能造成问题。时间允许的情况下，一步到位，通常比分两次到位能节约更多的时间，至少能节约一次测试的时间，另外大脑的上下文切换还有开销。\n* CI/CD 的建设，保证合并的代码是能够编译的。\n* 对于前端来说，全部采用 Typescript，使用 ESLint 约束代码，**禁止**直接使用 JavaScript。\n* 团队需要建立 Review 机制，并且对 Review 过程负责。对于别人提交 Review 的代码至少需要通读一遍，避免基本的错误。\n\n## 2. 日志是语言的另一面，也很能体现代码水平\n\n这里的日志，指的是在用户使用过程中，实时上传的的或者离线的日志。\n\n这里单独提一点日志，是因为在实际中，我们大约有一半时间在写代码，而另外一半时间在查问题，那么为什么就不能好好写日志呢？\n\n“日志不足/没打日志，需要加日志进一步定位”。\n\n不知道你在 OnCall 的过程中，是否遇到过此类回复，当然并不能说每次这样的问题都是开发者水平不足导致日志不全，但的确有很多情况是我们可以提前规避的。\n\n那么一个好的日志应该是什么样的呢？\n\n1. 前提：废话不要多，能简写就简写，这是因为一般日志都是存在用户本地的，日志量比较大的情况下会影响用户的硬盘占用，当然日志本身的打印也是消耗 CPU 的。\n2. 关键路径的日志要有，可能出问题的地方不要存在侥幸心理，把日志打全，特别是**不同负责模块之间衔接的日志，一定打全**，这样之后甩锅的时候有实锤也会方便一点。\n3. 关键日志需要有关键字，方便后面自动化分析，毕竟，对于一个比较完善的项目而言，机器人分析日志甚至比人分析更为靠谱。\n4. 日志也需要**向前兼容**，最好不要对以前的日志进行改动，这点我们可能通常会忽略，如果没有必要，建议不要对日志进行大的变动，防止自动化工具和其他分析日志的同学不知情。\n\n什么？你说你们团队还没有日志系统？\n\n那么第一件事，就是要有一个完善的离线日志回捞系统或在线日志系统。\n\n## 3. 打破边界有助于开阔视野，但是是否深入需要慎重决定\n\n虽然有的时候，员工打破边界对于公司来书并不是一个好事情，但大多数情况来说，对个人还是会有所帮助的。\n\n> 为什么说不是一个好事情呢，比如一个客户端的同学，去做 c++ 了，这个时候应该鼓励还是反对呢。实际上这个时候，他除了仅存的业务熟悉度和一些通用的编程能力，c++ 的能力也许就只有应届生的水平，如果从新招聘可能连初试都过不了。公司就必须要承担因为他的编程能力不熟练带来的效率损失，甚至因为更容易引发问题造成更大的损失。\n\n为什么说，对于个人来说是一个好事情呢，这个主要体现在以下几个方面：\n\n* 在公司中大多数情况下都是多个语言的开发者相互配合的，而当你同时参与了你上游或者下游的工作，你会发现沟通会更加顺畅了，甚至自己也拥有了简单的处理需求和问题的能力，底气会高很多。\n* 在你学习多个语言的过程中你会发现一些精华的部分，比如通用的框架设计方法、模块组织方法等各个语言都是通用的，甚至有些代码你直接翻译过来就可以直接用了，这也可以让你更深刻地了解到哪些是编程的精髓。\n\n当然，有的时候如果你跨界参与的太多，例如本身是一个资深的前端开发者，当你跨界参与了 c++ 开发，你会发现短时间内你的前端水平是在下降的，而 c++ 水平也没有达到独立承担工作的程度，这短时间内你的市场价值其实是有所下降的，这也是你需要慎重考虑到底要参与多少的原因之一。\n\n\n## 4. 复杂系统的初始架构设计，可以作为一个最后兜底\n\n实际上，复杂的系统大多一开始都不复杂，但是如何正确地预判系统的走向，设计出可以沿用很久的基础骨架、约束性强却扩展型足够的组件系统（即使后来来的人水平差也不至于写出太难维护的代码），以及和外界其他系统进行灵活的配合，是对水平有一定的考验的。\n\n这里我以某视频会议 App 举例，其最开始只有视频+音频的简单能力，在此基础上，团队负责人设计并编写了基于 Typescript 的核心状态机、按照 minor repo 划分了主要模块，设计了 Store 状态存储，设计了一套 API 注入方式可以注入系统外的 API 等等。\n\n这套架构沿用了三年，核心代码基本没有发生变化，功能上却新增了共享屏幕、共享网页、聊天/表情、标注/白板、远程控制、字幕/录制/翻译、日程会议、面试等若干重要的模块。\n\n虽然实际上，随着后面的同学的增多，以及最初核心开发者的离职，开发人员已经几乎换了一批，但是这套代码和架构基本上没发生太多变化，也一直支撑着若干项目。\n\n（p.s. 据说最开始参与设计的同学吐槽后面的维护有点渐渐跑题，但是整体还是可用性比较高的）。\n\n如果没有一定水平，想必业务框架早就随着业务的变更重构过多次了，肯定会带来巨大的人力浪费。\n\n## 5. 持续练习，持续关注行业动态\n\n最后一点，持续学习，大概是程序员的宿命吧。\n\n这里其实不用多说了，但是想提一点，其实有的时候如果你发现主动的持续学习会比较难的情况下，可以选择一种半被动的方式。\n\n比如，每周给自己定日程参与 leetcode 周赛，你把它当作自己工作的无可推脱的一部分，这样持续几次，你就会慢慢习惯这个过程。\n\n---\n\n以上共勉。\n\n\n\n","tags":["前端综合"]},{"title":"Deno 是如何运行 TypeScript 的？","url":"/2021/01/31/Deno 是如何运行 TypeScript 的/","content":"\n> Deno，一个 JavaScript/TypeScript 运行时。本文并不会从 JavaScript 的角度来去介绍如何使用 Deno，而是试图从框架实现的角度，来整体对 Deno 项目本身的开发实现进行解读，并且通过分析其运行 TypeScript 的原理，来对其进行一个入门的剖析。\n\n[原文链接已经转移至这里](https://zhuanlan.zhihu.com/p/348379605)","tags":["前端框架"]},{"title":"使用 Rust WebAssembly 0拷贝进行计算加速","url":"/2020/06/26/使用RustWebAssembly0拷贝进行计算加速/","content":"\ndemo: https://github.com/aircloud/rust-wasm-demo  \n\n其他资料：[入门 Rust 开发 WebAssembly](https://zhuanlan.zhihu.com/p/104299612)\n\n一般来说，使用 WebAssembly 能够在一定程度上提高性能，不过有的时候我们也许会发现，使用 WebAssembly 之后，有的时候我们不仅发现性能没有提升，反而下降了许多甚至数倍，实际上这是因为，使用 WebAssembly 需要非常谨慎，有很多细节都会大幅度影响性能，比如：\n\n* 我们编译采用的是 debug 还是 release 方式。\n* 最后编译的结果是否采用了不同级别的优化，如果使用了 `opt-level = 's'` 那么通常速度也会下降很多。\n* 是否在 JS 和 rust 之间存在大量的数据拷贝，因为很多代码是工具链生成的，也许有的时候我们会忽视这一点。\n\n本文针对以上等一些问题特别是第三点，给出一个 wasm 优化的参考方案，并给出示例代码。\n\n### 编译优化\n\n我们在优化数据拷贝之前，对于编译我们可以做一些前置的简单的工作。\n\n* 检查 Cargo.toml 脚本中 `[profile.release]` 中的 `opt-level` 选项，确认我们所使用的值：\n\n```\nThis flag controls the optimization level.\n\n0: no optimizations, also turns on cfg(debug_assertions) (the default).\n1: basic optimizations.\n2: some optimizations.\n3: all optimizations.\ns: optimize for binary size.\nz: optimize for binary size, but also turn off loop vectorization.\nNote: The -O flag is an alias for -C opt-level=2.\n\nThe default is 0.\n```\n\n如果我们使用了 ‘s’ 或者 'z'，那么通常会牺牲一部分性能（对于 demo 而言，使用 'z'， wasm 的性能也只有 js 的 20%），因为其主要是对体积进行一定的优化，所以如果优化前的体积我们可以接受的话，通常不需要这样的优化。\n\n在以上的前提下，我们使用 `--release` 的方式编译，通常就可以了。\n\n### 减少拷贝\n\n在这之前，我们需要有一个认知：\n\n**通过 rust 工具链编译的 wasm 代码，所有参数传入都是需要拷贝一次的，包括我们传入 ArrayBuffer 等 Buffer 类型的参数。**这是由于 wasm 只能访问自己的线性内存，而这个拷贝，通常是我们在处理大规模计算的一个坎，有的时候虽然 wasm 计算快一点，但是拷贝的消耗还是比较大的，加之 js 有若干 v8 优化的加持，可能和 wasm 也相差不多。\n\n所以我们要把计算移植到 wasm 中的话，首先要解决的就是大规模数据拷贝的问题。\n\n这里的一般思路为：\n\n1. wasm 分配内存：调用 wasm 的方法，在 wasm 内存中分配空间，返回指针位置\n2. js 写入数据：js 端在 wasm 的 memory arraybuffer 上，按指针位置和数据量建立 view，把数据写入\n3. wasm 计算：调用 wasm 方法完成计算， 返回计算好的批量结果的指针位置和大小\n4. js 读取数据：js 端在 wasm 的 memory arraybuffer上，按指针位置和数据量建立 view，把数据读出\n\n接下来，我们通过一个 demo 来完成以上几点，demo 的主要功能为：\n\n* 初始化一个 ImageData，内容随机。\n* 分别使用 js 和 WebAssembly 进行高斯模糊计算，并计算二者的时间，进行对比。\n\n这里的 demo 只是辅助进行验证改方案的可行性并且给出一个示例，并不作为一个标准的 benchmark 去对比 js 和 WebAssembly 的性能，同时，也并没有 UI 展示，计算结果输出在控制台中。\n\n最终笔者运行的结果为，js 比 WebAssembly 慢 30% 左右。\n\n#### 1. wasm 分配内存\n\n这部分的通用做法，即我们在 wasm 的 rust 中分配一个数组（Vec），然后把其指针传递给 js：\n\n```\n// rust：\n#[wasm_bindgen]\npub fn new_buffer(key: String, len: usize) -> *const u8 {\n  // GlobalBufferStorage 是一个 lazy_static\n  let mut global_buffer_storage = GlobalBufferStorage.lock().unwrap();\n  let mut buffer = vec![255; len];\n  let ptr = buffer.as_ptr();\n  global_buffer_storage.buffer_map.insert(key, buffer);\n  ptr\n}\n```\n\n为了后续方便寻找到这段数据，我们可以使用一个 key 将这个 Vec 联系起来，并且在 Rust 中放入全局（可以使用 lazy_static!，因为这种类型的数据没有办法直接定义在全局），之后通过 key 来查找数据。\n\n在 js 中，我们就可以建立各种 TypedArray 对其进行操作：\n\n```\nconst ptr = this.wasm!.new_buffer(key, len);\nconst u8Arr = new Uint8ClampedArray(this.wasm!.get_wasm_buffer(), ptr, len);\n```\n\n**这个时候，我们在 js 或 rust 任何一侧改了这个数据之后，都可以在另外一侧访问到。**\n\n实际上，在 js 侧的比如 [ImageData](https://developer.mozilla.org/en-US/docs/Web/API/ImageData/ImageData) 等一些对象中，也支持我们传递一个 TypedArray 进行初始化，这让我们在比如 canvas 等应用场景下，使用 wasm 分配的内存更为方便。\n\n```\nconst imageData = new ImageData(u8Arr, width, height);\n```\n\n#### 2. js 写入数据\n\n如果我们需要在 js 侧写入数据，实际上这个时候我们得到的 TypedArray 已经和直接使用 js new 的 TypedArray 在使用上没有差别，可以正常按照数组的方式进行数据写入。\n\n不过，这里需要注意的是，js 写入通过 wasm 分配内存建立的 TypedArray，有些场景下在一定程度上速度要慢于直接使用 js new 的 TypedArray（不过在笔者的测试数据中，wasm 分配的方式反而是更快的），所以如果我们是一个高频的数据写入的场景，比如帧数据等，这个时候最好进行一次对比测试。\n\n\n#### 3. wasm 计算\n\n当我们真正需要进行计算的时候，我们可以调用 wasm 的计算函数，并且传入上文中定义的 key，这样 wasm 的 rust 函数可以直接找到这段数据，这里我们的 demo 为一段计算卷积的函数：\n\n```\n#[wasm_bindgen]\npub fn convolution(key: String, width: usize, height: usize, kernel: Vec<i32>) {\n  let mut global_buffer_storage = GlobalBufferStorage.lock().unwrap();\n  let kernel_length = kernel.iter().sum::<i32>() as i32;\n  if let Some(buffer) = global_buffer_storage.buffer_map.get_mut(&key) {\n    for i in 1..width-1 {\n      for j in 1..height-1 {\n        let mut newR: i32 = 0;\n        let mut newG: i32 = 0;\n        let mut newB: i32 = 0;\n        for x in 0..3 { // 取前后左右共9个格子\n          for y in 0..3 {\n            newR += buffer[width * (j + y - 1) * 4 + (i + x - 1) * 4 + 0] as i32 * kernel[y * 3 + x] / kernel_length;\n            newG += buffer[width * (j + y - 1) * 4 + (i + x - 1) * 4 + 1] as i32 * kernel[y * 3 + x] / kernel_length;\n            newB += buffer[width * (j + y - 1) * 4 + (i + x - 1) * 4 + 2] as i32 * kernel[y * 3 + x] / kernel_length;\n          }\n        }\n        buffer[width * j * 4 + i * 4 + 0] = newR as u8;\n        buffer[width * j * 4 + i * 4 + 1] = newG as u8;\n        buffer[width * j * 4 + i * 4 + 2] = newB as u8;\n      }\n    }\n  } else {\n    return ();\n  }\n}\n```\n\n因为这段函数对应操作的内存数据实际上已经在 wasm 和 js 之间共享了，所以也是不需要返回值的，等计算完成后 js 直接去读之前建立的 TypedArray，甚至直接使用通过 TypedArray 创建的 ImageData，进行绘制上屏等后续操作。\n\n#### 4. js 读取数据\n\n在 demo 中，我们可以直接通过 `CanvasRenderingContext2D.putImageData()` 传入之前获取的 imageData，绘制上屏。\n\n### 其他方案\n\n实际上，我们如果目的是加速 js 计算，不仅仅有 WebAssembly 这一个方案可以选择，如果我们的环境中拥有可以访问 Node 的能力或者可以访问原生模块的能力（比如，我们的应用运行在 electron 环境，或者是一些移动客户端），也可以采用比如 addon 的方式来运行我们的计算部分，相比于 wasm，这部分的优缺点在于：\n\n优点：\n\n* 通常可以更好的控制优化，甚至做到汇编级别的优化定制，性能提升空间更高（同样也可能会面临数据拷贝的问题，也需要一定方式减少拷贝）。\n* 在重 addon 的环境下（例如，其他大量功能也依赖 addon），可以更好的处理函数调用关系、依赖库使用等，一定程度上减少体积和增加开发的便捷性，而 wasm 会被编译成一个独立的二进制文件，处于沙盒环境中，无法直接调用其他的动态库。\n\n缺点：\n\n* 无法做到像 wasm 一样跨平台，并且可以同时运行在网页、桌面环境、移动端等任何 Webview 存在的环境中。\n\n不过总之，如果使用得当，二者的性能都是可以优于原生的 js，都可以作为优化方案考虑。\n","tags":["Rust"]},{"title":"使用 OpenCV 实现简单的人脸识别程序","url":"/2019/09/10/使用OpenCV实现简单的人脸识别程序/","content":"\n本问就 Mac 系统安装 OpenCV 以及实现一个简单的人脸识别程序进行记录。\n\n### 安装 OpenCV\n\n实际上，OpenCV 的安装方式比较多，这里为了避免一些第三方安装的问题，我们采用源代码方式安装。\n\n安全前请确保本机已经安装了 CMake 和 Xcode。\n\n我们去[ OpenCV 的网站](https://opencv.org/releases/) 下载源代码，选择 Release -> SourceCode，可以选择最新的 4.11 版本。\n\n这里以 4.1.1 版本为例，下载后我们解压到 `opencv-4.1.1`，然后进入到该目录，新建一个 release 目录用于存放我们构建好的内容，并进入到该目录：\n\n```\nmkdir release\ncd release/\n```\n\n然后我们依次执行以下命令安装：\n\n```\ncmake -G “Unix Makefiles” .. \nmake\nmake install\n```\n\n全部命令执行成功后，实际上就安装完成了，我们可以从最后的输出中看到，相关内容已经被安装到了 `/usr/local/include`、`/usr/local/lib` 等文件夹下。\n\n### 使用 Xcode 编写人脸识别程序\n\n我们可以使用 Xcode 建立一个命令行程序，这里我们还需要处理两个问题：\n\n* OpenCV 的引入\n* 摄像头权限的获取\n\n#### OpenCV 的引入\n\n对于第一点，我们在 **Build Setting** 的 **Search Paths** 中增加 Header 和 Library 的路径：\n\n![路径](/img/cv1.jpg)\n\n然后我们需要在 **Build Phases** 的 **Link Binary With Libraries** 中增加动态链接库。\n\n我们可以点击左下角加号，选择 `Add Others` 然后进入 `/usr/local/lib` 把 OpenCV 相关的库均包含进来即可。\n\n>实际上我们可以部分引入，但是由于我们是初步上手，全部引入也可以。\n\n#### 摄像头权限的获取\n\n这里如果我们直接运行我们的程序，在 macOS 最新的系统中是无法运行通过的，这里涉及到摄像头权限问题。\n\n一般来说，对于 macOS，我们需要在运行程序的目录下声明 `info.plist`, 这样程序在运行的时候系统会自动有申请权限的弹窗，对于我们测试场景下而言，我们可以这样做：\n\n* 进入我们 Product 存放的目录（注意不是项目代码目录，可以在 Products 条目右单击 `Show in Finder`）\n* 复制一个 info.plist（这里我们可以随便找一个本地安装的应用程序的 info.plist，一般右单击显示包内容即可看到）\n* 在 info.plist 中增加 `NSCameraUsageDescription`，value 即提示语，可以写比如 `摄像头权限的获取`。\n\n#### 书写并运行程序\n\n做完上述准备工作后，我们可以写我们的人脸识别程序了，这里给出一个成功运行的代码示例（参考了网上的一些例子）：\n\n```\n#include <iostream>\n#include <opencv2/opencv.hpp>\n\nusing namespace std;\nusing namespace cv;\n\nvoid capture();\n\n// 是否退出摄像头抓取线程\nstatic bool g_quit = false;\n\nint main(int argc, char** argv) {\n    capture();\n    return 0;\n}\n\nvoid capture()\n{\n    // 打开摄像头\n    cv::VideoCapture cap(0);\n    \n    // 如果打开失败，返回错误\n    if (!cap.isOpened())\n    {\n        cout<<\"Open Capture Failed\"<<endl;\n        return;\n    }\n    \n    // 人脸识别分类器\n    cv::CascadeClassifier faceCascadeClassifier(\"/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_alt2.xml\");\n    \n    // 读取 Frame ，直到退出系统\n    while (!g_quit)\n    {\n        cv::Mat frame;\n        if (!cap.read(frame))\n        {\n            // 读取失败，返回错误\n            break;\n        }\n        \n        // 进行人脸识别\n        std::vector<cv::Rect> faces;\n        faceCascadeClassifier.detectMultiScale(frame, faces);\n        // 将人脸识别结果绘制到图片上\n        for (const auto& face : faces)\n        {\n            cout<<\"Find Face\"<<endl;\n            cv::rectangle(frame,\n                          cv::Point(face.x, face.y),\n                          cv::Point(face.x + face.width, face.y + face.height),\n                          CV_RGB(255, 0, 0),\n                          2);\n        }\n        imshow(\"Display Image\", frame);\n        waitKey(100);\n    }\n}\n```\n\n这里值得注意的是，我们这里使用的人脸识别分类器是 OpenCV 安装后自带的，你本机的目录可能并不是这一个（这个路径实际上安装好 OpenCV 之后会打印在控制台）。\n\n正常情况下，以上程序可以直接编译执行。","tags":["OpenCV"]},{"title":"Rust初探:实现二叉树的增删与遍历","url":"/2019/09/07/Rust初探-实现二叉树的增删与遍历/","content":"\n### Rust 简介\n\n实际上自己接触 Rust 的时间还是很有限的，这里也不会对 Rust 进行长篇大论地介绍，简单来说，Rust 是一个性能和 c++ 相近的系统级编程语言，同时，由于其所有权与变量生命周期等机制的设计，使其相对于 c++ 来说拥有内存安全的优势，几乎不会出现诸如悬垂指针、数组越界、段错误等问题，在微软、百度、字节跳动等公司均有所使用。\n\n关于 Rust 的特性以及未来，知乎[这个问题中的一些高赞回答以及相关的评论](https://www.zhihu.com/question/30407715)，非常值得一看。\n\n本文会以二叉树这样一个具体的例子出发，来对 Rust 的一部分知识内容进行学习。\n\n### 实现二叉树数据结构\n\n#### 定义结构\n\n之前在 Javascript 等语言中，我们只要对对象有所了解，实现一个二叉树的数据结构是非常简单的事情，而在 Rust 中，可能对于新手来说仅仅是实现基本的数据结构就是一个比较脑壳疼的事情。\n\n我们一般会写出类似这样的代码：\n\n```\nstruct Tree {\n    value: i32,\n    left: Tree, // 直接使用 Tree 是不行的\n    right: Tree  \n}\n```\n\n自然不会通过 Rust 的编译检查，会报错例如：`recursive type has infinite size`，不过其同时给我们提供了解决方案，这里我们使用 `Box<T>` 指针。\n\n另外，考虑到二叉树的左右子树可能为空，所以这里我们还需要增加一个 `Option`。\n\n最终我们的二叉树数据结构定义如下：\n\n```\n#[derive(Debug, Default)]\nstruct Tree {\n    value: i32,\n    left: Option<Box<Tree>>,\n    right: Option<Box<Tree>>   \n}\n```\n\n#### 实现基本的方法\n\n这里我们实现一些二叉树的基本的方法，作为上述结构体的方法，我们将实现以下方法：\n\n* 获取二叉树节点的值（其实也可以没有这个方法）。\n* 修改二叉树节点的值。\n* 设置子树。\n* 删除子树。\n\n这里除了第一个，其余我们都需要传递 `self` 的可变引用，我们的实现如下：\n\n```\nimpl Tree {\n    fn get_val(&self) -> i32 {\n        return self.value;\n    }\n    fn set_val(&mut self, val: i32) -> i32 {\n        self.value = val;\n        return self.value;\n    }\n    fn insert(&mut self, dir: &String, val: Tree) {\n        assert!(dir == \"left\" || dir == \"right\");\n        match dir.as_ref() {\n            \"left\" => self.left = Some(Box::new(val)),\n            \"right\" => self.right = Some(Box::new(val)),\n            _ => { \n                println!(\"Insert Error: only left and right supported\");\n                process::exit(1);\n            }\n        }\n    }\n    fn delete(&mut self, dir: &String) {\n        assert!(dir == \"left\" || dir == \"right\");\n        match dir.as_ref() {\n                \"left\" => self.left = None,\n                \"right\" => self.right = None,\n                 _ => { \n                    println!(\"Insert Error: only left and right supported\");\n                    process::exit(1);\n                }\n        }\n    }\n}\n```\n\n### 遍历二叉树\n\n这里遍历二叉树我们作为一个单独的方法，而不是属性方法来实现，这样会更符合我们平时的业务场景，这里其实问题比较多的，我们先简易实现一个版本：\n\n```\nfn traverse(tree: Tree) {\n    println!(\"Node Value: {:?}\", tree.value);\n    if tree.left.is_some() {\n        traverse(*tree.left.unwrap()); // 手动解引用\n    }\n    if tree.right.is_some() {\n        traverse(*tree.right.unwrap()); // 手动解引用\n    }\n}\n```\n\n如果我们测试一下这个版本，发现的确能够正常遍历的，但是实际上这有一个致命的问题：\n\n这里采用的是所有权的移动，而不是不可变借用，这会导致我们的函数执行完后原来变量的所有权已经被移动了，换一种说法则是会消耗掉这个变量，这显然不是我们预期的。\n\n虽然我们也可以在函数中返回 tree 的方式来最后再次移动所有权，但这样非常不便于实现，经过重构，我们采用了如下的方式实现：\n\n```\nfn traverse(tree: &Tree) {\n    println!(\"Node Value: {:?}\", tree.value);\n    match tree.left {\n        Some(ref x) => traverse(x),\n        _ => {}\n    }\n    match tree.right {\n        Some(ref x) => traverse(x),\n        _ => {}\n    }\n}\n```\n\n>另外一个注意点则是由于 `unwrap()` 本身是一个消耗性操作，我们这里不能使用 `unwrap`，参考[stackOverflow的提问1](https://stackoverflow.com/questions/22282117/how-do-i-borrow-a-reference-to-what-is-inside-an-optiont)、[stackOverflow的提问2](https://stackoverflow.com/questions/32338659/cannot-move-out-of-borrowed-content-when-unwrapping)。\n\n我们最终的完整代码如下：\n\n```\nuse::std::process;\nuse std::borrow::Borrow;\n#[derive(Debug, Default)]\nstruct Tree {\n    value: i32,\n    left: Option<Box<Tree>>,\n    right: Option<Box<Tree>>   \n}\n\nimpl Tree {\n    fn get_val(&self) -> i32 {\n        return self.value;\n    }\n    fn set_val(&mut self, val: i32) -> i32 {\n        self.value = val;\n        return self.value;\n    }\n    fn insert(&mut self, dir: &String, val: Tree) {\n        assert!(dir == \"left\" || dir == \"right\");\n        match dir.as_ref() {\n            \"left\" => self.left = Some(Box::new(val)),\n            \"right\" => self.right = Some(Box::new(val)),\n            _ => { \n                println!(\"Insert Error: only left and right supported\");\n                process::exit(1);\n            }\n        }\n    }\n    fn delete(&mut self, dir: &String) {\n        assert!(dir == \"left\" || dir == \"right\");\n        match dir.as_ref() {\n                \"left\" => self.left = None,\n                \"right\" => self.right = None,\n                 _ => { \n                    println!(\"Insert Error: only left and right supported\");\n                    process::exit(1);\n                }\n        }\n    }\n}\n\n// 原始的非消耗性遍历:\n// fn traverse(tree: &Tree) {\n//     println!(\"Node Value: {:?}\", tree.value);\n//     if tree.left.is_some() {\n//         // cannot move out of borrowed content\n//         // 首先 unwrap 是一个消耗性操作\n//         // 这是由于 unwrap 函数造成?  as_ref 也不行\n//         traverse((tree.left.as_ref().map(|x| **x).unwrap()).borrow());\n//     }\n//     // if tree.right.is_some() {\n//     //     // cannot move out of borrowed content\n//     //     traverse(tree.right.unwrap().borrow());\n//     // }\n// }\n\n// 非消耗性遍历\nfn traverse(tree: &Tree) {\n    println!(\"Node Value: {:?}\", tree.value);\n    match tree.left {\n        Some(ref x) => traverse(x),\n        _ => {}\n    }\n    match tree.right {\n        Some(ref x) => traverse(x),\n        _ => {}\n    }\n}\n\n// 消耗性遍历：\n// fn traverse(tree: Tree) {\n//     println!(\"Node Value: {:?}\", tree.value);\n//     if tree.left.is_some() {\n//         traverse(*tree.left.unwrap()); // 手动解引用\n//     }\n//     if tree.right.is_some() {\n//         traverse(*tree.right.unwrap()); // 手动解引用\n//     }\n// }\n\nfn main() {\n    println!(\"begin rust tree test:\");\n    let mut tree = Tree { value : 12, ..Default::default() };\n    let mut left = Tree { value : 121, ..Default::default() };\n    tree.insert(&String::from(\"left\"), left);\n    let mut right = Tree { value : 122, ..Default::default() };\n    tree.insert(&String::from(\"right\"), right);\n    // tree.delete(&String::from(\"right\"));\n    // println!(\"Tree val: {:?}\", left.get_val()); 不能这样写，所有权已经被移动\n    traverse(&tree);\n    // traverse(tree);\n}\n```","tags":["Rust"]},{"title":"深入Vue源代码解决时序问题一","url":"/2019/07/06/深入Vue源代码解决时序问题一/","content":"\n>viola 是一个支持 Vue 的动态化框架，其 Vue 版本在 Vue 官方版本 2.5.7 上进行了少量改写，本文针对其进行具体分析。\n\n最初，有使用者报告一个错误：在 iOS 系统，退出页面的时候，框架报错：\n\n```\nTypeError: undefined is not an object(evaluating 'e.isDestroyed\"\n```\n\n接到这个错误之后，我首先进入 Vue 的 debug 版本，尝试获取更详细的信息：\n\n```\nTypeError: undefined is not an object(evaluating 'componentInstance.isDestroyed\"\n```\n\n我们顺利地拿到了报错的变量名称，去 Vue 源代码中搜索，我们可以发现报错之处：\n\n```javascript\ndestroy: function destroy (vnode) {\n    var componentInstance = vnode.componentInstance;\n    if (!componentInstance._isDestroyed) { // 这里报错\n      if (!vnode.data.keepAlive) {\n        componentInstance.$destroy();\n      } else {\n        deactivateChildComponent(componentInstance, true /* direct */);\n      }\n    }\n  }\n```\n\n这里是 `componentInstance` 为 undefined，这个实际上是 vnode 的实例，其为 undefined，说明该 vue 组件在之前的阶段就已经出错不正常了，这里并不是错误的根源所在，我们需要再次进行寻找报错原因。\n\n于是我们查看业务代码的所有日志，又发现了这样一条报错：\n\n```\n[Vue warn]: Error in nextTick: \"TypeError: undefined is not an object (evaluating 'vm.$options')\" \n```\n\n初始化阶段出现这样一个错误，我们怀疑 `vm` 就是上文的 `componentInstance`，于是，我们打印报错堆栈：\n\n```javascript\n 调用栈:\nfunction updateChildComponent(\n    vm,\n    propsData,\n    listeners,\n    parentVnode,\n    renderChildren\n  ) {\n        //...\n        var hasChildren = !!(\n              renderChildren ||\n              vm.$options._renderChildren || // 这里报错\n              parentVnode.data.scopedSlots ||\n              vm.$scopedSlots !== emptyObject\n            );\n    }\n\nfunction prepatch(oldVnode, vnode) {\n      var options = vnode.componentOptions;\n      var child = vnode.componentInstance = oldVnode.componentInstance;\n      updateChildComponent(\n        child,\n        options.propsData,\n        options.listeners,\n        vnode,\n        options.children\n      );\n    }\n\nfunction patchVnode(oldVnode, vnode, insertedVnodeQueue, removeOnly) {}\nfunction patch(oldVnode, vnode, hydrating, removeOnly) {}\nfunction (vnode, hydrating) {}\nfunction () {\n        vm._update(vm._render(), hydrating);\n      }\nfunction get() {}\nfunction getAndInvoke(cb) {}\nfunction run() {}\nfunction flushSchedulerQueue() {}\nfunction flushCallbacks() {}\n```\n\n调用栈实际上有点冗长，不过我们还是能发现两个有用的信息：\n\n* 初始化阶段为 `undefined` 的 `vm`，就是 `componentInstance`，也就是和 destroy 阶段的报错属于同一个原因。\n* 根据调用栈发现，这是一个更新阶段的报错。\n\n这引发了我们的思考：更新阶段找不到 `componentInstance` 报错。\n\n这里实际上有点阻塞了，因为一般来说，Vue 的源代码经过测试，应该不会出现这种问题的，那是不是我们的问题呢，我们回归到业务代码：\n\n```\ncreated() {\n    this.getFeedsListFromCache();\n},\nmethods: {\n    getFeedsListFromCache() {\n        viola.requireAPI(\"cache\").getItem(this.cacheKey_feeds, data => {\n            this.processData(data.list);\n        });\n    },\n    processData(list = [], opt = {}) {\n        if (this.list.length < cacehFeedsLength) {\n        }\n        this.list = [];\n    },\n}\n```\n\n我们对业务代码进行了抽象简化，上面是我们的最小问题 Demo，实际上我们就做了这样一件事情：\n\n* 在 created 执行方法，调用端的接口，再回调函数里面更新某个 data 中声明的数据。\n\n首先，我们可以梳理下对一般 vue 组件的初始化更新，vue 是如何做的：\n\n* created 时实际上 vnode 已经建立完成，这个时候还没有 mount，但是数据监听已经建立了，这个时候如果改动数据，会把相关 update 函数放在一个名为 flushCallbacks 的函数队列中。\n* 该函数队列会通过默认为 `Promise.then` 的 microtask 方式来调度，当前阶段的 mount 流程会继续，mount 结束后，会执行 flushCallbacks 队列中的更新操作。\n\n从代码层面上来讲，这几个流程应该是这样的：\n\n```\n ├── callHook(vm, 'created'); // 执行created 钩子\n ├── proxySetter(val); // 改变数据，调用 proxy\n ├── Watcher.prototype.update; // 调用 Watcher，将 update 操作入栈\n ├── vm.$mount(vm.$options.el); // 执行 mount 流程\n ├── callHook(vm, 'beforeMount');\n ├──  callHook(vm, 'mounted'); // 依次调用 beforeMount 和 mounted\n └── flushCallbacks // 执行 更新\n```\n\n然后我们分析我们这里的流程，首先值得强调的是这个函数 `viola.requireAPI(\"cache\").getItem`，这个函数是端注入的函数，但我们不能将其当作异步函数来对待，实际上，**这是一个同步函数**，（至于这个同步函数和 js 中的普通函数，是否有区别，还有待商榷，不过应该是有区别的，因为如果我们不用此函数的话，就不会出现该问题。）\n\n接下来，我们打出详细的调用栈，根据顺序来分析实际的执行流程：\n\n```\n ├── callHook(vm, 'created'); // 执行created 钩子\n ├── proxySetter(val); // 改变数据，调用 proxy\n ├── Watcher.prototype.update; // 调用 Watcher，将 update 操作入栈\n ├── flushCallbacks // 执行 更新\n ├── vm.$mount(vm.$options.el); // 执行 mount 流程 \n ├── callHook(vm, 'beforeMount');\n └── callHook(vm, 'mounted'); // 依次调用 beforeMount 和 mounted\n```\n\n我们发现，我们的执行流程出现了很大问题：**在 mount 阶段未完成的时候就执行了 flushCallbacks，先执行更新操作，这里的顺序错乱导致了后续问题**。\n\n我们可看下调用 `flushCallbacks` 的代码：\n\n```javascript\nif (typeof Promise !== 'undefined' && isNative(Promise)) {\n  var p = Promise.resolve();\n  microTimerFunc = function () {\n    p.then(flushCallbacks);\n    // in problematic UIWebViews, Promise.then doesn't completely break, but\n    // it can get stuck in a weird state where callbacks are pushed into the\n    // microtask queue but the queue isn't being flushed, until the browser\n    // needs to do some other work, e.g. handle a timer. Therefore we can\n    // \"force\" the microtask queue to be flushed by adding an empty timer.\n    if (isIOS) { setTimeout(noop); }\n  };\n} \n```\n\n这里 `microTimerFunc` 的 `p.then`，被同步执行了，也就是说，这里的微任务优先于当前事件循环的函数执行了（此时由于 mount 流程是同步的，mount 流程的相关函数**理应**在该事件循环中，优先于微任务执行）。\n\n我们找到了根源，接下来就是分析解决方案和根本原因。\n\n由于我们的问题在于 update 流程执行太快了，所以采用一种方式放慢一点即可：\n\n* 将 vue 的微任务模式（默认）改成宏任务模式：`var useMacroTask = false; => true`。\n* 在 created 阶段的加一个 `setTimeout(0)`。\n\n不过对于根本原因，实际上本次仍然没有完全分析透彻，还留有如下疑问：\n\n* `viola.requireAPI(\"cache\").getItem` 这个函数到底做了什么？其对事件循环有什么影响？\n* 在执行 `microTimerFunc` 的时候，为什么 `p.then` 优先于 `vm.$mount` 执行了？\n* 该错误仅在 iOS 系统出现，iOS 系统是否会在某些情况将微任务的优先级变高？\n\n对于这些疑问，Vue 源代码中也做了一些评论：\n\n```\n// Here we have async deferring wrappers using both microtasks and (macro) tasks.\n// In < 2.4 we used microtasks everywhere, but there are some scenarios where\n// microtasks have too high a priority and fire in between supposedly\n// sequential events (e.g. #4521, #6690) or even between bubbling of the same\n// event (#6566). However, using (macro) tasks everywhere also has subtle problems\n// when state is changed right before repaint (e.g. #6813, out-in transitions).\n// Here we use microtask by default, but expose a way to force (macro) task when\n// needed (e.g. in event handlers attached by v-on).\n```\n\n不过，这里始终都没有找到最本质的原因，也许这和 iOS JSCore 的微任务/宏任务的处理机制有关，具体原因，待下次探究。\n\n\n\n","tags":["Vue","viola"]},{"title":"web应用开发与部署——你必须掌握的内容","url":"/2019/06/16/web应用开发与部署——你必须掌握的内容/","content":"\n\n\n本文基于笔者在腾讯的项目经验，从真实场景出发分析一个中型 Web 应用从立项到上线稳定运行的平稳解决方案，力求既不太空泛以至于看完了仍然找不到落地的点，也尽量不会特别纠结于个别细节导致没有相关使用经历的同学无法感同身受，而是从宏观到方法论，分析整个流程中我们需要用到的工具、方法与规范，给大家提供一个参考。\n\n本文适合具有一定经验的初中级前端开发者，如果有相关问题，也欢迎与我交流。\n\n目录\n\n* 项目构建的搭建，关键词：**webpack**、**react/vue cli**，**steamer**，**组件库**\n* 代码的规范约束，关键词：**typescript**、**eslint**、**prettier**\n* 测试与测试部署，关键词：**测试部署方案**、**docker**\n* 日志查看与脚本错误的监控，关键词：**sentry**、**vconsole**、**mlogger**\n* 版本发布更新，关键词：**发布系统**、**灰度发布**\n* 访问量实时监控\n\n### 起步：项目构建的搭建\n\n#### 使用 webpack 搭建脚手架\n\n目前在一般的项目中，我们都会使用 webpack 作为搭建开发环境的基础，而 react 和 vue 也各自提供了 cli 工具用于开发一个中小型项目，react 提供了 eject 功能让我们可以更加自由的配置 webpack，而 vue 脚手架虽然没有提供类似命令，但是借助 webpack 工具链我们几乎也可以自由定制每一个角落。\n\n不过，这里我的建议是，如果是个人项目或小型项目，我们可以基于 react 或 vue 的脚手架进行更改使用，对于一个具备一定规模的项目团队，建议还是自己维护一套单独的 webpack 构建环境，原因如下：\n\n* 由于我们一般需要在项目中接入各类司内工具、支持高级API和语法、同时支持 react/vue、构建目录定制化等各类工作，实际上 80% 以上的工作我们都需要在模版之上自行添加，这个时候我们再用脚手架带来的收益已经非常小了，反而还会受制于项目的初始目录结构。\n\n我们在自定义脚手架的 webpack 构建的时候，也需要梳理出一定的目录规范与约束，这样也有利于提高后期脚手架的可维护性和扩展性，一般来说，我们也要对脚手架中的公共部分和项目私有部分进行分离，对于一个具体项目而言，可以不用改动 webpack 的项目公共部分，这样也有利于减少不同项目之间的切换成本，对于我们目前的项目，一般会有如下两个目录：\n\n```\n- project\n\t- project.js\n- config\n\t- feature\n\t- plugins\n\t- rules\n\t- script.js\n\t- webpack.base.js \t\n```\n\n对于一个项目，只需更改 project 下的配置。\n\n这里我也推荐一个前同事做的[steamer研发体系](https://github.com/steamerjs)，在从中也可以找到很多相关参考，最简单的方式，就是直接在[steamer-simple](https://github.com/steamerjs/steamer-simple) 的基础上进行扩展。\n\n#### 定制生成目录\n\n生成目录的格式，这里需要单独讲一下。\n\n一般来说，我们生成目录的格式都是要跟发布系统进行结合的，不过也有的时候，我们做项目的时候还没有明确要接入发布系统，或者尚不知道发布系统的格式要求，但是一般情况下我们应当遵循下面的约定：\n\n* js/css/img 等资源文件和 html 文件分离，前者发布到 CDN，后者发布到 http 服务器。\n* html 中引入的文件地址，应当是在构建过程中更新的 CDN 地址，而不是相对路径地址。\n* 如果有离线包（offline 能力需要对应的客户端 webview 支持）等，需要单独一个目录。\n\n对于我们目前的项目而言，一般情况下会有三个生成目录：\n\n```\n- cdn\n- offline # 需要客户端支持该能力\n- webserver\n```\n\n如果一开始我们把所有内容生成到一个目录中了，这给我们后期的改动和维护，都带来很大的隐患。\n\n#### 组件库\n\n组件库这一部分，适合项目开始变得复杂的情况下进行启动，而不建议一开始进行过渡设计，建设组件库能够通过组件复用降低我们的开发成本，同时，组件库也需要专人维护，保持更新。\n\n### 开发：代码的规范约束\n\n对于 js 文件的代码格式，诸如要不要分号、两个还是四个字符缩进等，一只争议不断，本文也不对此进行讨论，但是对于一个团队的项目集合（而不是单个项目）而言，代码风格的统一，是一个非常有必要而且必须要做的事情。\n\n#### typescript\n\n关于 typescript 的相关文章实在太多了，这里也不对此进行详细的说明，其对代码的可读性、规范约束、降低报错风险等都有很好的改进，对于越复杂的项目其效果越明显。\n\n另外， [typescript 入门教程](https://ts.xcatliu.com/)的作者也在我们团队中，这里我想说，如果现在还没有开始使用 typescript，请开始学习并使用 typescript 吧。\n\n#### eslint 与 prettier\n\n除了 typescript 以外，在代码格式方面还建议使用 eslint 和 prettier 来进行代码格式的约束，这里虽然 eslint 和 prettier 两者在某些情景下会有些重叠，但是两者的侧重点不同，eslint 侧重于代码质量的检查并且给出提示，在某种层面上，可以看作是 typescript 的补充，而 prettier 在格式化代码方面更具有优势，并且 prettier 在设计之初就考虑了和 eslint 的集成，所以你可以完全放心的在项目中使用两者，而不用担心出现无法解决的冲突。\n\n另外，eslint 社区中已经形成了很多种最佳实践，而我们团队也设计出了自己的一套 eslint 规则，可以按需[取用](https://github.com/AlloyTeam/eslint-config-alloy)\n\np.s. 目前 tslint 后续计划不在维护，转向 eslint 增强，因此我们在项目中可以不再使用 tslint。\n\n以上这几种代码风格方面的约束，适合项目之初即开始约束，这样在中后期会有巨大的时间成本的节省和效率的提升。\n\n### 协作：使用 git\n\n使用 git 进行协作这里其实包括两个点，使用 git 管理项目与自建 gitlab，后者是一个比较基础性的工作，并且实际上难度并不大，我认为每一个公司都可以使用自建的 gitlab 进行版本管理，这个实际上难度并不大，并且可以有效的保护公司的代码财产，如果你所在的公司还没有，那么这也是你的机会。\n\n在具体的使用 git 中，对于git的分支/TAG管理、PR规范、提交文件约束等都应当有一套合理的流程，这里我对几点比较重要的进行说明：\n\n* 锁定主干与分支开发，我们在日常开发中禁止直接提交主干，而是只能在分支中进行开发，并且通过 MR 的方式提交到主干。\n* git hooks 检查：我们应该通过 git hooks 进行必要的检查，比如自动化测试、eslint 检查、以及一些项目中必要的检查。\n* MR 检查与 Code Review，这里建议在 Merge Request 的时候做两件事情，一件是 Code Review，不过这个在某些特殊情况下不具备条件，尤其是团队人力紧张的时候，另外一个则是 MR 的 HOOK 触发检查，这个一般需要借助一些持续集成工具来完成，可以说是我们代码在合并主干之前的最后一个关卡。\n\n### 测试：测试与测试部署\n\n测试是代码开发中重要的一个环节，但实际上对于前端开发来说，前端开发工程师一般较少书写测试用例，也并没有专业的测试开发工程师来辅助工作，不过，一般会有配备系统测试工程师在黑盒的情况下进行冒烟测试和功能测试以及整体链路的验收，俗称“点点点”。而这个时候，前端开发要做的就是把程序代码部署到测试服务器上，同时提供一个尽可能真实的场景供测试进行测试。\n\n在笔者经历的项目中，虽然也使用了单元测试、端对端测试，不过这一部分体系并不十分完备，并且可能也不是大多数前端开发者感兴趣的内容，所以这里主要总结如何进行高效的测试部署与发布对接。\n\n一般来说，我们一般会有一台到多台 Linux 测试机，供测试环境部署使用，对于前端项目而言，一般不需要特殊环境，可以进行 webpack 构建以及有 nginx 进行转发即可。\n\n而测试环境的部署，如果是让我们手动登录去部署，显然是不合理的，如果我们纯粹使用 CI 来完成这件事，则对 CI 工具的能力和项目人员素质有一定要求，并且不具备可视化管理能力，容易出错，这里我建议可以维护一个可视化系统来进行测试环境的部署和管理，其整个环节应该是这样的：\n\n```\n本地代码 -> gitlab -> 测试系统部署 -> 对接发布系统 \n```\n\n这里的测试系统，实际上是从 gitlab 拉取代码，并且本地执行 build 命令（一般是 `npm run build`）并把构建结果存储在 nginx 可代理的目录即可，出于系统完备性考虑，一般我们会有多台测试机，这里我建议一般拿其中的一台作为构建机，其他的测试机仅提供 nginx 代理能力即可，我们在一台构建机中进行构建，并且将构建结果通过系统命令发送到其他的测试机。\n\n一台构建机可以服务于所有的项目，这里还可能涉及到 webpack、nodejs 版本的维护，我们需要约束各个测试项目构建处在一个相对独立的环境中，我们也可以使用过 Docker 来进行构建，保证隔离。\n\n构建完成后，一般我们借助 Fiddler、Charles、Whistle 等任意一款代理工具，即可以进行测试。\n\n### 监控：日志查看与脚本错误的监控\n\n对于前端项目而言，即使我们已经使用了 typescript、eslint 并且也有了一些测试脚本和系统测试工程师进行的功能测试，我们还是免不了会出现 js 脚本错误，特别是 js 代码的运行环境和设备的多样化，很多错误我们并没有发现，但是产品、运营同学却出现了，或者到了线上在用户设备上出现了。\n\n所以，有两个事情我们必须要做：\n\n1. 日志查看功能（手机端）：现在我们写的大多数 TO C 页面都是在手机端进行，查看 console 非常不方便，我们需要一个线上实时查看 console 的工具。\n2. 我们需要脚本错误日志统计系统来进行错误统计管理与具体错误查看。\n\n对于第一个功能，进行细分，我们需要做这样几件事情：\n\n* 嵌入一个 console 和 网络请求查看器，并且只在特殊情况下才能触发（比如连续点击标题十次、或者使用特定交互手势）\n* 在触发查看器的时候，可以将日志完整地进行上传并分析。\n* 同时可以对该用户进行染色，会自动上传并记录该用户一定时间内后续刷新后操作的全部日志。\n\n不过这里并没有完全实现以上三点的开源库推荐，可以在 [vconsole](https://github.com/Tencent/vConsole) 或者 [mlogger](https://github.com/AlloyTeam/MLogger) 的基础上进行适当扩展，完成相关功能。\n\n对于第二个功能，我们需要一个完整的统计分析与管理的错误系统，这个如果自行开发的话，难度会比较大，这里强烈推荐 [sentry](https://sentry.io/welcome/)，可以非常方便的使用 Docker 部署到服务器端，并且拥有非常强大的日志错误分析与处理能力，通过结合 JavaScript 的 sourcemap ，可以给我们的错误定位带来极大的方便。\n\n总之，日志查看与脚本错误监控，是比较重要但是同时容易被忽视的地方，很多时候，我们的系统在线上使用了几个月了，真正有问题反馈了，我们才会考虑加上这些功能，但这个时候通常已经造成了损失。\n\n### 发布：版本发布更新\n\n发布系统，一般作为前端最后环节的系统，通常会和测试部署系统打通（或合二为一），一般的发布系统的必要功能如下：\n\n* 对于前端的发布，每次只发布有改变的文件，无变动的文件则无需发布。\n* 每次发布先发布 js/css/img 等资源文件，生效之后再发布 html 文件。\n* 发布系统保留线上旧版代码，出问题后可以快速一键回滚。\n\n至于一些其他的日志、报表等辅助性功能，则根据需要满足，这里不再赘述。\n\n#### 灰度发布\n\n灰度发布是大型项目在发布时的常见方法，指在发布版本时，初始情况下，只允许小比例（比如1-5%比例的用户使用），若出现问题时，可以快速回滚使用老版本，适用于主链路和访问量较大的页面。\n\n对于前端的灰度，实际上有以下几种方案：\n\n* 在代码层面进行灰度，即通过 if/else 进行判断，这样无需发布系统关注，也可以自由配置规则、比例与白名单/黑名单。\n* 在入口层面进行灰度，比如 App 内嵌的 H5 则在客户端的对应入口进行回复，这样通常也无需发布系统关注。\n* 通过发布系统，按照比例灰度，比如我们有 10 台 webserver，如果我们先发布 1 台，这样我们的灰度比例为 10%。\n\n### 访问量实时监控\n\n最后一点，我们还需要一个访问量实时监控系统，我们上述有了错误查看与脚本监控系统，但是对于我们的各个页面的访问量、点击率等指标，通常是产品/运营同学比较关心的，同时访问量的波动情况也是项目健康度的一个表征（访问量突然大幅上涨或下跌，一般都有其特定原因），所以我们需要访问量实时监控系统。\n\n而实际上访问量监控系统也有两种不同形态：\n\n* 对于每一个上报 key，只进行数量上的统计\n* 对于每一个上报 key，可以携带一些信息，对携带信息进行统计分析。\n\n通常情况下，前者的功能是实时或者低延时的，而后者由于需要一部分统计分析，通常可以接受非实时情况（一般每天出前一天的报表）。\n\n这部分内容，需要较强的后端接口稳定性，通常前端需要和对应岗位的同学共建。\n\n### 总结\n\n总结下来，我们一个稳定的前端项目，至少涉及到以下环节：\n\n* 完善的项目脚手架与代码约束规范\n* 内部 gitlab\n* 可视化管理的测试部署系统\n* 实时日志查看工具\n* 脚本错误统计管理系统\n* 发布管理系统\n* 访问量实时监控系统\n\n如果你所在的团队哪个环节还没有或者不完善，那么这也是你的机会。\n","tags":["前端构建"]},{"title":"qlc解决了什么问题","url":"/2019/02/16/qlc解决了什么问题/","content":"\n### 目前遇到的问题\n\n作为一名前端工程师，陆陆续续负责了不少项目，这些项目中，有一些是正在迭代的，其他同事同时在负责的项目，但是也有不少项目，要么就是老旧项目维护的同事已经离职或转岗了的，要么就是新项目从 0 开始的，再加上前端代码积累速度和迭代速度都比较快，其中暴露了不少问题。\n\n我身边的大多数程序员都有一个特点，就是喜欢把具体的东西抽象化，我们通常会抽象出公共的函数或方法、公共的类或HOC，放在一起，集中在项目的某一个文件夹下，叫做 js 文件夹或 lib 文件夹（以下我们用 js 文件夹代表公共函数文件夹 ）。\n\n这样做的确带来了很多便利，但同时也有一些隐患：\n\n* js 文件夹下代码越来越多，而且大多数鹅厂小伙伴的作风是 0 文档 0 注释，这给新接手项目的同学熟悉项目带来了极大的麻烦。\n* 不同项目都有自己的 js 文件夹，在开发一个新项目时，我们通常的做法是：\n\t* 直接将原有项目的 js 文件夹拷贝到新项目中，这样在新项目中，我们也可以直接使用这些公共函数了。\n\t* 将原有项目的部分 js 文件拷贝到新项目中，并且随着新项目的开发，增量拷贝。\n\t* 以上两种做法，本质区别不大，前者会直接给新项目增加很多无用代码（原有项目中所谓的公共函数在新项目中并不一定会用到），而对这两种方式，如果我们要修复一个 bug，修改或升级公共代码中的一个文件，那么我们就要一个一个的，将修复好的文件拷贝到不同的项目中，如果项目多了并且已经交由不同的人维护了，这简直是一个灾难。\n* 由于公共 js 文件夹下内容比较多，并且有的开发同学习惯以 'urlUtils.js'、'strUtils.js' 这种方式来整合一些小的函数集，这样会造成函数重复的隐患（毕竟我们一个文件一行行的去分析目前的公共库已经有了哪些能力是不现实的），我观察过之前自己接手的一个不算复杂的项目（潘多拉），其仅仅是从 url 解析 query 这种功能函数，就有多达 3个(甚至更多)，分布在 js 文件夹以及 node_modules 里面，这显然是不同的维护人员由于信息不对称重复引入的。\n* 对于怎么样才能算作“公共”函数，目前是缺乏一个 review 过程的，任何项目开发人员，几乎都可以无限制地在公共 js 文件夹下增加内容，并在之后被携带着拷贝到其他项目中，这其中有些函数，也许并不适合在这里。\n\n### 问题归纳与解决\n\n实际上，总结下来，我们需要解决三个痛点：\n\n* 以低成本的方式增加高可读性的文档，方便新接手项目的同学熟悉。\n* 解决跨项目之间的公共函数复用和更新维护困难的问题。\n* 增加必要的 review 环节，对公共函数库的必要性和代码正确性进行 review。\n\n就第一个问题而言，其实现在的前端文档工具链已经极大降低了写文档的成本了，利用 [jsdoc](http://usejsdoc.org/) 或 [esdoc](https://esdoc.org/) 等文档生成工具，我们基本上已经不需要手动写文档，而是在写代码的同时写注释，就可以自动生成文档，并且配合相关的编辑器插件，一部分注释都可以自动生成。\n\n但是目前我经历的大多数项目还是没有文档，这里可能是由于以下四个原因：\n\n* 部分同学并不知道有 esdoc、jsdoc 这种比较好用的文档生成工具。\n* 开发组中没有人去推动，文档不属于 KPI 和考核的内容，加之时间紧迭代快，缺乏前人栽树的动力。\n* 虽然现在的文档生成工具比较简单了，但一般还是需要一定的配置，也有一点上手成本。\n* 生成的文档不能十分满足需求，例如 esdoc 默认只能生成 html 格式的文档，在编辑器里面没法直接看。\n\n针对第一个问题，qlc 做出了一些努力：\n\n* 0 配置，全自动化生成文档，甚至集成到了其他开发流程中，命令行也不用敲。\n* 基于 esdoc 以及开源插件二次开发，可以选择性生成 html 和 markdown 格式的文档，注重文档体验。\n* 基于 esdoc 注释写作成本更低，更能节省时间。\n\n>跟 jsdoc 相比，esdoc 使用方式比较简单，不需要严格使用标签，而且能够支持搜索，并且官方资料更为齐全。\n\n至此，使用 qlc 生成文档，已经非常简单了。\n\n第二、第三个问题实际上是公共函数库的维护问题，qlc 也设计了对应的流程，着力解决该问题：\n\n* 首先有一个远程公共库（基于 git）。\n* 对于某一个项目而言，可以从远程库中下拉所需要的公共函数/类，并自动生成文档。\n* 如果我们对某一个项目增加了一个公共函数并且认为可以为更多的项目所用，命令行上传到远程库自动触发 MR，维护人员 review 通过后即可供其他项目使用。\n* 修复或更新某一个公共函数之后，我们只需同步到远程库，其他项目维护人员在命令行工具的辅助下同步即可。\n\n### 更多\n\n到此，你是否认为 qlc 给你带来了一定的价值呢，可以到 qlc 的官方仓库查看更多的[文档细节](https://git.code.oa.com/qlc/qlc)\n\n\n\n\n\n","tags":["javascript"]},{"title":"入门WebAssembly以及使用其进行图像卷积处理","url":"/2019/02/16/入门WebAssembly以及使用其进行图像卷积处理/","content":"\n> WebAssembly 出现有很长时间了，但是由于日常工作并无直接接触，因此一直疏于尝试，最近终于利用一些业余时间简单入门了一下，因此在此总结。\n\n### 简介\n\n首先我们需要知道 WebAssembly 是一个什么东西，其实际是一个字节码编码方式，比较接近机器码（但是又无法直接执行），这样可以方便地做到跨平台同时省去像 JavaScript 等语言的解释时间，所以是有一定优势的，使用起来其实也比较灵活，凡是可以转化成字节码的，都是可以使用 WebAssembly。\n\n以下仅列举部分可以支持 WebAssembly 转化的语言：\n\n* [AssemblyScript](https://github.com/AssemblyScript/assemblyscript): 语法和 TypeScript 一致(事实上，其是 Typescript 的一个子集)，对前端来说学习成本低，为前端编写 WebAssembly 最佳选择；\n* c\\c++: 官方推荐的方式，详细使用见[文档](http://webassembly.org.cn/getting-started/developers-guide/);\n* [Rust](https://www.rust-lang.org/): 语法复杂、学习成本高，对前端来说可能会不适应。详细使用见[文档](https://github.com/rust-lang-nursery/rust-wasm);\n* [Kotlin](http://kotlinlang.org/): 语法和 Java、JS 相似，语言学习成本低，详细使用见[文档](https://kotlinlang.org/docs/reference/native-overview.html);\n* [Golang](https://golang.org/): 语法简单学习成本低。但对 WebAssembly 的支持还处于未正式发布阶段，详细使用见[文档](https://blog.gopheracademy.com/advent-2017/go-wasm/)。\n\n尝试使用 WebAssembly 官方推荐的方式，我们首先可以在[这里](http://webassembly.org.cn/getting-started/developers-guide/)来下载。\n\n如果用腾讯内网有的文件是下载不下来的，这个时候我们可以给命令行增加一个代理（如果我们用的 Fiddler 或 Charles，开启的时候默认命令行也可以走代理，如果是 Whistle，我们需要手动设置代理），有些文件我们还可以下载好之后使用文件代理。\n\n```\nexport https_proxy=\"http://127.0.0.1:8899\"\nexport http_proxy=\"http://127.0.0.1:8899\"\n// 文件代理：\nhttps://s3.amazonaws.com/mozilla-games/emscripten/packages/node-v8.9.1-darwin-x64.tar.gz file:///Users/niexiaotao/node-v8.9.1-darwin-x64.tar.gz\n```\n\n## 初体验\n\n这里考虑到前端同学的上手难度，我们先使用 AssemblyScript 写一个极小的例子，一个斐波那契函数：\n\n```\nexport function f(x: i32): i32 {\n    if (x === 1 || x === 2) {\n        return 1;\n    }\n    return f(x - 1) + f(x - 2)\n}\n```\n\n通过类似 `asc f.ts -o f.wasm` 这样的命令编译成 f.wasm 之后，我们可以分别在 Node 环境和浏览器环境来执行：\n\nNode：\n\n```\nconst fs = require(\"fs\");\nconst wasm = new WebAssembly.Module(\n    fs.readFileSync(__dirname + \"/f.wasm\"), {}\n);\nconst myModule = new WebAssembly.Instance(wasm).exports;\nconsole.log(myModule.f(12));\n```\n\n浏览器：\n\n```\nfetch('f.wasm') // 网络加载 f.wasm 文件\n        .then(res => res.arrayBuffer()) // 转成 ArrayBuffer\n        .then( buffer =>\n            WebAssembly.compile(buffer)\n        )\n        .then(module => { // 调用模块实例上的 f 函数计算\n            const instance = new WebAssembly.Instance(module);\n            const { f } = instance.exports;\n            console.log('instance:', instance.exports);\n            console.log('f(20):', f(20));\n        });\n```\n\n于是，我们完成了 WebAssembly 的初体验。\n\n当然，这个例子太简单了。\n\n## 使用 WebAssembly 进行图像卷积处理\n\n实际上，WebAssembly 的目的在于解决一些复杂的计算问题，优化 JavaScript 的执行效率。所以我们可以使用 WebAssembly 来处理一些图像或者矩阵的计算问题。\n\n接下来，我们通过 WebAssembly 来处理一些图像的卷积问题，用于图像的风格变换，我们最终的例子可以在[这里](http://assembly.niexiaotao.com/)体验。\n\n每次进行卷积处理，我们的整个流程是这样的：\n\n* 将原图像使用 canvas 绘制到屏幕上。\n* 使用 `getImageData` 获取图像像素内容，并转化成类型数组。\n* 将上述类型数组通过共享内存的方式传递给 WebAssembly 部分。\n* WebAssembly 部分接收到数据，进行计算，并且通过共享内存的方式返回。\n* 将最终结果通过 canvas 画布更新。\n\n上述各个步骤中，绘制的部分集中在 JavaScript 端，而计算的部分集中在 WebAssembly，这两部分相互比较独立，可以分开编写，而双端数据通信是一个比较值得注意的地方，事实上，我们可以通过 ArrayBuffer 来实现双端通信，简单的说，JavaScript 端和 WebAssembly 可以共享一部分内存，并且都拥有读写能力，当一端写入新数据之后，另一段也可以读到，这样我们就可以进行通信了。\n\n关于数据通信的问题，这里还有一个比较直白的[科普文章](https://segmentfault.com/a/1190000010434237)，可以参考。\n\n在这里没有必要对整个项目代码进行展示，因此可以参考（[代码地址](https://github.com/aircloud/assemConvolution)），我们这里仅仅对部分关键代码进行说明。\n\n### 共享内存\n\n首先，我们需要声明一块共享内存，这其实可以使用 WebAssembly 的 API 来完成：\n\n```\nlet memory = new WebAssembly.Memory({ initial: ((memSize + 0xffff) & ~0xffff) >>> 16 });\n```\n\n这里经过这样的比较复杂的计算是因为 initial 传入的是以 page 为单位，详细可以参考[这里](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WebAssembly/Memory)，实际上 memSize 即我们共享内存的字节数。\n\n然后这里涉及到 memSize 的计算，我们主要需要存储三块数据：卷积前的数据、卷积后的数据（由于卷积算法的特殊性以及为了避免更多麻烦，这里我们不进行数据共用），还有卷积核作为参数需要传递。\n\n这里我们共享内存所传递的数据按照如下的规则进行设计：\n\n![](http://niexiaotao.cn/img/ker1.jpg)\n\n传递给 WebAssembly 端的方式并不复杂，直接在 `WebAssembly.instantiate` 中声明即可。 \n\n```\nfetch(wasmPath)\n     .then(response => response.arrayBuffer())\n     .then(buffer => WebAssembly.instantiate(buffer, {\n         env: {\n             memory,\n             abort: function() {}\n         },\n         Math\n     })).then(module => {})\n                \n```\n\n然后我们在 AssemblyScript 中就可以进行读写了：\n\n```\n//写：\nstore<u32>(position, v) // position 为位置\n\n//读：\nload<u32>(position) // position 为位置\n```\n\n而在 JavaScript 端，我们也可以通过 `memory.buffer` 拿到数据，并且转化成类型数组：\n\n```\nlet mem = new Uint32Array(memory.buffer)\n//通过 mem.set(data) 可以在 JavaScript 端进行写入操作\n```\n\n这样，我们在 JavaScript 端和 AssemblyScript 端的读写都明晰了。\n\n这里需要注意的是，**JS端采用的是大端数据格式，而 AssemblyScript 中采用的是小端，因此其颜色数据格式为 AGBR**\n\n### 卷积计算\n\n我们所采用的卷积计算本身算法比较简单，并且不是本次的重点，但是这里需要注意的是：\n\n* 我们无法直接在 AssemblyScript 中声明数组并使用，因此除了 Kernel 通过共享内存的方式传递过来以外，我们应当尽量避免声明数组使用（虽然也有使用非共享内存数组的相关操作，但是使用起来比较繁琐）\n* 卷积应当对 R、G、B 三层单独进行，我这里 A 层不参与卷积。\n\n以上都在代码中有所体现，参考相关代码便可明了。\n\n卷积完成后，我们通过共享内存的方法写入类型数组，然后在 JavaScript 端合成数据，调用 `putImageData` 上屏即可。\n\n### 其他\n\n当然，本次图像卷积程序仅仅是对 Webassembly 和 AssemblyScript 的初步尝试，笔者也在学习阶段，如果上述说法有问题或者你想和我交流，也欢迎留言或者提相关 issue。\n","tags":["WebAssembly"]},{"title":"web跨端融合方案浅析","url":"/2018/12/04/web跨端融合方案浅析/","content":"\n本文会对目前流行的基于 JavaScript 的 web 跨端融合方案进行总结和分析，目标人群为 web 方向的从业者但是对跨端融合方案了解不多的人。\n\n### web 跨端融合简介\n\n在 2015 年 React Native 发布之前，web 在移动端 APP 上主要通过 WebView 进行承载，其有许多优点，可以快速迭代发布，不特别受 APP 版本的影响，因此，一些快速发展的业务（包括前期的手机QQ、手机淘宝）大量采用了 WebView 内嵌 H5 页面的形式来推动业务。\n\n但是这种方式缺点也比较明显，主要体现在以下两点：\n\n* 加载时间较长，包括 WebView 初始化的时间、网络请求的时间。\n* HTML 页面在性能上天然不如 Native 页面，无论怎么进行性能优化。\n\n在 2015 年，Facebook 推出了 React Native，从而打开了 web 跨端融合的大门，后续在此架构基础上又出现了阿里巴巴的 Weex（2016）、腾讯的小程序（小程序实际上更偏 web 一点，和其他几类稍有不同，本文不作介绍）、 Hippy（2018）、Taro（Taro 其实更偏向解释翻译，和其他几类定位不同）等跨端融合解决方案，并且渐渐被用到越来越多的项目中，目前，跨端融合开发已经是一种比较主流的 web 开发模式，在阿里系应用、腾讯的微信、QQ浏览器、手机QQ均已经进行了大规模应用。\n\n### 基本架构\n\n虽然 web 跨端融合方案众多，除了上述提到的三种，还有各个公司的更多方案，但是一般来说跨端融合的技术架构都比较相近，我们可以通过下面这一个图来简单概括：\n\n![](/img/1.jpg)\n\n接下来，我们逐个进行简析：\n\n* 业务代码：即我们写的 React Native 代码、Weex 代码，一般来说，我们的业务代码需要经过框架工具或者打包工具（例如 webpack 配合 loader）进行打包，从而兼容一些 ES Next 的写法以及一些框架本身不支持的 Web 写法。\n* Javascript FrameWork：这部分主要是针对 Weex、Hippy 来讲的，Weex 声称支持 Vue、Rax 语法，而 Hippy 声称支持 React、Vue 写法，实际上，对于这些库而言，并不是直接将 React、Vue 引入到项目中，而是会对其源代码进行修改（Vue 有针对 Weex 平台的[版本](https://github.com/vuejs/vue/tree/dev/src/platforms)），而 Hippy 也是对 React 源代码进行了修改，例如，你写的一个` createElement `的操作，在 Web 平台中实际调用的是 `document.createElement(tagName) `这个接口；而在 Weex 平台中实际执行的是` new renderer.Element(tagName)`（renderer 由 Javascript Runtime 提供，并且最终和 Native 通信渲染上屏）。\n* Javascript Runtime：Runtime 的部分，主要是对外暴露了一些统一的接口，比如说节点的增删改查、网络请求的接口等，而这些借口，实际上是其“代理”的客户端的能力，通过客户端 JSAPI 的方式进行调用。另外，把 Runtime 和 FrameWork 进行抽离，也可以便于一个跨端方案适配多个框架，只需要将不同的 FrameWork 和浏览器交互的部分代码转换成 Runtime 提供的标准接口，就可以实现对不同框架的支持。\n* Core：这部分主要是对 Javascript 的解释执行，在 iOS 上一般是 JSCore（系统自带，给客户端提供了执行 JavaScript 程序的能力），而安卓上则可以采用 V8、X5 等。\n* 最下层则是分 Android 和 iOS 端去进行渲染。\n\n### 发展现状\n\n实际上，React Native 最初提出这种解决方案的时候，市面上并没有同类的产品，但是由于 React Native 的一些问题和其他原因，各个大公司基本都在实现自己的跨端融合方案，这里 React Native 的问题主要体现在：\n\n* 最主要的是协议风险。\n* React Native 打包出来的 JSBundle 较大，并且默认没有灵活的分包机制，需要自行解决相关问题。\n* 在部分组件比如 List 组件中，性能较差（据非官方说法，性能并不是 React Native 团队首要考察因素，但是国内团队一般都比较重视性能）。\n* 部分事件发送频繁导致性能损失、例如列表滚动事件、手势事件等。\n* 双端 API 大量没有对齐（这也和其 slogan 是‘learn once, write everywhere’ 而不是 ‘write once, run everywhere’ 相对应）。\n\n而对于国内的 Weex 和 Hippy 框架，其都做了大量的性能优化解决了上述问题，并且规避了协议风险（Weex 采用了 Apache 2.0 协议，而 Hippy 即将开源）。\n\n另外值得一提的是，Weex 和 Hippy 都可以在 web 端进行运行，一般可以作为降级方案使用，从而真正做到了“一份代码”，三端运行。\n\n### 性能优化\n\n实际上，采用目前的跨端融合方案的体验已经比采用 WebView 的方案强太多了，但是性能优化是没有止境的，随着页面复杂度的提高以及用户体验的要求，实际上目前这类跨端融合方案采用了以下几个方向的性能和用户体验优化：\n\n#### 减少网络请求\n\n在我们上述提供的架构图中，一般而言对于一个这类页面，业务代码是通过网络请求加载的，这个时候在加载上主要省去的是 WebView 的初始化时间，这其实是不够的，所以我们也可以采用将业务代码提前下发并存在用户本地，打开的时候只需要从本地拉取并执行代码，这样可以减少相关的网络请求阻塞，优化加载时间。\n\n另外，减少网络请求还体现在对资源的缓存上，对一个页面中所采用的图片等资源文件进行 LRU 策略的缓存，从而防止重复的请求（在传统的 WebView 的方案上，也可以采用对 WebView 增加 Hook 的方式实现）。\n\n当然，以上两点在 WebView 的方案上也可以采用。\n\n#### 降低通信成本\n\n我们从上文的架构图中可以看出，这里的层级实际上比较多，如果不同层级的通信数据较多，并且有比较频繁甚至重复的编解码操作，肯定会有很大的开销，从而影响性能，所以，在不同层级之间做好数据的传递，并且防止重复的编解码操作是比较重要的。\n\n这里可以优化的细节其实比较多，我们举一个 Hippy 的例子：\n\n在 Hippy 架构中，jsRuntime 会生成一个 jsObject 对象树（即需要渲染的 DOM 信息），其在经过 JSBridge 时需要通过`JSON.stringify` 进行序列化，而在 Java（andriod) 接收端，则需要先将其变成一个 JsonObject，最终转化成 HippyMap，这里实际上是有重复的编解码操作的，我们看看 Hippy 的优化策略：\n\n![](/img/3.jpg)\n\n>图片来自 IMWeb 2018\n\n通过 hippybuffer 的方式减少通信的数据量，并且防止重复的编解码操作，可以有效提高性能。\n\n#### 减少通信次数\n\n为了减少在通信方面的消耗，我们除了降低通信的成本，还可以做的就是减少通信次数，当然，前提是不影响用户体验。\n\n这方面可以减少的通信消耗，其中一个方面是频繁的事件通信，我们知道，事件的触发是在 native 端的，但是事件处理的逻辑代码实际上是在 js 层来完成的，在这方面的通信，React Native 就因为频繁的通信从而影响了性能。\n\n我们可以优化的地方在于，首先减少没有绑定回调函数的事件通信，一般而言这部分通信是不必要的，其次是多次通信可以进行合并，比如说 list 滚动回调函数、以及动画通信，我们可以通过配置驱动代替数据驱动的方式（即一次向客户端传递整个配置，后续相同事件可以直接在客户端进行处理），来减少通信次数。\n\n这方面 Hippy 和 Weex 都有大量细碎的实践，在此便不具体介绍了。\n\n#### 降低首屏时间\n\n在原来的 WebView 页面中，我们为了增强用户体验，防止用户进来之后看到白屏，可以采用服务端渲染的方式，将渲染好的页面返回给客户端，同时优化了首屏请求，也防止了客户端设备较差造成JS执行时间较长的情况。\n\n在跨端融合方案中我们仍然有类似的解决方案，在不考虑离线包的情况下（即只考虑业务代码从远程加载的情况），我们也可以由服务端渲染好再返回，Weex 便采用了类似的方案，不过其做的更加彻底，在服务端将代码结果编译成 AST 树并转化成字节码（OPcode），在客户端解析后直接生成虚拟 DOM：\n\n![](/img/2.jpg)\n\n>图片来自 IMWeb 2018\n\n#### 客户端级别的其他优化\n\n客户端的优化有一部分是本来客户端开发就会面临的内容，也有一部分是和混合方案有关的优化，比如 Flex Render 的优化，不过这方面的内容一般而言和前端关系不是非常密切，笔者作为初级前端工程师，对这方面的内容还并不熟悉。\n\n### 框架选型\n\n本文的最后一部分，介绍框架选型。\n\n对于各类跨端融合的方案，其相对于 WebView 都有非常大的性能提升，因此在前期，无论选择什么框架都能够看到成效，这里也并不进行特定的框架选型推荐，但是一般认为，如果是从 Vue 的项目切换，Weex 会更合适一点，而如果从 React 项目切换，在确保没有证书风险的情况下可以采用 React Native，否则可以尝试原生支持 React 的 Hippy。\n\n以上。\n\n\n","tags":["跨端融合"]},{"title":"Node.js 的 TCP 链接管理","url":"/2018/11/25/Node-js的TCP链接管理/","content":"\n在 Node.js 的微服务中，一般不同的服务模块我们会采用 TCP 进行通信，本文来简单谈一谈如何设计 TCP 服务的基础管理。\n\n>在具体设计上，本文参考了微服务框架 [Seneca](https://github.com/senecajs/seneca) 所采用的通信方案 [Seneca-transport](https://github.com/senecajs/seneca-transport)，已经被实践所证明其可行性。\n\n一提到 TCP 通信，我们肯定离不开 `net` 模块，事实上，借助 `net` 模块，我们也可以比较快速地完成一般的 TCP 通信的任务。\n\n为了避免对基础的遗忘，我们还是先附上一个基本的 TCP 链接代码：\n\n```javascript\n//server.js:\nconst net = require('net');\n\nconst server = net.createServer((socket) => {\n    socket.write('goodbye\\n');\n    socket.on('data', (data) => {\n        console.log('data:', data.toString());\n        socket.write('goodbye\\n');\n    })\n}).on('error', (err) => {\n    throw err;\n});\n\n// grab an arbitrary unused port.\nserver.listen(8024, () => {\n    console.log('opened server on', server.address());\n});\n\n//client.js:\nconst net = require('net');\n\nconst client = net.createConnection({ port: 8024 }, () => {\n    //'connect' listener\n    console.log('connected to server!');\n    client.write('world!\\r\\n');\n    setInterval(() => {\n        client.write('world!\\r\\n');\n    }, 1000)\n});\nclient.on('data', (data) => {\n    console.log(data.toString());\n    // client.end();\n});\nclient.on('end', () => {\n    console.log('disconnected from server');\n});\n```\n\n其实，上述已经是一个几乎最简单的客户端和服务端通信 Demo，但是并不能在实际项目中使用，首先我们需要审视，其离生产环境还差哪些内容：\n\n1. 以上要求 Server 端要在 Client 端之前启动，并且一旦因为一些错误导致 Server 端重启了并且这个时候 Client 端正好和 Server 端进行通信，那么肯定会 crash，所以，我们需要一个更为平滑兼容的方案。\n2. 以上 TCP 链接的 Server 部分，并没有对 connection 进行管理的能力，并且在在以上的例子中，双方都没有主动释放链接，也就是说，建立的是一个 TCP 长连接。\n3. 以上链接的处理数据能力有限，只能处理纯文本的内容，并且还有一定的风险性（你也许会说可以用 JSON 的序列化反序列化的方法来处理 JSON 数据，但是你别忘了 `socket.on('data'...` 很可能接收到的不是一个完整的 JSON，如果 JSON 较长，其可能只接收到一般的内容，这个时候如果直接 `JSON.parse())` 很可能就会报错）。\n\n以上三个问题，便是我们要解决的主要问题，如果你看过之后立刻知道该如何解决了，那么这篇文章可能你不需要看了，否则，我们可以一起继续探索解决方案。\n\n### 使用 reconnect-core\n\n[reconnect-core](https://www.npmjs.com/package/reconnect-core) 是一个和协议无关的链接重试算法，其工作方式也比较简单，当你需要在 Client 端建立链接的时候，其流程是这样的：\n\n* 调用事先传入的链接建立函数，如果这个时候返回成功了，即成功建立链接。\n* 如果第一次建立链接失败了，那么再隔一段时间建立第二次，如果第二次还是失败，那么再隔一段更长的时间建立第三次，如果还是失败，那么再隔更长的一段时间……直到到达最大的尝试次数。\n\n实际上关于尝试的时间间隔，也会有不同的策略，比较常用的是 Fibonacci 策略和 exponential 策略。\n\n当然，关于策略的具体实现，reconnect-core 采用了一个 [backoff](https://www.npmjs.com/package/backoff) 的库来管理，其可以支持  Fibonacci 策略和 exponential 策略以及更多的自定义策略。\n\n对于上面提到的 DEMO 代码。我们给出 Client 端使用 reconnect-core 的一个实现：\n\n```javascript\n//client.js:\nconst Reconnect = require('reconnect-core');\nconst net = require('net');\nconst Ndjson = require('ndjson');\n\nconst Connect = Reconnect(function() {\n    var args = [].slice.call(arguments);\n    return net.connect.apply(null, args)\n});\n\nlet connection = Connect(function(socket) {\n    socket.write('world!\\r\\n');\n    socket.on('data', (msg) => {\n        console.log('data', msg.toString());\n    });\n    socket.on('close', (msg) => {\n        console.log('close', msg).toString();\n        connection.disconnect();\n    });\n    socket.on('end', () => {\n        console.log('end');\n    });\n});\n\nconnection.connect({\n    port: 8024\n});\nconnection.on('reconnect', function () {\n    console.log('on reconnect...')\n});\nconnection.on('error', function (err) {\n   console.log('error:', err);\n});\nconnection.on('disconnect', function (err) {\n   console.log('disconnect:', err);\n});\n```\n>采用 Reconnect 实际上相比之前是多了一层内容，我们在这里需要区分 connection 实例和 socket 句柄，并且附加正确的时间监听。\n\n现在，我们就不用担心到底是先启动服务端还是先启动客户端了，另外，就算我们的服务端在启动之后由于某些错误关闭了一会，只要没超过最大时间（而这个也是可配置的），仍然不用担心客户端与其建立连接。\n\n\n### 给 Server 端增加管理能力\n\n给 Server 端增加管理能力是一个比较必要的并且可以做成不同程度的，一般来说，最重要的功能则是及时清理链接，常用的做法是收到某条指令之后进行清理，或者到达一定时间之后定时清理。\n\n这里我们可以增加一个功能，达到一定时间之后，自动清理所有链接：\n\n```javascript\n//server.js\nconst net = require('net');\n\nvar connections = [];\n\nconst server = net.createServer((socket) => {\n    connections.push(socket);\n    socket.write('goodbye\\n');\n    socket.on('data', (data) => {\n        console.log('data:', data.toString());\n        socket.write('goodbye\\n');\n    })\n}).on('error', (err) => {\n    throw err;\n});\n\nsetTimeout(() => {\n    console.log('clear connections');\n    connections.forEach((connection) => {\n        connection.end('end')\n        // connection.destory()\n    })\n}, 10000);\n\n// grab an arbitrary unused port.\nserver.listen(8024, () => {\n    console.log('opened server on', server.address());\n});\n```\n\n我们可以通过`connection.end('end')` 和 `connection.destory()` 来清理，一般来说，前者是正常情况下的关闭指令，需要 Client 端进行确认，而后者则是强制关闭，一般在出错的时候会这样调用。\n\n### 使用 ndjson 来格式化数据\n\n[ndjson](https://www.npmjs.com/package/ndjson) 是一个比较方便的 JSON 序列化/反序列化库，相比于我们直接用 JSON，其好处主要体现在：\n\n* 可以同时解析多个 JSON 对象，如果是一个文件流，即其可以包含多个 `{}`，但是要求则是每一个占据一行，其按行分割并且解析。\n* 内部使用了 [split2](https://www.npmjs.com/package/split2)，好处就是其返回时可以保证该行的所有内容已经接受完毕，从而防止 ndjson 在序列化的时候出错。\n\n关于 ndjson 的基本使用，可以根据上述链接查找文档，这里一般情况下，我们的使用方式如下（以下是一个 demo）：\n\n```javascript\n//server.js:\nconst net = require('net');\n\nvar connections = [];\n\nconst server = net.createServer((socket) => {\n    connections.push(socket);\n    socket.on('data', (data) => {\n        console.log('data:', data.toString());\n        socket.write('{\"good\": 1234}\\r\\n');\n        socket.write('{\"good\": 4567}\\n\\n');\n    })\n}).on('error', (err) => {\n    throw err;\n});\n\n// grab an arbitrary unused port.\nserver.listen(8024, () => {\n    console.log('opened server on', server.address());\n});\n\n//client.js:\nconst Reconnect = require('reconnect-core');\nconst net = require('net');\nconst Ndjson = require('ndjson');\nvar Stream = require('stream');\n\nconst Connect = Reconnect(function() {\n    var args = [].slice.call(arguments);\n    return net.connect.apply(null, args)\n});\n\nlet connection = Connect(function(socket) {\n    socket.write('world!\\r\\n');\n    var parser = Ndjson.parse();\n    var stringifier = Ndjson.stringify();\n\n    function yourhandler(){\n        var messager = new Stream.Duplex({ objectMode: true });\n        messager._read = function () {\n            // console.log('data:', data);\n        };\n        messager._write = function (data, enc, callback) {\n            console.log(typeof data, data);\n            // your handler\n            return callback()\n        };\n        return messager\n    }\n    socket // 链接句柄\n        .pipe(parser)\n        .pipe(yourhandler())\n        .pipe(stringifier)\n        .pipe(socket);\n\n    socket.on('close', (msg) => {\n        console.log('close', msg).toString();\n        connection.disconnect();\n    });\n    socket.on('end', (msg) => {\n        console.log('end', msg);\n    });\n});\nconnection.connect({\n    port: 8024\n});\nconnection.on('reconnect', function () {\n    console.log('on reconnect...')\n});\nconnection.on('error', function (err) {\n   console.log('error:', err);\n});\nconnection.on('disconnect', function (err) {\n   console.log('disconnect:', err);\n});\n```\n\n其中，用户具体的逻辑代码，可以是 `yourhandler` 函数 `_write` 里面的一部分，其接收的是一个一个处理好的对象。\n\n","tags":["Node.js","TCP"]},{"title":"多组件单页列表应用的代码组织实践","url":"/2018/11/10/多组件单页列表应用的代码组织实践/","content":"\n本文主要对多组件单页面列表应用的代码组织实践进行总结，从而给相关应用的 Web 开发提供参考。\n\n### 什么是多组件单页面列表应用？\n\n目前，其实多组件单页面列表应用非常常见，也是我们日常生活中使用非常高频的一个类别的应用，最典型的比如新闻信息流产品腾讯新闻、今日头条等这类新闻应用，在这类新闻应用中，往往图片、图文、视频、问答、投票等多种模块混杂排列。再简单一点的话，知乎、豆瓣甚至一些论坛以及一些购物软件，也可以归为此类应用。\n\n由于笔者在负责QQ看点搜索模块的相关内容， 因此，这里给出一个QQ看点搜索的展示图：\n\n![](/img/kd.jpg)\n\n这类应用其实有如下特点：\n\n* 属于长列表滚动，内容随着滚动不断加载，一般在用户返回之前可能积累了大量的内容，因此可能会造成一定的性能问题。\n* 模块众多，并且模块的种类和样式更新迭代快，这给我们在复用组件的选择上带来了挑战，如果我们盲目复用组件，则会造成胶水代码越来越多，如果不复用组件，那么代码量会随着业务发展线性增长，这都给我们后续的维护带来了挑战。\n\n当然，一般的基于 Web 的应用（实际上，QQ看点搜索并不完全是纯粹的 WebView 应用）所面临的问题这里也都会遇到。不过，上述两类问题应该算是这类应用的比较重要的问题，其实归根到底，前者是性能问题（面向用户），后者是维护问题（面向开发者）。\n\n如何解决这里的性能问题，其实已经有很多常规的方案可以借鉴了，这并不是本篇文章的重点，除了传统 Web 用到的性能优化方法，这里仅仅列举一些常规的做法：\n\n* 图片等资源的懒加载。\n* 列表虚拟滚动，即使用有限的元素，优化CSS写法等。\n* 使用跨端融合方案渲染，例如 Weex、ReactNative、Hippy 等。\n\n### 多组件单页面应用的维护困境\n\n对于这类多组件单页面应用，一般都是增量发展的，即最开始只有很个别的几个模块，随着业务越来越复杂，模块越来越多，逻辑也越来越复杂。\n\n我们一开始，肯定可以想到一个模块（即上文中灰色分割线分割的一块）是一个组件，不同组件之间抽离出公共的函数，或者采用 mixin 将公共的部分抽离，至于数据端，由于这类应用通常在深度上不复杂，直接采用 React 或者 Vue 提供的父子组件通信的方式一般就够用了。这样设计既满足组件化的思路，也能够方便的维护项目，比较适合项目的初期。\n\n但是随着项目发展，我们会发现，问题慢慢地产生了：\n\n* 单元组件非常不好界定，比如一个左图右文的图文混排组件（例如刘亦菲的热点），之后又会增加左视频右文字，和图文展示的区别不大但是加了视频的播放时长，之后又加了左视频集合右文字（例如双世宠妃第一部分），如果我们把这多类内容当作一个组件，我们的组件中就会有非常多的判断代码，那么就会有大量的代码冗余，或者设计复杂的 mixin 和工具函数。\n* 除了我们自身的问题，往往随着内容增多，后端返回的数据内容也会非常的不一致，在相似甚至相同的组件中，数据格式也不尽相同，我们需要在我们的单元组件中，来解析判断多种数据格式。\n* 第三点就是样式更新隐患，当我们的组件多了之后，如果我们对我们的组件进行更新，那么很可能需要同时更新多处（嗯，全局替换也许是个不错的主意），这也是相当有风险的，也许会无意间改动我们并不想改动的 UI。\n\n如果我们等项目复杂后面对这个问题，我们会发现改动前期的代码工作量比较巨大，但是这又是我们不得不做的事情，这类问题的产生，实际上主要原因是我们的组件设计规划的不合理，我们完全可以在最初的项目中，通过一定的设计规划，来规避这些问题。\n\n### 多组件单页面应用的组件规划\n\n既然，我们现在希望设计一套比较好的组件规划，我们就需要重新审视我们的项目，对于我们的项目而言，一个业务模块一个组件的方式，的确简单方便，但是这样粗放的组件划分原则，实际上并不能完全满足我们复杂的维护需求，反而会给我们带来困扰。\n\n经过一系列的重构和整理，目前QQ看点搜索的组件规划逻辑是这样的：\n\n![](/img/kds.jpg)\n\n这里为了方便理解，我们采取上面样例图片中比较常见的一类业务：图文混排条目（左图右文和右图左文）来进行举例，如何设计组件来让提高我们项目的可维护性。\n\n这里首先是零件层，零件层应该有如下内容：\n\n* 图片零件，定宽，定高，自带懒加载，正常情况下只需传入一个 URL 即可使用。\n* 标题组件，一行标题和两行标题可以设计成两个组件，但进行 CSS 层面的复用。\n* 描述内容组件，例如双世宠妃的两行剧集描述。\n* 元信息内容组件，例如普通图文的来源和发表时间。\n* 时长组件，视频图文中用到。\n* 带有描述性的图片组件，视频图文中用到。\n* 图标组件：可以承载图标。\n\n以上各个组件的内容，几乎都足够简单，只需传入一个 props 作为内容，一般情况下，组件中不能出现 if 或 switch 等逻辑。\n\n接下来是组合器部分，组合器也是零件，只不过是零件的组合，其实也可以设计的比较薄弱，从而将更多的功能在布局器中完成，但是个别的时候，有这一层会给我们带来一定的方便，这里比如：\n\n* 图标+文字的组合器标题。\n\n对于零件层和组合层，一般情况下都不需要有影响外部的 margin 和 padding，即如果不增加任何多余样式罗列零件层和组合层，其上下左右四边应该是互相贴合的。\n\n接下来是布局层，这里的布局层，其实可以进行多种方式的设计，根据设计不同其数目也不同，这里给出一种设计方式：\n\n* 第一种是左图右文形式，右边可以选择普通图片、普通图片+时长组件、普通图片+描述。右边可以在一行标题、两行标题、描述零件、元信息零件中任意选择和组合。\n* 第二种是右图左文形式，左边的可配置内容和上文右边相同。\n\n当然，这两种整合成一种也无妨。\n\n在布局层，是拥有事件能力的，但是其主要应该是绑定响应时间并且调用通过 props 传入的回调函数，其不应该自己执行事件的响应逻辑。\n\n最后是控制器层，**在控制器层，除了包裹标签之外，不应该出现任何 html 标签，其也不应当引用除了布局层组件以外的更深层次的组件。控制层的主要作用是进行数据处理。**\n\n控制层的分类方式和上述几层稍有不同，这里，我们就不是按照 UI 来分不同的控制器了，而是按照数据或者业务来分类，因为这里我们主要是进行数据逻辑的处理，和 UI 的关系不是那么重要了（已经将 UI 的压力进行了下沉）。\n\n通过上述的做法，之后如果有新的需求增加进来，我们根据需要，在不同层级的组件增加内容就好了。\n\n### 总结\n\n通过以上的逻辑，我们把组件划分的更加清晰明确，将 UI 展示和数据逻辑分离，并且方便我们对样式进行迭代升级。\n\n当然，这个时候你也许还会问，如果我对部分组件样式进行升级改造，怎么样防止对原有的样式无影响呢？暂时还没有好的办法，不过，我们正在做的 UI 自动化测试套件——mangosteen，可以完美解决这个问题，敬请期待。","tags":["组件化"]},{"title":"使用 Node.js 打造多用户实时监控系统","url":"/2018/10/21/使用 Node.js 打造多用户实时监控系统/","content":"\n### 背景概述\n\n首先描述一下笔者遇到的问题，我们可以设定这样一个场景：现在有一个实时监控系统的开发需求，要求同时支持多个用户（这里我们为了简化，暂时不涉及登陆态，假定一个设备即为一个用户），对于不同的用户来讲，他们需要监控的一部分内容是完全相同的，比如设备的 CPU 信息、内存信息等，而另外一部分内容是部分用户重叠的，比如对某一区域的用户来说某些监控信息是相同的，而还有一些信息，则是用户之间完全不同的。\n\n对于每个用户来讲，当其进入页面之后即表明其开始监控，需要持续地进行数据更新，而当其退出界面或者手动点击停止监控，则停止监控。\n\n### 问题描述\n\n实际上，对于以上情况，我们很容易想到通过 WebSocket，对不同的用户进行隔离处理，当一个用户开始监控的时候，通过函数来逐个启动其所有的监控项目，当其停止监控的时候，取消相关监控，并且清除无关变量等。我们可以将所有内容写到 WebSocket 的连接回调中，由于作用域隔离，不同用户之间的监控（读操作）不会产生互相影响。\n\n这种方式可以说是最为快捷方便的方式了，并且几乎无需进行设计，但是这样有一个非常明显的效率问题：\n\n由于不同用户的部分监控项目是有重叠的，对于这些重叠的项目，我们如果对于每一个用户都单独监控，那么就会产生非常多的浪费，如果这些监控中还涉及到数据库交互或者较为复杂的计算，那么成倍之后的性能损失是非常难以承受的。\n\n所以，我们需要将不同用户重叠的那些监控项目，进行合并，合并成一个之后，如果有新的消息，我们就推到所有相关用户的回调函数中去处理。\n\n也就是说，我们需要管理一个一对多的订阅发布模式。\n\n到这里，我们发现我们想要实现这样一个监控系统，并不是非常简单，主要有下列问题：\n\n* [1]对于可能有用户重叠的监控项目，我们需要抽离到用户作用域之外，并且通过统计计数等方式来\"记住\"当前所有的监控用户，当有新内容时推到各个用户的处理函数中，并且当最后一个用户取消监控的时候要及时清理相关对象。\n* [2]不同用户的重叠监控项目的监控方式也各不相同，有的是通过 `setInterval` 等方式的定时任务，有的是事件监听器等等。\n* [3]判断不同用户的项目是否重叠也有一定的争议，比如假设不同用户端监控的是同一个项目，调用的也是相同的函数，但是由于用户 ID 不同，这个时候我们如何判断是否算\"同一个监控\"？\n\n以上的这些问题，如果我们不借助现有的库和工具，自己顺着思路一点点去写，则很容易陷入修修补补的循环，无法专注监控本身，并且最后甚至在效率上适得其反。\n\n### 解决方案\n\n以下解决方案基于 Rx.js，需要对 [Observable](https://cn.rx.js.org/class/es6/Observable.js~Observable.html) 有一定了解。\n\n#### 多个用户的监控以及取消\n\n[Monitor-RX](https://github.com/aircloud/monitor-rx) 是对以上场景问题的一个解决方案封装，其利用了 Rx.js 对订阅发布的管理能力，可以让整个流程变的清晰。\n\n在 Rx.js 中，我们可以通过以下方式建立一个多播对象 `multicasted`：\n\n```\nvar source = Rx.from([1, 2, 3]);\nvar subject = new Rx.Subject();\nvar multicasted = source.pipe(multicast(subject)).refCount();\n// 其属于 monitor-rx 的实现细节，无需理解亦可使用 monitor-rx\n\nsubscription1 = refCounted.subscribe({\n    next: (v) => console.log('observerA: ' + JSON.stringify(v))\n});\n\nsetTimeout(() => {\n    subscription2 = refCounted.subscribe({\n        next: (v) => console.log('observerB: ' + JSON.stringify(v))\n    });\n}, 1200);\n\nsubscription1.unsubscribe();\nsetTimeout(() => {\n    subscription2.unsubscribe();\n    // 这里 refCounted 的 unsubscribe 相关清理逻辑会自动被调用\n}, 3200);\n```\n\n在这里采用多播，有如下几个好处：\n\n* 可以随时增加新的订阅者，并且新的订阅者只会收到其加入订阅之后的数据。\n* 可以随时对任意一个订阅者取消订阅。\n* 当所有订阅者取消订阅之后，Observable 会自动触发 Observable 函数，从而可以对其事件循环等进行清理。\n\n以上能力其实可以帮助我们解决上文提到的问题 [1]。\n\n#### 监控格式的统一\n\n实际上，在我们的监控系统中，从数据依赖的角度，我们的监控函数会有这样几类：\n\n* [a]纯粹的定时任务，无数据依赖，这方面比如当前内存快照数据等。\n* [b]带有记忆依赖的定时任务：定时任务依赖前一次的数据（甚至更多次），需要两次数据做差等，这方面的数据比如一段时间的消耗数据，cpu 使用率的计算。\n* [c]带有用户依赖的定时任务：依赖用户 id 等信息，不同用户无法共用。\n\n而从任务触发的角度，我们仍待可以对其分类：\n\n* [i]简单的 `setInterval` 定时任务。\n* [ii]基于事件机制的不定时任务。\n* [iii]基于其他触发机制的任务。\n\n实际上，我们如果采用 Rx.js 的模式进行编写，无需考虑任务的数据依赖和触发的方式，只需写成一个一个 Observable 实例即可。另外，对于比较简单的 [a]&[i] 或 [c]&[i]  类型，我们还可以通过 monitor-rx 提供的 `convertToRx` 或 `convertToSimpleRx` 转换成 Observable 实例生成函数，例如：\n\n```\nvar os = require('os');\nvar process = require('process');\nconst monitorRx = require('monitor-rx');\n\nfunction getMemoryInfo() {\n    return process.memoryUsage();\n}\n\nconst memory = monitorRx.Utils.convertToSimpleRx(getMemoryInfo)\n\n// 或者\n//const memory = monitorRx.Utils.convertToRx({\n//    getMemoryInfo\n//});\n\nmodule.exports = memory;\n```\n\nconvertToRx 相比于 convertToSimpleRx，可以支持函数配置注入（即下文中 opts 的 func 属性和 args 属性）,可以在具体生成 Observable 实例的时候具体指定使用哪些函数以及其参数。\n\n如果是比较复杂的 Observable 类型，那么我们就无法直接通过普通函数进行转化了，这个时候我们遵循 Observable 的标准返回 Observable 生成函数即可（不是直接返回 Observable 实例） \n\n这实际上也对问题 [2] 进行了解决。\n\n#### 监控唯一性：\n\n我们知道，如果两个用户都监控同一个信息，我们可以共用一个 Observable，这里的问题，就是如何定义两个用户的监控是\"相同\"的。\n\n这里我们采用一个可选项 opts 的概念，其一共有如下属性：\n\n```\n{\n    module: 'ModuleName',\n    func: ['FuncName'],\n    args: [['arg1','arg2']],\n    opts: {interval:1000}, \n}\n```\n\nmodule 即用户是对哪一个模块进行监控（实际上是 Observable），func 和 args 则是监控过程中需要调用的函数，我们也可以通过 agrs 传入用户个人信息。于没有内部子函数调用的监控，二者为空即可，opts 是一些其他可选项，比如定义请求间隔等。\n\n之后，我们通过 `JSON.stringify(opts)` 来序列化这个可选项配置，如果两个用户序列化后的可选项配置相同，那么我们就认为这两个用户可以共用一个监控，即共用一个 Observable。\n\n### 更多内容\n\n实际上，借助 Monitor-RX，我们可以很方便的解决上述提出的问题，Monitor-RX 也在积极的更新中，大家可以在[这里](https://github.com/aircloud/monitor-rx)了解到更多的信息。","tags":["Node.js","javascript","Rx.js"]},{"title":"从源码分析sentry的错误信息收集","url":"/2018/08/18/从源码分析sentry的错误信息收集/","content":"\nraven.js 是 sentry 为 JavaScript 错误上报提供的 JS-SDK，本篇我们基于其源代码对其原理进行分析，本篇文章只分析前端部分，对应的文件目录是`https://github.com/getsentry/sentry-javascript/tree/master/packages/raven-js`。\n\n首先抛出几个问题：\n\n* **raven.js 是如何收集浏览器错误信息的？**\n* **raven.js 上报的错误信息格式是什么样的？又是如何把这些信息传给后端？支不支持合并上报？**\n* **面包屑（breadcrumbs）是什么？raven.js 如何来收集面包屑信息？**\n* **raven.js 如何和框架配合使用（比如 vue、react）？**\n\n在回答以上这几个问题之前，我们首先来对 raven.js 做一个宏观的分析，主要涉及其文件目录、所引用的第三方框架等。\n\nraven.js 的核心文件内容并不多，其中使用了三个第三方库，放在了 vendor 文件夹下：\n\n* [json-stringify-safe](https://github.com/moll/json-stringify-safe) ：一个对 `JSON.stringify` 的封装，安全的 json 序列化操作函数，不会抛出循环引用的错误。\n\t* 这里面有一个注意点要单独说一下，我们熟知的 `JSON.stringify` , 可以接受三个参数：第一个参数是我们要序列化的对象；第二个参数是对其中键值对的处理函数；第三个参数是控制缩进空格。reven.js 的 `json-stringify-safe` 就是充分利用了这三个参数。\n* [md5](https://github.com/blueimp/JavaScript-MD5)：js 的 md5 函数。\n* [TraceKit](https://github.com/csnover/TraceKit)：TraceKit 是一个已经比较完善的错误收集、堆栈格式化的库，reven.js 的功能在很大程度上对它有所依赖。\n\n除此之外，raven.js 支持插件，官方提供的一些知名库的 sentry 插件主要放在了 plugin 文件夹下面，raven.js 的一些核心文件，则放在了 src 文件夹下面。\n\n### raven.js 是如何收集错误信息的？\n\n我们知道，在前端收集错误，肯定离不开 `window.onerror` 这个函数，那么我们就从这个函数说起。\n\n实际上，这部分工作是 raven.js 引用的第三方库 TraceKit 完成的：\n\n```\nfunction installGlobalHandler() {\n  if (_onErrorHandlerInstalled) { // 一个起到标志作用的全局变量\n    return;\n  }\n  _oldOnerrorHandler = _window.onerror; \n  // _oldOnerrorHandler 是防止对用户其他地方定义的回调函数进行覆盖\n  // 该 _window 经过兼容，实际上就是 window\n  _window.onerror = traceKitWindowOnError;\n  _onErrorHandlerInstalled = true;\n}\n```\n\n相关错误回调函数交给 traceKitWindowOnError 处理，下面我们来看一下 traceKitWindowOnError 函数，为了避免太多冗余代码，我们仅分析一种主要情况：\n\n```\nfunction traceKitWindowOnError(msg, url, lineNo, colNo, ex) {\n\t\n\tvar exception = utils.isErrorEvent(ex) ? ex.error : ex;\n\t//...\n    stack = TraceKit.computeStackTrace(exception);\n    notifyHandlers(stack, true);\n    //...\n   \n    //...\n    if (_oldOnerrorHandler) {\n       return _oldOnerrorHandler.apply(this, arguments);\n    }\n    return false;\n}\n```\n\n其中调用的最重要的一个函数，就是 computeStackTrace，而这个函数也是 TraceKit 的核心函数，简单来讲，它做的事情就是统一格式化报错信息调用栈，因为对于各个浏览器来说，返回的 Error 调用栈信息格式不尽相同，另外甚至还有的浏览器并不返回调用栈，computeStackTrace 函数对这些情况都做了兼容性处理，并且对于一些不返回调用栈的情况，还使用了 caller 来向上回溯函数的调用栈，最终把报错信息转化成一个键相同的对象数组，做到了报错信息格式的统一。\n\nnotifyHandlers 函数则是通知相关的回调函数。 实际上，raven.js 在 install 函数中会调用 TraceKit.report.subscribe 函数，并把对错误的处理逻辑写入回调：\n\n```\nfunction subscribe(handler) {\n    installGlobalHandler();\n    handlers.push(handler);\n}\n```\n\n以上过程完成了错误处理过程中的负责角色转换，并且借助 TraceKit，可以使 raven.js 得到一个结构比较清晰的带有格式化好的调用栈信息的错误内容对象，之后，raven.js 对错误内容进一步处理并最终上报。\n\n下面我们对错误处理 raven.js 控制的部分做了一些梳理：\n\n```\n _handleOnErrorStackInfo: function(stackInfo, options) {\n    options.mechanism = options.mechanism || {\n      type: 'onerror',\n      handled: false\n    };\n    // mechanism 和错误统计来源有关\n\n    if (!this._ignoreOnError) {\n      this._handleStackInfo(stackInfo, options);\n    }\n},\n\n_handleStackInfo: function(stackInfo, options) {\n    var frames = this._prepareFrames(stackInfo, options);\n\n    this._triggerEvent('handle', {\n      stackInfo: stackInfo,\n      options: options\n    });\n\n    this._processException(\n      stackInfo.name,\n      stackInfo.message,\n      stackInfo.url,\n      stackInfo.lineno,\n      frames,\n      options\n    );\n},\n\n_processException: function(type, message, fileurl, lineno, frames, options) {\n    // 首先根据 message 信息判断是否是需要忽略的错误类型\n    // 然后判断出错的文件是否在黑名单中或者白名单中\n    // 接下来对错误内容进行必要的整合与转换，构造出 data 对象\n    // 最后调用上报函数\n    this._send(data);\n}\n\n_send: function(data) {\n\t\n\t// 对 data 进一步处理，增加必要的信息，包括后续会提到的面包屑信息\n\n\t// 交由 _sendProcessedPayload 进行进一步处理\n\tthis._sendProcessedPayload(data);\n}\n\n_sendProcessedPayload: function(data, callback) {\n\n\t// 对 data 增加一些必要的元信息\n\t// 可以通过自定义 globalOptions.transport 的方式来自定义上报函数 \n\t(globalOptions.transport || this._makeRequest).call(this, {\n\t     url: url,\n\t     auth: auth,\n\t     data: data,\n\t     options: globalOptions,\n\t     onSuccess: function success() {\n\t       \n\t     },\n\t     onError: function failure(error) {\n\t       \n\t     }\n\t});\n}    \n\n// 真正发起请求的函数\n_makeRequest: function(opts) {\n\t// 对于支持 fetch 的浏览器，直接使用 fetch 的方式发送 POST 请求\n\t// 如果浏览器不支持 fetch，则使用 XHR 的传统方式发送 POST 请求\n}\n``` \n\n实际上我们可以发现，从拿到已经初步格式化的报错信息，到最终真正执行数据上报，raven.js 的过程非常漫长，这其中我分析有如下几个原因：\n\n* 每个函数只处理一件或者一些事情，保持函数的短小整洁。\n* 部分函数可以做到复用（因为除了自动捕获错误的方式， raven.js 还提供通过 captureException，即 `try {\n    doSomething(a[0])\n} catch(e) {\n    Raven.captureException(e)\n}` 的方式来上报错误，两个过程中有一些函数的调用是有重叠的）。\n\n但是笔者认为，raven.js 的代码设计还有很多值得优化的地方，比如：\n\n* 对最终上报数据（data）的属性处理和增加分散在多个函数，并且有较多可选项目，很难梳理出一个完整的 data 格式，并且不便于维护。\n* 部分函数的拆分必要性不足，并且会增加链路的复杂性，比如 `_processException `、`_sendProcessedPayload `、`_makeRequest `等都只在一个链路中被调用一次。\n* 部分属性重命名会造成资源浪费，由于 TraceKit 部分最终返回的数据格式并不完全满足 raven.js 的需要，所以 raven.js 之后又在较后阶段进行了重命名等处理，实际上这些内容完全可以通过一些其他的方式避免。\n\n最后，非常遗憾，sentry 目前完全不支持合并上报，就算是在同一个事件循环（甚至事件循环的同一个阶段，关于事件循环，可以参考我之前绘制的[一张图](https://www.processon.com/view/link/5b6ec8cbe4b053a09c2fb977)）的两个错误，sentry 都是分开来上报的，这里有一个简单例子：\n\n```javascript\nRaven.config('http://8ec3f1a9f652463bb58191bd0b35f20c@localhost:9000/2').install()\nlet s = window.ss;\n\ntry{\n    let b = s.b\n} catch (e) {\n    Raven.captureException(e)\n    // sentry should report error now\n}\n\ns.nomethod();\n// sentry should report error now\n```\n\n以上例子中，sentry 会发送两个 POST 请求。\n\n### raven.js 最终上报数据的格式\n\n\n这一部分，我们并不会详细地分析 raven.js 上报的数据的每一项内容，仅会给读者展示一个比较典型的情况。\n\n我们看一下对于一个一般的 js 错误，raven.js 上报的 json 中包含哪些内容，下面是一个已经删掉一些冗余内容的典型上报信息：\n\n```\n{\n  \"project\": \"2\",\n  \"logger\": \"javascript\",\n  \"platform\": \"javascript\",\n  \"request\": {\n    \"headers\": {\n      \"User-Agent\": \"Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1\"\n    },\n    \"url\": \"http://localhost:63342/sentry-test1/test1.html?_ijt=j54dmgn136gom08n8v8v9fdddu\"\n  },\n  \"exception\": {\n    \"values\": [\n      {\n        \"type\": \"TypeError\",\n        \"value\": \"Cannot read property 'b' of undefined\",\n        \"stacktrace\": {\n          \"frames\": [\n            {\n              \"filename\": \"http://localhost:63342/sentry-test1/test1.html?_ijt=j54dmgn136gom08n8v8v9fdddu\",\n              \"lineno\": 19,\n              \"colno\": 19,\n              \"function\": \"?\",\n              \"in_app\": true\n            }\n          ]\n        }\n      }\n    ],\n    \"mechanism\": {\n      \"type\": \"generic\",\n      \"handled\": true\n    }\n  },\n  \"transaction\": \"http://localhost:63342/sentry-test1/test1.html?_ijt=j54dmgn136gom08n8v8v9fdddu\",\n  \"extra\": {\n    \"session:duration\": 6\n  },\n  \"breadcrumbs\": {\n    \"values\": [\n      {\n        \"timestamp\": 1534257309.996,\n        \"message\": \"_prepareFrames stackInfo: [object Object]\",\n        \"level\": \"log\",\n        \"category\": \"console\"\n      },\n      // ...\n   ]\n  },\n  \"event_id\": \"ea0334adaf9d43b78e72da2b10e084a9\",\n  \"trimHeadFrames\": 0\n}\n```\n\n其中支持的信息类型重点分为以下几种：\n\n* sentry 基本配置信息，包括库本身的配置和使用者的配置信息，以及用户的一些自定义信息\n* 错误信息，主要包括错误调用栈信息\n* request 信息，主要包括浏览器的 User-Agent、当前请求地址等\n* 面包屑信息，关于面包屑具体指的是什么，我们会在下一环节进行介绍\n\n### raven.js 面包屑收集\n\n面包屑信息，也就是错误在发生之前，一些用户、浏览器的行为信息，raven.js 实现了一个简单的队列（有一个最大条目长度，默认为 100），这个队列在时刻记录着这些信息，一旦错误发生并且需要上报，raven.js 就把这个队列的信息内容，作为面包屑 breadcrumbs，发回客户端。\n\n面包屑信息主要包括这几类：\n\n* 用户对某个元素的点击或者用户对某个可输入元素的输入\n* 发送的 http 请求\n* console 打印的信息（支持配置 'debug', 'info', 'warn', 'error', 'log' 等不同级别）\n* window.location 变化信息\n\n接下来，我们对这几类面包屑信息 sentry 的记录实现进行简单的分析。\n\n实际上，sentry 对这些信息记录的方式比较一致，都是通过对原声的函数进行包装，并且在包装好的函数中增加自己的钩子函数，来实现触发时候的事件记录，实际上，sentry 总共包装的函数有：\n\n* window.setTimeout\n* window.setInterval\n* window.requestAnimationFrame\n* EventTarget.addEventListener\n* EventTarget.removeEventListener\n* XMLHTTPRequest.open\n* XMLHTTPRequest.send\n* window.fetch\n* History.pushState\n* History.replaceState\n\n>备注：这里包装的所有函数，其中有一部分只是使 raven.js 具有捕获回调函数中错误的能力（对回调函数进行包装）\n\n接下来我们看一段典型的代码，来分析 raven.js 是如何记录用户的点击和输入信息的（通过对 EventTarget.addEventListener 进行封装）：\n\n```javascript\nfunction wrapEventTarget(global) {\n      var proto = _window[global] && _window[global].prototype;\n      if (proto && proto.hasOwnProperty && proto.hasOwnProperty('addEventListener')) {\n        fill(\n          proto,\n          'addEventListener',\n          function(orig) {\n            return function(evtName, fn, capture, secure) {\n              try {\n                if (fn && fn.handleEvent) { //兼容通过 handleEvent 的方式进行绑定事件\n                  fn.handleEvent = self.wrap(\n                    {\n                      mechanism: {\n                        type: 'instrument',\n                        data: {\n                          target: global,\n                          function: 'handleEvent',\n                          handler: (fn && fn.name) || '<anonymous>'\n                        }\n                      }\n                    },\n                    fn.handleEvent\n                  );\n                }\n              } catch (err) {\n              }\n\n              var before, clickHandler, keypressHandler;\n\n              if (\n                autoBreadcrumbs &&\n                autoBreadcrumbs.dom &&\n                (global === 'EventTarget' || global === 'Node')\n              ) {\n                // NOTE: generating multiple handlers per addEventListener invocation, should\n                //       revisit and verify we can just use one (almost certainly)\n                clickHandler = self._breadcrumbEventHandler('click');\n                keypressHandler = self._keypressEventHandler();\n                before = function(evt) { // 钩子函数，用于在回调函数调用的时候记录信息\n                  if (!evt) return;\n\n                  var eventType;\n                  try {\n                    eventType = evt.type;\n                  } catch (e) {\n                    // just accessing event properties can throw an exception in some rare circumstances\n                    // see: https://github.com/getsentry/raven-js/issues/838\n                    return;\n                  }\n                  if (eventType === 'click') return clickHandler(evt);\n                  else if (eventType === 'keypress') return keypressHandler(evt);\n                };\n              }\n              return orig.call(\n                this,\n                evtName,\n                self.wrap(\n                  {\n                    mechanism: {\n                      type: 'instrument',\n                      data: {\n                        target: global,\n                        function: 'addEventListener',\n                        handler: (fn && fn.name) || '<anonymous>'\n                      }\n                    }\n                  },\n                  fn,\n                  before\n                ),\n                capture,\n                secure\n              );\n            };\n          },\n          wrappedBuiltIns\n        );\n        fill(\n          proto,\n          'removeEventListener',\n          function(orig) {\n            return function(evt, fn, capture, secure) {\n              try {\n                fn = fn && (fn.__raven_wrapper__ ? fn.__raven_wrapper__ : fn);\n              } catch (e) {\n                // ignore, accessing __raven_wrapper__ will throw in some Selenium environments\n              }\n              return orig.call(this, evt, fn, capture, secure);\n            };\n          },\n          wrappedBuiltIns\n        );\n      }\n    }\n```\n\n以上代码兼容了通过 handleEvent 的方式进行绑定事件（如果没有听说过这种方式，可以在[这里](http://www.ayqy.net/blog/handleevent%E4%B8%8Eaddeventlistener/)补充一些相关的知识）。\n\n默认情况下，raven.js 只记录通过 `EventTarget.addEventListener` 绑定的点击和输入信息，实际上这是比较科学的，并且这些信息较为有效。另外，raven.js 也提供了记录所有点击和输入信息的可选项，其实现方式更为简单，直接在 document 上添加相关的监听即可。\n\n### raven.js 如何和框架配合使用\n\nraven.js 和框架配合使用的方式非常简单，但是我们要知道，很多框架内置了错误边界处理，或者对错误进行转义。以至于我们通过 window.onerror 的方式得不到完整的错误信息。同时，有些框架提供了错误处理的接口（比如 vue），利用错误处理的接口，我们能够获取到和错误有关的更多更重要的信息。\n\nraven.js 利用各个框架的官方接口，提供了 vue、require.js、angular、ember、react-native 等各个框架的官方插件。\n\n插件内容本身非常简单，我们可以看一下 vue 插件的代码：\n\n```\nfunction formatComponentName(vm) {\n  if (vm.$root === vm) {\n    return 'root instance';\n  }\n  var name = vm._isVue ? vm.$options.name || vm.$options._componentTag : vm.name;\n  return (\n    (name ? 'component <' + name + '>' : 'anonymous component') +\n    (vm._isVue && vm.$options.__file ? ' at ' + vm.$options.__file : '')\n  );\n}\n\nfunction vuePlugin(Raven, Vue) {\n  Vue = Vue || window.Vue;\n\n  // quit if Vue isn't on the page\n  if (!Vue || !Vue.config) return;\n\n  var _oldOnError = Vue.config.errorHandler;\n  Vue.config.errorHandler = function VueErrorHandler(error, vm, info) {\n    var metaData = {};\n\n    // vm and lifecycleHook are not always available\n    if (Object.prototype.toString.call(vm) === '[object Object]') {\n      metaData.componentName = formatComponentName(vm);\n      metaData.propsData = vm.$options.propsData;\n    }\n\n    if (typeof info !== 'undefined') {\n      metaData.lifecycleHook = info;\n    }\n\n    Raven.captureException(error, {\n      extra: metaData\n    });\n\n    if (typeof _oldOnError === 'function') {\n      _oldOnError.call(this, error, vm, info);\n    }\n  };\n}\n\nmodule.exports = vuePlugin;\n```\n\n应该不用进行过多解释。\n\n你也许想知道为什么没有提供 react 插件，事实上，react 16 以后才引入了[Error Boundaries](https://reactjs.org/blog/2017/07/26/error-handling-in-react-16.html)，这种方式由于灵活性太强，并不太适合使用插件，另外，就算不使用插件，也非常方便地使用 raven.js 进行错误上报，可以参考[这里](https://docs.sentry.io/clients/javascript/integrations/react/)\n\n>但笔者认为，目前 react 的引入方式会对源代码进行侵入，并且比较难通过构建的方式进行 sentry 的配置，也许我们可以寻找更好的方式。\n\n完。\n\n","tags":["javascript","前端监控"]},{"title":"一篇关于react历史的流水账","url":"/2018/06/10/一篇关于react历史的流水账/","content":"\nreact 目前已经更新到 V16.3，其一路走来，日臻完善，笔者接触 react 两年有余，在这里做一个阶段性的整理，也对 react 的发展和我对 react 的学习做一个整体记录。\n\n笔者是在 16 年初开始关注 react，而实际上那个时候 react 已经发布快三年了， 16 年初的我写页面还是主要使用 backbone.js、Jquery，并且认为，相比于纯粹使用 Jquery 的“刀耕火种”的时代，使用 backbone.js 已经足够方便并且不需要替代品了。\n\n这篇文章会从 react 开源之初进行讲起，直到 2018 年六月。\n\n### 为什么是 react\n\n我们知道，react 并不是一个 MVC 框架，也并没有使用传统的前端模版，而是采用了纯 JS 编写（实际上用到了 JSX ），使用了虚拟 DOM，使用 diff 来保证 DOM 的更新效率，并且可以结合 facebook 的 Flux 架构，解决传统 MVC 模式的一些痛点。\n\n在 react 开源之初，相关生态体系并不完善，甚至官方还在用`Backbone.Router`加 react 来开发单页面应用。\n\n但是那个时候的 react，和现在的 react，解决的核心问题都没有变化，那就是**复杂的UI渲染问题（ complex UI rendering ）**，所有的它的组件化，虚拟 DOM 和 diff 算法，甚至目前提出的 Fiber、async rendering等等，都是围绕这个中心。\n\n### FLUX\n\n在 2014 年五月左右，也就是距离 react 开源接近一年时间，react 公开了 FLUX 架构。当然，我们现在在学习的过程中，甚至都很难听到 FLUX 这个词汇了，更多的则是 redux 甚至 dva 等更上层的框架，但是目前绝大多数 react 相关的数据管理框架都受到了 FLUX 很大启发。\n\nFLUX 和双向数据绑定的关系，我认为这里有必要援引当初官方写的一点解释（更详细的一些信息，可以看[这篇文章](https://www.10000h.top/react_flux.pdf)）：\n\n```\nTo summarize, Flux works well for us because the single directional data flow makes it easy to understand and modify an application as it becomes more complicated. We found that two-way data bindings lead to cascading updates, where changing one data model led to another data model updating, making it very difficult to predict what would change as the result of a single user interaction.\n\n总而言之，Flux对我们来说效果很好，因为单向数据流可以让应用程序变得更加复杂，从而轻松理解和修改应用程序。我们发现双向数据绑定导致级联更新，其中更改一个数据模型导致另一个数据模型更新，使得很难预测单个用户交互的结果会发生什么变化。\n```\n\n从此之后，下面这张图便多次出现在官方博客和各个网站中，相信我们也肯定见过下图：\n\n![](https://www.10000h.top/images/flux.png)\n\n### react-router\n\n2014年8月，react-router 的雏形发布，在其发布之前，不少示例应用还在使用 backbone\n.js 的 router，而 react-router 的发布，标志着 react 生态的进一步成熟。\n\n### react ES6 Class\n\n实际上，在 2015.01.27 之前，我们都是在使用 `React.createClass`来书写组件。\n\n而在 2015.01.27 这一天，也就是第一届 `reactjs conf` 的前一天，react 官方发布了 React V0.13.0 beta 版本。这一个版本的最大更新就是支持 ES6 的 Class 写法来书写组件，同时也公布了比如 propTypes 类型检查、defaultProps、AutoBind、ref 等一系列相关工作在 ES6 Class 模式下的写法。\n\n这次发布是 react 开源至此最为重大的一次更新，也因此直接将 react 的写法进行了革新，在我看来，这标志着 react 从刀耕火种的原始时代进入了石器时代。\n\n*实际上，直到一个半月后的 03.10 ，V0.13 的正式版本才发布。*\n\n而在之后的 V15.5 版本（2017年4月发布），react 才将`React.createClass`的使用设置为 Deprecation，并且宣布会在将来移除该 API，与此同时，react 团队仍然提供了一个单独的库`create-react-class` 来支持原来的 `React.createClass` 功能。\n\n### Relay & GraphQL\n\n在 2015 年的 2月，Facebook 公布了 GraphQL，GraphQL 是一种新的数据查询解决方案，事实证明，它是非常优秀的一个解决方案，到现在已经基本在行业内人尽皆知。\n\n而 Relay 则是链接 react 和 GraphQL 的一个解决方案，有点类似 redux（但是 stat 数只有 redux 的四分之一左右），但是对 GraphQL 更为友好，并且在缓存机制的设计（按照 Graph 来 cache）、声明式的数据获取等方面，有一些自己的独到之处。\n\n当然，我们使用 redux 配合相关插件，也可以不使用 Relay。\n\n\n### React Native\n\n在第一届 React.js Conf 中，react 团队首次公开了 React Native，并且在3月份真正开源了 React Native（实际上这个时候安卓版本还并不可用），之后在2015年上半年，相关团队陆陆续续披露了关于 React Native 发展情况的更多信息。\n\n并且也是在这个时候（2015年3月），react 团队开始使用 **learn once, write anywhere** 这个如今我们耳熟能详的口号。\n\n### react & react-dom & babel\n\n在2015年七月，官方发布了React v0.14 Beta 1，这也是一个变动比较大的版本，在这个版本中，主要有如下比较大的变化:\n\n* 官方宣布废弃 react-tools 和 JSTransform，这是和 JSX 解析相关的库，而从此 react 开始使用 babel，我认为这对 react 以及其使用者来说无疑是一个利好。\n* 分离 react 和 react-dom，由于 React Native 已经迭代了一段时间，这个分离同时也意味着 react 之后的发展方向，react 本身将会关注抽象层和组件本身，而 react-dom 可以将其在浏览器中落地，React Native 可以将其在客户端中落地，之后也许还会有 react-xxx ...\n\n将 react 和 react-dom 分离之后，react 团队又对 react-dom 在 dom 方面做了较为大量的更新。\n\n### Discontinuing IE 8 Support\n\n在 react V15 的版本中，放弃了对 IE 8 的支持。\n\n\n### Fiber\n\nreact 团队使用 Fiber 架构完成了 react V16 的开发，得益于 Fiber 架构，react 的性能又得到了显著提升（尤其是在某些要求交互连续的场景下），并且包大小缩小了 32%。\n\n到目前来说，关于 Fiber 架构的中英文资料都已经相当丰富，笔者在这里就不进行过多的赘述了。\n\n### 接下来的展望\n\nreact 团队目前的主要工作集中在 async rendering 方面，这方面的改进可以极大提升用户交互体验（特别是在弱网络环境下），会在 2018 年发布。\n\n如果你对这方面的内容很感兴趣，不妨看看 react 之前的[演讲视频](https://reactjs.org/blog/2018/03/01/sneak-peek-beyond-react-16.html)\n\n### 附录1 一些你可能不知道的变化\n\n* react并非直接将 JSX 渲染成 DOM，而是对某些事件和属性做了封装（优化）。 react 对表单类型的 DOM 进行了优化，比如封装了较为通用的 onChange 回调函数，这其中需要处理不少问题，react 在 V0.4 即拥有了这一特性，可以参考[这里](https://reactjs.org/blog/2013/07/23/community-roundup-5.html#cross-browser-onchange)\n* 事实上，react 在V0.8之前，一直在以“react-tools”这个名字发布，而 npm 上面叫做 react 的实际上是另外一个包，而到 V0.8 的时候，react 团队和原来的 “react” 包开发者协商，之后 react 便接管了原来的这个包，也因此，react并没有 V0.6 和 V0.7，而是从 V0.5 直接到了 V0.8\n* react 从 V0.14 之后，就直接跳跃到了 V15，官方团队给出的理由是，react 很早就已经足够稳定并且可以使用在生产版本中，更改版本的表达方式更有助于表示 react 项目本身的稳定性。\n\n### 附录2 一些比较优秀的博客\n\n* 关于React Components, Elements, 和 Instances，如果你还有一些疑问，可以看一看React官方团队的文章：[React Components, Elements, and Instances](https://reactjs.org/blog/2015/12/18/react-components-elements-and-instances.html)\n* 如果你倾向于使用 mixins，不妨看看 react 关于取消 mixin的说法：[Mixins Considered Harmful](https://reactjs.org/blog/2016/07/13/mixins-considered-harmful.html)\n* react props 相关的开发模式的建议，我认为目前在使用 react 的程序员都应该了解一下[You Probably Don't Need Derived State](https://reactjs.org/blog/2018/06/07/you-probably-dont-need-derived-state.html)","tags":["react"]},{"title":"十条编写优化的 JavaScript 代码的建议","url":"/2018/05/29/十条编写优化的JavaScript代码的建议/","content":"\n本文总结了十条编写优秀的 JavaScript 代码的习惯，主要针对 V8 引擎：\n\n1.始终以相同的顺序实例化对象属性，以便可以共享隐藏类和随后优化的代码。V8 在对 js 代码解析的时候会有构建隐藏类的过程，以相同的顺序实例化（属性赋值）的对象会共享相同的隐藏类。下面给出一个不好的实践：\n\n```javascript\nfunction Point(x, y) {\n    this.x = x;\n    this.y = y;\n}\nvar p1 = new Point(1, 2);\np1.a = 5;\np1.b = 6;\nvar p2 = new Point(3, 4);\np2.b = 7;\np2.a = 8;\n// 由于 a 和 b 的赋值顺序不同，p1 和 p2 无法共享隐藏类\n```\n\n2.避免分配动态属性。在实例化之后向对象添加属性将强制隐藏类更改，并减慢为先前隐藏类优化的所有方法。相反，在其构造函数中分配所有对象的属性。  \n\n3.重复执行相同方法的代码将比仅执行一次（由于内联缓存）执行许多不同方法的代码运行得更快。  \n\n4.避免创建稀疏数组。稀疏数组由于不是所有的元素都存在，因此是一个哈希表，因此访问稀疏数组中的元素代价更高。另外，尽量不要采用预分配数量的大数组，更好的办法是随着你的需要把它的容量增大。最后，尽量不要删除数组中的元素，它会让数组变得稀疏。  \n\n5.标记值：V8采用32位来表示对象和数字，其中用一位来区别对象（flag = 0）或数字（flag = 1），因此这被称之为 SMI (Small Integer)因为它只有31位。因此，如果一个数字大于31位，V8需要对其进行包装，将其变成双精度并且用一个对象来封装它，因此应该尽量使用31位有符号数字从而避免昂贵的封装操作。  \n\n6.检查你的依赖，去掉不需要 import 的内容。  \n\n7.将你的代码分割成一些小的 chunks ，而不是整个引入。 \n \n8.尽可能使用 defer 来推迟加载 JavaScript，另外只加载当前路由需要的代码段。\n  \n9.使用 dev tools 和 DeviceTiming 来寻找代码瓶颈。  \n\n10.使用诸如Optimize.js这样的工具来帮助解析器决定何时需要提前解析以及何时需要延后解析。  \n  \n以上内容来源：\n* [How JavaScript works: Parsing, Abstract Syntax Trees (ASTs) + 5 tips on how to minimize parse time](https://blog.sessionstack.com/how-javascript-works-parsing-abstract-syntax-trees-asts-5-tips-on-how-to-minimize-parse-time-abfcf7e8a0c8)\n* [How JavaScript works: inside the V8 engine + 5 tips on how to write optimized code](https://blog.sessionstack.com/how-javascript-works-inside-the-v8-engine-5-tips-on-how-to-write-optimized-code-ac089e62b12e)\n\n","tags":["javascript"]},{"title":"浅谈前端中的二进制数据类型","url":"/2018/05/09/浅谈前端中的二进制数据类型/","content":"\n>目前在一个项目中，WebSocket部分由于后端使用了gzip压缩，前端处理起来废了一点时间，从而发现自己在二进制数据类型这个知识点还存在一定的盲区，因此这里进行总结。\n\n本文主要简单介绍ArrayBuffer对象、TypedArray对象、DataView对象以及Blob原始数据类型，和它们之间的互相转换方法。部分代码参考[这里](http://javascript.ruanyifeng.com/stdlib/arraybuffer.html#toc4)而非本人原创，仅做个人学习使用。\n\n这些类型化对象，一般会在以下场景中使用：\n\n* WebGL 中，浏览器和显卡之间需要使用二进制数据进行通信。\n* 在一些 Rest 接口或者 WebSocket 中，采用压缩过的数据进行通信，这个压缩和解压缩的过程可能需要借助二进制对象。\n* 在 Canvas 中，我们可能需要通过生成 Blob 的方式保存当前内容。\n* 在 Img 等资源文件中，URL 可以为 Blob 原始数据类型。\n* 在读取用户上传文件时，可能需要用到二进制数据类型进行中间转换。\n\n下文分两部分，前一部分概述各个二进制数据类型，后一部分将它们之间的互相转换。\n\n### 二进制数据类型概述\n\n#### ArrayBuffer\n\nArrayBuffer对象代表储存二进制数据的一段内存，它不能直接读写，只能通过视图（TypedArray视图和DataView视图)来读写，视图的作用是以指定格式解读二进制数据。\n\nArrayBuffer也是一个构造函数，可以分配一段可以存放数据的连续内存区域。\n\n```\nvar buf = new ArrayBuffer(32);\n```\n\n上面代码生成了一段32字节的内存区域，每个字节的值默认都是0。可以看到，ArrayBuffer构造函数的参数是所需要的内存大小（单位字节）。\n\n为了读写这段内容，需要为它指定视图。DataView视图的创建，需要提供ArrayBuffer对象实例作为参数。\n\n```\nvar buf = new ArrayBuffer(32);\nvar dataView = new DataView(buf);\ndataView.getUint8(0) // 0\n```\n\n上面代码对一段32字节的内存，建立DataView视图，然后以不带符号的8位整数格式，读取第一个元素，结果得到0，因为原始内存的ArrayBuffer对象，默认所有位都是0。\n\n另外，我们可以将ArrayBuffer生成的结果，传入TypedArray中：\n\n```\nvar buffer = new ArrayBuffer(12);\n\nvar x1 = new Int32Array(buffer);\nx1[0] = 1;\nvar x2 = new Uint8Array(buffer);\nx2[0]  = 2;\n\nx1[0] // 2\n```\n\nArrayBuffer实例的byteLength属性，返回所分配的内存区域的字节长度。\n\n```\nvar buffer = new ArrayBuffer(32);\nbuffer.byteLength\n// 32\n```\n如果要分配的内存区域很大，有可能分配失败（因为没有那么多的连续空余内存），所以有必要检查是否分配成功。\n\n```\nif (buffer.byteLength === n) {\n  // 成功\n} else {\n  // 失败\n}\n```\n\nArrayBuffer实例有一个slice方法，允许将内存区域的一部分，拷贝生成一个新的ArrayBuffer对象。\n\n```\nvar buffer = new ArrayBuffer(8);\nvar newBuffer = buffer.slice(0, 3);\n```\n\n上面代码拷贝buffer对象的前3个字节（从0开始，到第3个字节前面结束），生成一个新的ArrayBuffer对象。slice方法其实包含两步，第一步是先分配一段新内存，第二步是将原来那个ArrayBuffer对象拷贝过去。\n\nslice方法接受两个参数，第一个参数表示拷贝开始的字节序号（含该字节），第二个参数表示拷贝截止的字节序号（不含该字节）。如果省略第二个参数，则默认到原ArrayBuffer对象的结尾。\n\n除了slice方法，ArrayBuffer对象不提供任何直接读写内存的方法，只允许在其上方建立视图，然后通过视图读写。\n\nArrayBuffer有一个静态方法isView，返回一个布尔值，表示参数是否为ArrayBuffer的视图实例。这个方法大致相当于判断参数，是否为TypedArray实例或DataView实例。\n\n```\nvar buffer = new ArrayBuffer(8);\nArrayBuffer.isView(buffer) // false\n\nvar v = new Int32Array(buffer);\nArrayBuffer.isView(v) // true\n```\n\n#### TypedArray\n\n目前，TypedArray对象一共提供9种类型的视图，每一种视图都是一种构造函数。\n\n* Int8Array：8位有符号整数，长度1个字节。\n* Uint8Array：8位无符号整数，长度1个字节。\n* Uint8ClampedArray：8位无符号整数，长度1个字节，溢出处理不同。\n* Int16Array：16位有符号整数，长度2个字节。\n* Uint16Array：16位无符号整数，长度2个字节。\n* Int32Array：32位有符号整数，长度4个字节。\n* Uint32Array：32位无符号整数，长度4个字节。\n* Float32Array：32位浮点数，长度4个字节。\n* Float64Array：64位浮点数，长度8个字节。\n\n这9个构造函数生成的对象，统称为TypedArray对象。它们很像正常数组，都有length属性，都能用方括号运算符（[]）获取单个元素，所有数组的方法，在类型化数组上面都能使用。两者的差异主要在以下方面。\n\n* TypedArray数组的所有成员，都是同一种类型和格式。\n* TypedArray数组的成员是连续的，不会有空位。\n* Typed化数组成员的默认值为0。比如，new Array(10)返回一个正常数组，里面没有任何成员，只是10个空位；new Uint8Array(10)返回一个类型化数组，里面10个成员都是0。\n* TypedArray数组只是一层视图，本身不储存数据，它的数据都储存在底层的ArrayBuffer对象之中，要获取底层对象必须使用buffer属性。\n\n##### 构造函数\n\nTypedArray数组提供9种构造函数，用来生成相应类型的数组实例。\n\n构造函数有多种用法。\n\n* TypedArray(buffer, byteOffset=0, length?)\n\n同一个ArrayBuffer对象之上，可以根据不同的数据类型，建立多个视图。\n\n```\n// 创建一个8字节的ArrayBuffer\nvar b = new ArrayBuffer(8);\n\n// 创建一个指向b的Int32视图，开始于字节0，直到缓冲区的末尾\nvar v1 = new Int32Array(b);\n\n// 创建一个指向b的Uint8视图，开始于字节2，直到缓冲区的末尾\nvar v2 = new Uint8Array(b, 2);\n\n// 创建一个指向b的Int16视图，开始于字节2，长度为2\nvar v3 = new Int16Array(b, 2, 2);\n```\n\n对于以上代码，v1、v2和v3是重叠的：v1[0]是一个32位整数，指向字节0～字节3；v2[0]是一个8位无符号整数，指向字节2；v3[0]是一个16位整数，指向字节2～字节3。只要任何一个视图对内存有所修改，就会在另外两个视图上反应出来。\n\n注意，byteOffset必须与所要建立的数据类型一致，否则会报错。\n\n```\nvar buffer = new ArrayBuffer(8);\nvar i16 = new Int16Array(buffer, 1);\n// Uncaught RangeError: start offset of Int16Array should be a multiple of 2\n```\n\n上面代码中，新生成一个8个字节的ArrayBuffer对象，然后在这个对象的第一个字节，建立带符号的16位整数视图，结果报错。因为，带符号的16位整数需要两个字节，所以byteOffset参数必须能够被2整除。\n\n如果想从任意字节开始解读ArrayBuffer对象，必须使用DataView视图，因为TypedArray视图只提供9种固定的解读格式。\n\n* TypedArray(length)\n\n视图还可以不通过ArrayBuffer对象，直接分配内存而生成。\n\n```\nvar f64a = new Float64Array(8);\nf64a[0] = 10;\nf64a[1] = 20;\nf64a[2] = f64a[0] + f64a[1];\n```\n\n* TypedArray(typedArray)\n\n类型化数组的构造函数，可以接受另一个视图实例作为参数。\n\n```\nvar typedArray = new Int8Array(new Uint8Array(4));\n```\n\n上面代码中，Int8Array构造函数接受一个Uint8Array实例作为参数。\n\n注意，此时生成的新数组，只是复制了参数数组的值，对应的底层内存是不一样的。新数组会开辟一段新的内存储存数据，不会在原数组的内存之上建立视图。\n\n```\nvar x = new Int8Array([1, 1]);\nvar y = new Int8Array(x);\nx[0] // 1\ny[0] // 1\n\nx[0] = 2;\ny[0] // 1\n```\n\n上面代码中，数组y是以数组x为模板而生成的，当x变动的时候，y并没有变动。\n\n如果想基于同一段内存，构造不同的视图，可以采用下面的写法。\n\n```\nvar x = new Int8Array([1, 1]);\nvar y = new Int8Array(x.buffer);\nx[0] // 1\ny[0] // 1\n\nx[0] = 2;\ny[0] // 2\n```\n\n* TypedArray(arrayLikeObject)\n\n构造函数的参数也可以是一个普通数组，然后直接生成TypedArray实例。\n\n```\nvar typedArray = new Uint8Array([1, 2, 3, 4]);\n```\n\n注意，这时TypedArray视图会重新开辟内存，不会在原数组的内存上建立视图。\n\n上面代码从一个普通的数组，生成一个8位无符号整数的TypedArray实例。\n\nTypedArray数组也可以转换回普通数组。\n\n```\nvar normalArray = Array.prototype.slice.call(typedArray);\n```\n\n##### BYTES_PER_ELEMENT属性\n\n每一种视图的构造函数，都有一个BYTES_PER_ELEMENT属性，表示这种数据类型占据的字节数。\n\n```\nInt8Array.BYTES_PER_ELEMENT // 1\nUint8Array.BYTES_PER_ELEMENT // 1\nInt16Array.BYTES_PER_ELEMENT // 2\nUint16Array.BYTES_PER_ELEMENT // 2\nInt32Array.BYTES_PER_ELEMENT // 4\nUint32Array.BYTES_PER_ELEMENT // 4\nFloat32Array.BYTES_PER_ELEMENT // 4\nFloat64Array.BYTES_PER_ELEMENT // 8\n```\n\n##### ArrayBuffer与字符串的互相转换\n\nArrayBuffer转为字符串，或者字符串转为ArrayBuffer，有一个前提，即字符串的编码方法是确定的。假定字符串采用UTF-16编码（JavaScript的内部编码方式），可以自己编写转换函数。\n\n```\n// ArrayBuffer转为字符串，参数为ArrayBuffer对象\nfunction ab2str(buf) {\n  return String.fromCharCode.apply(null, new Uint16Array(buf));\n}\n\n// 字符串转为ArrayBuffer对象，参数为字符串\nfunction str2ab(str) {\n  var buf = new ArrayBuffer(str.length * 2); // 每个字符占用2个字节\n  var bufView = new Uint16Array(buf);\n  for (var i = 0, strLen = str.length; i < strLen; i++) {\n    bufView[i] = str.charCodeAt(i);\n  }\n  return buf;\n}\n```\n\n##### TypedArray.prototype.set()\n\nTypedArray数组的set方法用于复制数组（正常数组或TypedArray数组），也就是将一段内容完全复制到另一段内存。\n\n```\nvar a = new Uint8Array(8);\nvar b = new Uint8Array(8);\n\nb.set(a);\n```\n\n上面代码复制a数组的内容到b数组，它是整段内存的复制，比一个个拷贝成员的那种复制快得多。set方法还可以接受第二个参数，表示从b对象哪一个成员开始复制a对象。\n\n```\nvar a = new Uint16Array(8);\nvar b = new Uint16Array(10);\n\nb.set(a, 2)\n```\n上面代码的b数组比a数组多两个成员，所以从b[2]开始复制。\n\n##### TypedArray.prototype.subarray()\n\nsubarray方法是对于TypedArray数组的一部分，再建立一个新的视图。\n\n```\nvar a = new Uint16Array(8);\nvar b = a.subarray(2,3);\n\na.byteLength // 16\nb.byteLength // 2\n```\n\nsubarray方法的第一个参数是起始的成员序号，第二个参数是结束的成员序号（不含该成员），如果省略则包含剩余的全部成员。所以，上面代码的a.subarray(2,3)，意味着b只包含a[2]一个成员，字节长度为2。\n\n##### TypedArray.prototype.slice()\n\nTypeArray实例的slice方法，可以返回一个指定位置的新的TypedArray实例。\n\n```\nlet ui8 = Uint8Array.of(0, 1, 2);\nui8.slice(-1)\n// Uint8Array [ 2 ]\n```\n\n\n上面代码中，ui8是8位无符号整数数组视图的一个实例。它的slice方法可以从当前视图之中，返回一个新的视图实例。\n\nslice方法的参数，表示原数组的具体位置，开始生成新数组。负值表示逆向的位置，即-1为倒数第一个位置，-2表示倒数第二个位置，以此类推。\n\n##### TypedArray.of()\n\nTypedArray数组的所有构造函数，都有一个静态方法of，用于将参数转为一个TypedArray实例。\n\n```\nFloat32Array.of(0.151, -8, 3.7)\n// Float32Array [ 0.151, -8, 3.7 ]\n```\n\n##### TypedArray.from()\n\n静态方法from接受一个**可遍历的数据结构（比如数组）**作为参数，返回一个基于这个结构的TypedArray实例。\n\n```\nUint16Array.from([0, 1, 2])\n// Uint16Array [ 0, 1, 2 ]\n```\n\n这个方法还可以将一种TypedArray实例，转为另一种。\n\n```\nvar ui16 = Uint16Array.from(Uint8Array.of(0, 1, 2));\nui16 instanceof Uint16Array // true\n```\n\nfrom方法还可以接受一个函数，作为第二个参数，用来对每个元素进行遍历，功能类似map方法。\n\n```\nInt8Array.of(127, 126, 125).map(x => 2 * x)\n// Int8Array [ -2, -4, -6 ]\n\nInt16Array.from(Int8Array.of(127, 126, 125), x => 2 * x)\n// Int16Array [ 254, 252, 250 ]\n```\n\n上面的例子中，from方法没有发生溢出，这说明遍历是针对新生成的16位整数数组，而不是针对原来的8位整数数组。也就是说，from会将第一个参数指定的TypedArray数组，拷贝到另一段内存之中（占用内存从3字节变为6字节），然后再进行处理。\n\n#### DataView\n\n如果一段数据包括多种类型（比如服务器传来的HTTP数据），这时除了建立ArrayBuffer对象的复合视图以外，还可以通过DataView视图进行操作。\n\nDataView视图提供更多操作选项，而且支持设定字节序。本来，在设计目的上，ArrayBuffer对象的各种TypedArray视图，是用来向网卡、声卡之类的本机设备传送数据，所以使用本机的字节序就可以了；而DataView视图的设计目的，是用来处理网络设备传来的数据，所以大端字节序或小端字节序是可以自行设定的。\n\nDataView视图本身也是构造函数，接受一个ArrayBuffer对象作为参数，生成视图。\n\n```\nDataView(ArrayBuffer buffer [, 字节起始位置 [, 长度]]);\n```\n下面是一个例子。\n\n```\nvar buffer = new ArrayBuffer(24);\nvar dv = new DataView(buffer);\n```\n\nDataView实例有以下属性，含义与TypedArray实例的同名方法相同。\n\n* DataView.prototype.buffer：返回对应的ArrayBuffer对象\n* DataView.prototype.byteLength：返回占据的内存字节长度\n* DataView.prototype.byteOffset：返回当前视图从对应的ArrayBuffer对象的哪个字节开始\n\nDataView实例提供8个方法读取内存。\n\n* getInt8：读取1个字节，返回一个8位整数。\n* getUint8：读取1个字节，返回一个无符号的8位整数。\n* getInt16：读取2个字节，返回一个16位整数。\n* getUint16：读取2个字节，返回一个无符号的16位整数。\n* getInt32：读取4个字节，返回一个32位整数。\n* getUint32：读取4个字节，返回一个无符号的32位整数。\n* getFloat32：读取4个字节，返回一个32位浮点数。\n* getFloat64：读取8个字节，返回一个64位浮点数。\n\n这一系列get方法的参数都是一个字节序号（不能是负数，否则会报错），表示从哪个字节开始读取。\n\n```\nvar buffer = new ArrayBuffer(24);\nvar dv = new DataView(buffer);\n\n// 从第1个字节读取一个8位无符号整数\nvar v1 = dv.getUint8(0);\n\n// 从第2个字节读取一个16位无符号整数\nvar v2 = dv.getUint16(1);\n\n// 从第4个字节读取一个16位无符号整数\nvar v3 = dv.getUint16(3);\n```\n\n上面代码读取了ArrayBuffer对象的前5个字节，其中有一个8位整数和两个十六位整数。\n\n如果一次读取两个或两个以上字节，就必须明确数据的存储方式，到底是小端字节序还是大端字节序。默认情况下，DataView的get方法使用大端字节序解读数据，如果需要使用小端字节序解读，必须在get方法的第二个参数指定true。\n\n```\n// 小端字节序\nvar v1 = dv.getUint16(1, true);\n\n// 大端字节序\nvar v2 = dv.getUint16(3, false);\n\n// 大端字节序\nvar v3 = dv.getUint16(3);\n```\n\nDataView视图提供8个方法写入内存。\n\n* setInt8：写入1个字节的8位整数。\n* setUint8：写入1个字节的8位无符号整数。\n* setInt16：写入2个字节的16位整数。\n* setUint16：写入2个字节的16位无符号整数。\n* setInt32：写入4个字节的32位整数。\n* setUint32：写入4个字节的32位无符号整数。\n* setFloat32：写入4个字节的32位浮点数。\n* setFloat64：写入8个字节的64位浮点数。\n\n这一系列set方法，接受两个参数，第一个参数是字节序号，表示从哪个字节开始写入，第二个参数为写入的数据。对于那些写入两个或两个以上字节的方法，需要指定第三个参数，false或者undefined表示使用大端字节序写入，true表示使用小端字节序写入。\n\n```\n// 在第1个字节，以大端字节序写入值为25的32位整数\ndv.setInt32(0, 25, false);\n\n// 在第5个字节，以大端字节序写入值为25的32位整数\ndv.setInt32(4, 25);\n\n// 在第9个字节，以小端字节序写入值为2.5的32位浮点数\ndv.setFloat32(8, 2.5, true);\n```\n\n如果不确定正在使用的计算机的字节序，可以采用下面的判断方式。\n\n```\nvar littleEndian = (function() {\n  var buffer = new ArrayBuffer(2);\n  new DataView(buffer).setInt16(0, 256, true);\n  return new Int16Array(buffer)[0] === 256;\n})();\n```\n\n#### Blob\n\nBlob 对象表示一个不可变、原始数据的类文件对象。Blob 表示的不一定是JavaScript原生格式的数据。File 接口基于Blob，继承了 blob 的功能并将其扩展使其支持用户系统上的文件。\n\n要从其他非blob对象和数据构造一个Blob，请使用 Blob() 构造函数。要创建包含另一个blob数据的子集blob，请使用 slice()方法。要获取用户文件系统上的文件对应的Blob对象，请参阅 File文档。\n\n从Blob中读取内容的唯一方法是使用 FileReader。以下代码将 Blob 的内容作为类型数组读取：\n\n```\nvar reader = new FileReader();\nreader.addEventListener(\"loadend\", function() {\n   // reader.result 包含转化为类型数组的blob\n});\nreader.readAsArrayBuffer(blob);\n```\n\n更多关于Blob的内容，请直接查看[这里](https://developer.mozilla.org/zh-CN/docs/Web/API/Blob)\n\n### 数据格式转换\n\n#### String转Blob\n\n```\n//将字符串 转换成 Blob 对象\nvar blob = new Blob([\"Hello World!\"], {\n    type: 'text/plain'\n});\nconsole.info(blob);\nconsole.info(blob.slice(1, 3, 'text/plain'));\n```\n#### TypeArray转Blob\n\n```\n//将 TypeArray  转换成 Blob 对象\nvar array = new Uint16Array([97, 32, 72, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100, 33]);\n//测试成功\n//var blob = new Blob([array], { type: \"application/octet-binary\" });\n//测试成功， 注意必须[]的包裹\nvar blob = new Blob([array]);\n//将 Blob对象 读成字符串\nvar reader = new FileReader();\nreader.readAsText(blob, 'utf-8');\nreader.onload = function (e) {\n    console.info(reader.result); //a Hello world!\n}\n```\n\n#### ArrayBuffer转Blob\n\n```\nvar buffer = new ArrayBuffer(32);\nvar blob = new Blob([buffer]);       // 注意必须包裹[]\n```\n\n#### Blob转String\n\n这里需要注意的是readAsText方法的使用。\n\n```\n//将字符串转换成 Blob对象\nvar blob = new Blob(['中文字符串'], {\n    type: 'text/plain'\n});\n//将Blob 对象转换成字符串\nvar reader = new FileReader();\nreader.readAsText(blob, 'utf-8');\nreader.onload = function (e) {\n    console.info(reader.result);\n}\n```\n\n#### Blob转ArrayBuffer\n\n这里需要注意的是readAsArrayBuffer方法的使用。\n\n```\n//将字符串转换成 Blob对象\nvar blob = new Blob(['中文字符串'], {\n    type: 'text/plain'\n});\n//将Blob 对象转换成 ArrayBuffer\nvar reader = new FileReader();\nreader.readAsArrayBuffer(blob);\nreader.onload = function (e) {\n    console.info(reader.result); //ArrayBuffer {}\n    //经常会遇到的异常 Uncaught RangeError: byte length of Int16Array should be a multiple of 2\n    //var buf = new int16array(reader.result);\n    //console.info(buf);\n\n    //将 ArrayBufferView  转换成Blob\n    var buf = new Uint8Array(reader.result);\n    console.info(buf); //[228, 184, 173, 230, 150, 135, 229, 173, 151, 231, 172, 166, 228, 184, 178]\n    reader.readAsText(new Blob([buf]), 'utf-8');\n    reader.onload = function () {\n        console.info(reader.result); //中文字符串\n    };\n\n    //将 ArrayBufferView  转换成Blob\n    var buf = new DataView(reader.result);\n    console.info(buf); //DataView {}\n    reader.readAsText(new Blob([buf]), 'utf-8');\n    reader.onload = function () {\n        console.info(reader.result); //中文字符串\n    };\n}\n```\n\n","tags":["javascript"]},{"title":"Linux服务器初始化设置用户和ssh公私钥登陆","url":"/2018/04/11/Linux服务器初始化设置用户和ssh公私钥登陆/","content":"\n>当我们开始使用一个新的服务器的时候，首先一定要对服务器的登陆等做一些修改工作，笔者曾经就因为对服务器登陆安全没有重视，导致服务器数据全部丢失。接下来我们按照步骤，罗列出应该做的一些事情。\n\n### 修改ssh端口号\n\n第一件事情：\n\n修改ssh端口号： 之后加上一个端口比如说50000\n\n`vi /etc/ssh/sshd_config`之后在port字段加上一个端口比如说50000，原来的端口号字段可能是被注释掉的，要先解除注释。\n\n然后执行：\n\n```\nservice sshd restart\n```\n\n这个时候可能还要重新配置一下防火墙，开放50000端口，具体如何配置也可以参考[这里](https://blog.csdn.net/ul646691993/article/details/52104082)的后半部分。但是目前，阿里云的服务器实测是不需要再配置防火墙的，但是需要去登陆到网页后台修改安全组。\n\n之后就可以通过这样的方式登录了：(注意登录方式一定要写对)\n\n```shell\nssh root@115.29.102.81 -p 50000\n```\n\n### 创建用户\n\n这个时候我们还是用root进行操作，所以我们接下来要给自己创建一个账户，比如创建一个如下的用户：\n\n```\nuseradd xiaotao\npasswd xiaotao\n```\n\n可以用`ls -al /home/``查看一下账户\n\n对创建的这个用户增加sudo权限： 相关配置文件/etc/sudoers中，但是这个文件是只读的，所以要更改一下权限\n\n```\nchmod u+w sudoers\n```\n\n然后进入这个文件在这里进行更改：\n\n```\nroot    ALL=(ALL)       ALL\nxiaotao  ALL=(ALL)       ALL\n```\n\n然后再改回权限：\n\n```\nchmod u-w sudoers\n```\n\n注意一点，CentOS 7预设容许任何帐号透过ssh登入（也就是说自己根本不用改改，直接新建帐号登录即可），包括根和一般帐号，为了不受根帐号被黑客暴力入侵，我们必须禁止 root帐号的ssh功能，事实上root也没有必要ssh登入伺服器，因为只要使用su或sudo（当然需要输入root的密码）普通帐号便可以拥有root的权限。使用vim（或任何文本编辑器）开启的/ etc/ SSH/ sshd_config中，寻找：\n\n```\n＃PermitRootLogin yes\n```\n修改：\n\n```\nPermitRootLogin no\n```\n\n### 配置公私钥加密登录\n\n**这一步骤要切换到自己新建的用户，不能再用 root 用户了，否则可能无法正常登陆。**\n\n很多时候以上所说的还是不够安全，为了更加安全方便，我们采用公私钥对称加密登录，简单的讲做法就是再客户端生成一把私钥一把公钥，私钥是在客户端的，公钥上传到服务端，对称加密进行登录。\n\n在客户端先进到这个目录：\n\n```\ncd ~/.ssh\n```\n\n生成公钥和私钥（实际上如果之前有的话就不用重新生成了）\n\n```\nssh-keygen -t rsa\n```\n\n接下来把公钥上传到服务端\n\n```\nscp ~/.ssh/id_rsa.pub xiaotao@<ssh_server_ip>:~\n```\n\n在服务端执行以下命令(如果没有相关的文件和文件夹要先进行创建，注意不要使用 sudo )\n\n```\ncat  id_rsa.pub >> ～/.ssh/authorized_keys\n```\n\n配置服务器的/etc/ssh/sshd_config，下面是一些建议的配置：\n\n```\nvim /etc/ssh/sshd_config\n# 禁用root账户登录，非必要，但为了安全性，请配置\nPermitRootLogin no\n\n# 是否让 sshd 去检查用户家目录或相关档案的权限数据，\n# 这是为了担心使用者将某些重要档案的权限设错，可能会导致一些问题所致。\n# 例如使用者的 ~.ssh/ 权限设错时，某些特殊情况下会不许用户登入\nStrictModes no\n\n# 是否允许用户自行使用成对的密钥系统进行登入行为，仅针对 version 2。\n# 至于自制的公钥数据就放置于用户家目录下的 .ssh/authorized_keys 内\nRSAAuthentication yes\nPubkeyAuthentication yes\nAuthorizedKeysFile      %h/.ssh/authorized_keys\n\n#有了证书登录了，就禁用密码登录吧，安全要紧\nPasswordAuthentication no\n```\n\n然后不要忘记 `sudo service sshd restart`\n\n\n一般来讲，这样就算是成功了，我们可以在客户端尝试：\n\n```\nssh -i ~/.ssh/id_rsa remote_username@remote_ip\n```\n\n如果不行，可能是服务端或客户端相关 `.ssh` 文件权限不对，可以进行如下尝试：\n\n```\n服务端\nchown -R 0700  ~/.ssh\nchown -R 0644  ~/.ssh/authorized_keys\n\n客户端改一下\nchmod 600 id_rsa\n```","tags":["Linux","ssh"]},{"title":"dva源码解读","url":"/2018/04/11/dva源码解读/","content":"\n### 声明\n\n本文章用于个人学习研究，并不代表 dva 团队的任何观点。\n\n原文以及包含一定注释的代码见[这里](https://github.com/aircloud/dva-analysis)，若有问题也可以在[这里](https://github.com/aircloud/dva-analysis/issues)进行讨论\n\n### 起步\n\n#### 为什么是dva?\n\n笔者对 dva 的源代码进行解读，主要考虑到 dva 并不是一个和我们熟知的主流技术无关的从0到1的框架，相反，它是对主流技术进行整合，提炼，从而形成一种最佳实践，分析 dva，意味着我们可以对自己掌握的很多相关技术进行回顾，另外，dva 的代码量并不多，也不至于晦涩难懂，可以给我们平时的业务开发以启发。\n\n本文章作为 dva 的源码解读文章，并不面向新手用户，读者应当有一定的 react 使用经验和 ECMAscript 2015+ 的使用经验，并且应当了解 redux 和 redux-saga，以及对 dva 的使用有所了解(可以从[这里](https://github.com/dvajs/dva/blob/master/README_zh-CN.md#%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8-dva-)了解为什么需要使用 dva)\n\n重点推荐:\n\n* 通过[这里](https://github.com/dvajs/dva-knowledgemap)的内容了解使用dva的最小知识集\n* 通过[这里](https://redux-saga-in-chinese.js.org/docs/introduction/index.html)学习 redux-saga\n\n其他推荐：\n\n* [dva的概念](https://github.com/dvajs/dva/blob/master/docs/Concepts_zh-CN.md)\n* [dva的全部API](https://github.com/dvajs/dva/blob/master/docs/API_zh-CN.md)\n* [React+Redux 最佳实践](https://github.com/sorrycc/blog/issues/1)\n* [React在蚂蚁金服的实践](http://slides.com/sorrycc/dva#/)\n* [dva 2.0的改进](https://github.com/sorrycc/blog/issues/48)\n* [ReSelect介绍](http://cn.redux.js.org/docs/recipes/ComputingDerivedData.html)\n* [浅析Redux 的 store enhancer](https://www.jianshu.com/p/04d3fefea8d7)\n\n\n几个 dva 版本之间的关系:\n\n* dva@2.0：基于 react 和 react-router@4\n* dva-react-router-3@1.0：基于 react 和 react-router@3\n* dva-no-router@1.0：无路由版本，适用于多页面场景，可以和 next.js 组合使用\n* dva-core@1.0：仅封装了 redux 和 redux-saga\n\n我们本次主要分析目标为 dva@2.0 和 dva-core@1.0\n\n\n### 我们为什么需要 redux-saga\n\n目前，在大多数项目开发中，我们现在依然采用的是redux-thunk + async/await (或 Promise)。\n\n实际上这个十几行的插件已经完全可以解决大多是场景下的问题了，如果你在目前的工作中正在使用这一套方案并且能够完全将当下的需求应付自如并且没有什么凌乱的地方，其实也是没有必要换成redux-saga的。\n\n接下来我们讲 redux-saga，先看名字：saga，这个术语常用于CQRS架构，代表查询与责任分离。\n\n相比于 redux-thunk，前者通常是把数据查询等请求放在 actions 中(不纯净的 actions)，并且这些 actions 可以继续回调调用其他 actions(纯净的 actions)，从而完成数据的更新；而 redux-saga，则保持了 actions 的纯粹性，单独抽出一层专门来处理数据请求等操作(saga函数)。\n\n这样做还有另外一些好处：\n\n* 由于我们已经将数据处理数据请求等异步操作抽离出来了，并且通过 generator 来处理，我们便可以方便地进行多种异步管理：比如同时按顺序执行多个任务、在多个异步任务中启动race等。\n* 这样做可以延长任务的生命周期，我们的一次调用可以不再是一个\"调完即走\"的过程，还可以是一个LLT（Long Lived Transaction)的事物处理过程，比如我们可以将用户的登入、登出的管理放在一个saga函数中处理。\n\n当然，redux-saga还有比如拥有有诸多常用并且声明式易测的 Effects、可以无阻塞的fork等一些更复杂的异步操作和管理方法，如果应用中有较多复杂的异步操作流程，使用redux-saga无疑会让条理更加清楚。\n\n当然，本文的目的不是介绍或者安利redux-saga，只是因为redux-saga是 dva 的一个基础，相关概念点到为止，如需了解更多请自行参考资料。\n\n### dva 源码解读\n\n我们的源码分析流程是这样的：通过一个使用 dva 开发的例子，随着其对 dva 函数的逐步调用，来分析内部 dva 相关函数的实现原理。\n\n我们分析采用的例子是 dva 官方提供的一个增删改查的应用，可以在[这里](https://github.com/dvajs/dva/tree/rewrite-dynamic)找到它的源代码。\n\n我们先看该例子的入口文件：\n\n```\nimport dva from 'dva';\nimport createHistory from 'history/createBrowserHistory';\nimport createLoading from 'dva-loading';\nimport { message } from 'antd';\nimport './index.css';\n\nconst ERROR_MSG_DURATION = 3; // 3 秒\n\n// 1. Initialize\nconst app = dva({\n  history: createHistory(),\n  onError(e) {\n    message.error(e.message, ERROR_MSG_DURATION);\n  },\n});\n\n// 2. Plugins\napp.use(createLoading());\n\n// 3. Model\n// Moved to router.js\n// 这里的 Model 被转移到了动态加载的 router 里面，我们也可以如下写：\n// app.model(require('./models/users'));\n\n// 4. Router\napp.router(require('./router'));\n\n// 5. Start\napp.start('#root');\n```\n\n我们发现dva从初始化配置到最后的start(现在的dva start函数在不传入container的情况下可以返回React Component，便于服务端渲染等，但这里我们还是按照例子的写法来)。\n\n这里我们先有必要解释一下，dva 在当前依据能力和依赖版本的不同，有多个可引入的版本，我们的例子和所要分析的源代码都是基于 react-router V4 的 dva 版本。\n\n在源代码中，相关目录主要为 dva 目录(packages/dva) 和 dva-core(packages/dva-core)目录，前者主要拥有history管理、router、动态加载等功能，而后者是不依赖这些内容的基础模块部分，为前者所引用\n\n#### 第一步\n\n第一步这里传入了两个内容：(dva构造函数总共可以传入那些 opts，会在下文中进行说明)\n\n```\nconst app = dva({\n  history: createHistory(),\n  onError(e) {\n    message.error(e.message, ERROR_MSG_DURATION);\n  },\n});\n```\n\n这一步的相关核心代码如下:\n\n```\nexport default function (opts = {}) {\n  const history = opts.history || createHashHistory(); // 默认为 HashHistory\n  const createOpts = {\n    initialReducer: {\n      routing, // 来自 react-router-redux 的 routerReducer\n    },\n    setupMiddlewares(middlewares) {\n      return [\n        routerMiddleware(history), // 来自 react-router-redux 的 routerMiddleware\n        ...middlewares,\n      ];\n    },\n    setupApp(app) {\n      app._history = patchHistory(history); \n    },\n  };\n\n  const app = core.create(opts, createOpts);\n  const oldAppStart = app.start;\n  app.router = router;\n  app.start = start;\n  return app;\n  \n  // 一些用到的函数的定义...\n  \n}  \n```\n\n这里面大多数内容都比较简单，这里面提两个地方：\n\n1. patchHistory：\n\n```\nfunction patchHistory(history) {\n  const oldListen = history.listen;\n  history.listen = (callback) => {\n    callback(history.location);\n    return oldListen.call(history, callback);\n  };\n  return history;\n}\n```\n\n显然，这里的意思是让第一次被绑定 listener 的时候执行一遍 callback，可以用于初始化相关操作。\n\n我们可以在`router.js`中添加如下代码来验证：\n\n```\n  history.listen((location, action)=>{\n    console.log('history listen:', location, action)\n  })\n```\n\n2. 在完成可选项的构造之后，调用了 dva-core 中暴露的 create 函数。\n\ncreate 函数本身也并不复杂，核心代码如下：\n\n```javascript\nexport function create(hooksAndOpts = {}, createOpts = {}) {\n  const {\n    initialReducer,\n    setupApp = noop,\n  } = createOpts;\n\n  const plugin = new Plugin(); // 实例化钩子函数管理类\n  plugin.use(filterHooks(hooksAndOpts)); // 这个时候先对 obj 进行清理，清理出在我们定义的类型之外的 hooks，之后进行统一绑定\n\n  const app = {\n    _models: [\n      prefixNamespace({ ...dvaModel }), // 前缀处理\n    ],\n    _store: null,\n    _plugin: plugin,\n    use: plugin.use.bind(plugin),\n    model, // 下文定义\n    start, // 下文定义\n  };\n  return app;\n \n  //一些函数的定义\n  \n}  \n```\n\n这里面我们可以看到，这里的 `hooksAndOpts` 实际上就是一开始我们构造 dva 的时候传入的 opts 对象经过处理之后的结果。\n\n我们可以传入的可选项，实际上都在 `Plugin.js` 中写明了:\n\n```\nconst hooks = [\n  'onError',\n  'onStateChange',\n  'onAction',\n  'onHmr',\n  'onReducer',\n  'onEffect',\n  'extraReducers',\n  'extraEnhancers',\n];\n```\n\n具体 [hooks的作用可以在这里进行查阅](https://github.com/dvajs/dva/blob/master/docs/API_zh-CN.md#appusehooks)。\n\nPlugin 插件管理类(实际上我认为称其为钩子函数管理类比较合适)除了定义了上文的使用到的use方法(挂载插件)、还有apply方法(执行某一个钩子下挂载的所有回调)、get方法(获取某一个钩子下的所有回调，返回数组)\n\n\n#### 第二步\n\n\n这里的第二步比较简洁：我们知道实际上这里就是使用了`plugin.use`方法挂载了一个插件\n\n```javascript\napp.use(createLoading()); // 需要注意，插件挂载需要在 app.start 之前\n```\n\ncreateLoading 这个插件实际上是官方提供的 Loading 插件，通过这个插件我们可以非常方便地进行 Loading 的管理，无需进行手动管理，我们可以先[看一篇文章](https://www.jianshu.com/p/61fe7a57fad4)来简单了解一下。\n\n这个插件看似神奇，实际上原理也比较简单，主要用了`onEffect`钩子函数(装饰器)：\n\n```javascript\nfunction onEffect(effect, { put }, model, actionType) {\n    const { namespace } = model;\n    if (\n        (only.length === 0 && except.length === 0)\n        || (only.length > 0 && only.indexOf(actionType) !== -1)\n        || (except.length > 0 && except.indexOf(actionType) === -1)\n    ) {\n        return function*(...args) {\n            yield put({ type: SHOW, payload: { namespace, actionType } });\n            yield effect(...args);\n            yield put({ type: HIDE, payload: { namespace, actionType } });\n        };\n    } else {\n        return effect;\n    }\n  }\n```\n\n结合基于的redux-saga，在目标异步调用开始的时候`yield put({ type: SHOW, payload: { namespace, actionType } });`，在异步调用结束的时候`yield put({ type: HIDE, payload: { namespace, actionType } });`，这样就可以管理异步调用开始和结束的Loading状态了。\n\n\n#### 第三步\n\n第三步这里其实省略了，因为使用了动态加载，将 Models 定义的内容和 React Component 进行了动态加载，实际上也可以按照注释的方法来写。\n\n但是没有关系，我们还是可以分析 models 引入的文件中做了哪些事情(下面列出的代码在原基础上进行了一些简化):\n\n```javascript\nimport queryString from 'query-string';\nimport * as usersService from '../services/users';\n\nexport default {\n  namespace: 'users',\n  state: {\n    list: [],\n    total: null,\n    page: null,\n  },\n  reducers: {\n    save(state, { payload: { data: list, total, page } }) {\n      return { ...state, list, total, page };\n    },\n  },\n  effects: {\n    *fetch({ payload: { page = 1 } }, { call, put }) {\n      const { data, headers } = yield call(usersService.fetch, { page });\n      yield put({\n        type: 'save',\n        payload: {\n          data,\n          total: parseInt(headers['x-total-count'], 10),\n          page: parseInt(page, 10),\n        },\n      });\n    },\n    //...\n    *reload(action, { put, select }) {\n      const page = yield select(state => state.users.page);\n      yield put({ type: 'fetch', payload: { page } });\n    },\n  },\n  subscriptions: {\n    setup({ dispatch, history }) {\n      return history.listen(({ pathname, search }) => {\n        const query = queryString.parse(search);\n        if (pathname === '/users') {\n          dispatch({ type: 'fetch', payload: query });\n        }\n      });\n    },\n  },\n};\n```\n\n这些内容，我们通过`app.model(require('./models/users'));`就可以引入。\n\n实际上，model 函数本身还是比较简单的，但由于 dva 拥有 model 动态加载的能力，实际上调用 app.start 前和 app.start 后model函数是不一样的。\n\n调用 start 函数前，我们直接挂载即可(因为start函数中会对所有model进行遍历性统一处理，所以无需过多处理)：\n\n```javascript\nfunction model(m) {\n    if (process.env.NODE_ENV !== 'production') {\n      checkModel(m, app._models);\n    }\n    app._models.push(prefixNamespace(m));\n    // 把 model 注册到 app 的 _models 里面，但是当 app start 之后，就不能仅仅用这种方法了，需要 injectModel\n  }\n```\n\n调用了 start 函数之后，model函数被替换成如下:\n\n```javascript\nfunction injectModel(createReducer, onError, unlisteners, m) {\n    model(m);\n\n    const store = app._store;\n    if (m.reducers) {\n      store.asyncReducers[m.namespace] = getReducer(m.reducers, m.state);\n      store.replaceReducer(createReducer(store.asyncReducers));\n    }\n    if (m.effects) {\n      store.runSaga(app._getSaga(m.effects, m, onError, plugin.get('onEffect')));\n    }\n    if (m.subscriptions) {\n      unlisteners[m.namespace] = runSubscription(m.subscriptions, m, app, onError);\n    }\n  }\n```\n\n**我们首先分析第一个 if 中的内容**：首先通过getReducer函数将转换好的 reducers 挂载(或替换)到 store.asyncReducers[m.namespace] 中，然后通过 redux 本身提供的能力 replaceReducer 完成 reducer 的替换。\n\n这里我们需要注意 getReducer 函数，实际上，dva 里面 reducers 写法和我们之前直接使用 redux 的写法略有不同：\n\n我们这里的 reducers，实际上要和 action 中的 actionType 同名的 reducer，所以这里我们没有必要去写 switch case 了，对于某一个 reducer 来说其行为应该是确定的，这给 reducers 的写法带来了一定的简化，当然，我们可以使用 extraReducers 定义我们之前习惯的那种比较复杂的 reducers。\n\n**接下来我们分析第二个 if 中的内容**：第二个函数首先获取到了我们定义的 effects 并通过 _getSaga 进行处理，然后使用 `runSaga`(实际上就是createSagaMiddleware().run，来自于redux-saga) 进行执行。\n\n实际上，这里的 `_getSaga` 函数比较复杂，我们接下来重点介绍这个函数。\n\n`_getSaga` 函数由 `getSaga.js` 暴露，其定义如下：\n\n```javascript\nexport default function getSaga(resolve, reject, effects, model, onError, onEffect) {\n  return function *() {  // 返回一个函数\n    for (const key in effects) {  // 这个函数对 effects 里面的所有键\n      if (Object.prototype.hasOwnProperty.call(effects, key)) { // 先判断一下键是属于自己的\n        const watcher = getWatcher(resolve, reject, key, effects[key], model, onError, onEffect);\n        // 然后调用getWatch获取watcher\n        const task = yield sagaEffects.fork(watcher); // 利用 fork 开启一个 task\n        yield sagaEffects.fork(function *() { // 这样写的目的是，如果我们移除了这个 model 要及时结束掉\n          yield sagaEffects.take(`${model.namespace}/@@CANCEL_EFFECTS`);\n          yield sagaEffects.cancel(task);\n        });\n      }\n    }\n  };\n}\n```\n\ngetWatcher 的一些核心代码如下:\n\n```javascript\n\nfunction getWatcher(resolve, reject, key, _effect, model, onError, onEffect) {\n  let effect = _effect;\n  let type = 'takeEvery';\n  let ms;\n\n  if (Array.isArray(_effect)) {\n    effect = _effect[0];\n    const opts = _effect[1];\n    // 对 opts 进行一定的校验\n    //...\n  }\n\n  function *sagaWithCatch(...args) { // 都会调用这个过程\n    try {\n      yield sagaEffects.put({ type: `${key}${NAMESPACE_SEP}@@start` });\n      const ret = yield effect(...args.concat(createEffects(model)));\n      yield sagaEffects.put({ type: `${key}${NAMESPACE_SEP}@@end` });\n      resolve(key, ret);\n    } catch (e) {\n      onError(e);\n      if (!e._dontReject) {\n        reject(key, e);\n      }\n    }\n  }\n\n  const sagaWithOnEffect = applyOnEffect(onEffect, sagaWithCatch, model, key); \n  // 挂载 onEffect 钩子\n\n  switch (type) {\n    case 'watcher':\n      return sagaWithCatch;\n    case 'takeLatest':\n      return function*() {\n        yield takeLatest(key, sagaWithOnEffect);\n      };\n    case 'throttle': // 起到节流的效果，在 ms 时间内仅仅会被触发一次\n      return function*() {\n        yield throttle(ms, key, sagaWithOnEffect);\n      };\n    default:\n      return function*() {\n        yield takeEvery(key, sagaWithOnEffect);\n      };\n  }\n}\n```\n\n这个函数的工作，可以主要分为以下三个部分：\n\n1.将 effect 包裹成 sagaWithCatch，除了便于错误处理和增加前后钩子，值得我们注意的是 resolve 和 reject，\n\n这个 resolve 和 reject，实际上是来自`createPromiseMiddleware.js`\n\n我们知道，我们在使用redux-saga的过程中，实际上是监听未来的action，并执行 effects，所以我们在一个 effects 函数中执行一些异步操作，然后 put(dispatch) 一个 action，还是会被监听这个 action 的其他 saga 监听到。\n\n所以就有如下场景：我们 dispatch 一个 action，这个时候如果我们想获取到什么时候监听这个 action 的 saga 中的异步操作执行结束，是办不到的(因为不是所有的时候我们都把所有处理逻辑写在 saga 中)，所以我们的 dispatch 有的时候需要返回一个 Promise 从而我们可以进行异步结束后的回调(这个 Promise 在监听者 saga 异步执行完后被决议，见上文`sagaWithCatch`函数源代码)。\n\n如果我讲的还是比较混乱，也可以参考[这个issue](https://github.com/dvajs/dva/issues/175)\n\n对于这个情况，我认为这是 dva 代码最精彩的地方之一，作者通过定义如下的middleware:\n\n```javascript\n const middleware = () => next => (action) => {\n    const { type } = action;\n    if (isEffect(type)) {\n      return new Promise((resolve, reject) => {\n        map[type] = {\n          resolve: wrapped.bind(null, type, resolve),\n          reject: wrapped.bind(null, type, reject),\n        };\n      });\n    } else {\n      return next(action);\n    }\n  };\n\n  function wrapped(type, fn, args) {\n    if (map[type]) delete map[type];\n    fn(args);\n  }\n\n  function resolve(type, args) {\n    if (map[type]) {\n      map[type].resolve(args);\n    }\n  }\n\n  function reject(type, args) {\n    if (map[type]) {\n      map[type].reject(args);\n    }\n  }\n```\n\n并且在上文的`sagaWithCatch`相关effect执行结束的时候调用 resolve，让 dispatch 返回了一个 Promise。\n\n当然，上面这段代码还是有点问题的，这样会导致同名 reducer 和 effect 不会 fallthrough（即两者都执行），因为都已经返回了，action 便不会再进一步传递，关于这样设计的好坏，在[这里](https://github.com/sorrycc/blog/issues/48)有过一些讨论，笔者不进行展开表述。\n\n2.在上面冗长的第一步之后，又通过`applyOnEffect`函数包裹了`OnEffect`的钩子函数，这相当于是一种`compose`，(上文的 dva-loading 中间件实际上就是在这里被处理的)其实现对于熟悉 redux 的同学来说应该不难理解：\n\n```javascript\nfunction applyOnEffect(fns, effect, model, key) {\n  for (const fn of fns) {\n    effect = fn(effect, sagaEffects, model, key);\n  }\n  return effect;\n}\n```\n\n3.最后，根据我们定义的type(默认是`takeEvery`，也就是都执行)，来选择不同的 saga，takeLatest 即为只是执行最近的一个，throttle则起到节流的效果，一定时间内仅仅允许被触发一次，这些都是 redux-saga 的内部实现，dva 也是基本直接引用，因此在这里不进行展开。\n\n**最后我们分析`injectModel`第三个`if`中的内容**:处理`subscriptions`:\n\n```javascript\nif (m.subscriptions) {\n  unlisteners[m.namespace] = runSubscription(m.subscriptions, m, app, onError);\n}\n```\n\n`subscriptions`可以理解为和这个model有关的全局监听，但是相对独立。这一个步骤首先调用`runSubscription`来一个一个调用我们的`subscriptions`:\n\n```javascript\nexport function run(subs, model, app, onError) { // 在index.js中被重命名为 runSubscription\n  const funcs = [];\n  const nonFuncs = [];\n  for (const key in subs) {\n    if (Object.prototype.hasOwnProperty.call(subs, key)) {\n      const sub = subs[key];\n      const unlistener = sub({\n        dispatch: prefixedDispatch(app._store.dispatch, model),\n        history: app._history,\n      }, onError);\n      if (isFunction(unlistener)) {\n        funcs.push(unlistener);\n      } else {\n        nonFuncs.push(key);\n      }\n    }\n  }\n  return { funcs, nonFuncs };\n}\n```\n\n正如我们所期待的，`run`函数就是一个一个执行`subscriptions`，但是这里有一点需要我们注意的，我们定义的`subscriptions`应该是需要返回一个`unlistener`来返回接触函数，这样当整个 model 被卸载的时候 dva 会自动调用这个接解除函数(也就是为什么这里的返回函数被命名为`unlistener`)\n\n#### 第四步\n\n源代码中的第四步，是对 router 的挂载：\n\n```javascript\napp.router(require('./router'));\n```\n\n`require('./router')`返回的内容在源代码中经过一系列引用传递最后直接被构造成 React Component 并且最终调用 ReactDom.render 进行渲染，这里没有什么好说的，值得一提的就是 router 的动态加载。\n\n动态加载在该样例中是这样使用的：\n\n```javascript\nimport React from 'react';\nimport { Router, Switch, Route } from 'dva/router';\nimport dynamic from 'dva/dynamic';\n\nfunction RouterConfig({ history, app }) {\n  const IndexPage = dynamic({\n    app,\n    component: () => import('./routes/IndexPage'),\n  });\n\n  const Users = dynamic({\n    app,\n    models: () => [\n      import('./models/users'),\n    ],\n    component: () => import('./routes/Users'),\n  });\n\n  history.listen((location, action)=>{\n    console.log('history listen:', location, action)\n  })\n\n  return (\n    <Router history={history}>\n      <Switch>\n        <Route exact path=\"/\" component={IndexPage} />\n        <Route exact path=\"/users\" component={Users} />\n      </Switch>\n    </Router>\n  );\n}\n```\n\n我们可以看出，主要就是利用`dva/dynamic.js`暴露的 dynamic 函数进行动态加载，接下来我们简单看一下 dynamic 函数做了什么:\n\n```javascript\nexport default function dynamic(config) {\n  const { app, models: resolveModels, component: resolveComponent } = config;\n  return asyncComponent({\n    resolve: config.resolve || function () {\n      const models = typeof resolveModels === 'function' ? resolveModels() : [];\n      const component = resolveComponent();\n      return new Promise((resolve) => {\n        Promise.all([...models, component]).then((ret) => {\n          if (!models || !models.length) {\n            return resolve(ret[0]);\n          } else {\n            const len = models.length;\n            ret.slice(0, len).forEach((m) => {\n              m = m.default || m;\n              if (!Array.isArray(m)) {\n                m = [m];\n              }\n              m.map(_ => registerModel(app, _)); // 注册所有的 model\n            });\n            resolve(ret[len]);\n          }\n        });\n      });\n    },\n    ...config,\n  });\n}\n```\n\n这里主要调用了 asyncComponent 函数，接下来我们再看一下这个函数：\n\n```javascript\nfunction asyncComponent(config) {\n  const { resolve } = config;\n\n  return class DynamicComponent extends Component {\n    constructor(...args) {\n      super(...args);\n      this.LoadingComponent =\n        config.LoadingComponent || defaultLoadingComponent;\n      this.state = {\n        AsyncComponent: null,\n      };\n      this.load();\n    }\n\n    componentDidMount() {\n      this.mounted = true;\n    }\n\n    componentWillUnmount() {\n      this.mounted = false;\n    }\n\n    load() {\n      resolve().then((m) => {\n        const AsyncComponent = m.default || m;\n        if (this.mounted) {\n          this.setState({ AsyncComponent });\n        } else {\n          this.state.AsyncComponent = AsyncComponent; // eslint-disable-line\n        }\n      });\n    }\n\n    render() {\n      const { AsyncComponent } = this.state;\n      const { LoadingComponent } = this;\n      if (AsyncComponent) return <AsyncComponent {...this.props} />;\n\n      return <LoadingComponent {...this.props} />;\n    }\n  };\n}\n```\n\n这个函数逻辑比较简洁，我们分析一下动态加载流程；\n\n* 在 constructor 里面调用 `this.load();` ( LoadingComponent 为占位 component)\n* 在 `this.load();` 函数里面调用 `dynamic` 函数返回的 resolve 方法\n* resolve 方法实际上是一个 Promise，把相关 models 和 component 加载完之后 resolve (区分这两个 resolve)\n* 加载完成之后返回 AsyncComponent (即加载的 Component)\n\n动态加载主流程结束，至于动态加载的代码分割工作，可以使用 webpack3 的 `import()` 动态加载能力(例子中也是这样使用的)。\n\n\n#### 第五步\n\n第五步骤就是 start 了：\n\n```javascript\napp.start('#root');\n```\n\n这个时候如果我们在 start 函数中传入 DomElement 或者 DomQueryString，就会直接启动应用了，如果我们这个时候不传入任何内容，实际上返回的是一个`<Provider />` (React Component)，便于服务端渲染。 相关判断逻辑如下：\n\n```javascript\n if (container) {\n      render(container, store, app, app._router);\n      app._plugin.apply('onHmr')(render.bind(null, container, store, app));\n    } else {\n      return getProvider(store, this, this._router);\n    }\n```\n\n至此，主要流程结束，以上几个步骤也包括了 dva 源码做的主要工作。\n\n当然 dva 源码中还有一些比如前缀处理等工作，但是相比于以上内容非常简单，所以在这里不进行分析了。\n\n\n### dva-core 文件目录\n\ndva-core中的源码文件目录以及其功能:\n\n* checkModel 对我们定义的 Model 进行检查是否符合要求\n* constants 非常简单的常量文件，目前只定义了一个常量：NAMESPACE_SEP(/)\n* cratePromiseMiddleware 笔者自己定义的 redux 插件\n* createStore 封装了 redux 原生的 createStore\n* getReducer 这里面的函数其实主要就是调用了 handleActions 文件导出的函数\n* getSaga 将用户输入的 effects 部分的键值对函数进行管理\n* handleActions 是将 dva 风格的 reducer 和 state 转化成 redux 本来接受的那种方式\n* index 主入口文件\n* Plugin 插件类：可以管理不同钩子事件的回调函数，拥有增加、获取、执行钩子函数的功能\n* perfixedDispatch 该文件提供了对 Dispatch 增加前缀的工具性函数 prefixedDispatch\n* prefixNamespace 该文件提供了对 reducer 和 effects 增加前缀的工具性函数 prefixNamespace\n* prefixType 判断是 reducer 还是 effects\n* subscriptions 该文件提供了运行 subscriptions 和调用用户返回的 unlisten 函数以及删除缓存的功能\n* utils 提供一些非常基础的工具函数\n\n\n### 优势总结\n\n* 动态 model，已经封装好了整套调用，动态添加/删除 model 变得非常简单\n* 默认封装好了管理 effects 的方式，有限可选可配置，降低学习成本的同时代码更利于维护\n* 易于上手，集成redux、redux-saga、react-router等常用功能\n\n\n### 劣势总结\n\n* 版本区隔不明显，dva 有 1.x 和 2.x 两种版本，之间API有些差异，但是官网提供的一些样例等中没有说明基于的版本，并且有的还是基于旧版本的，会给新手带来很多疑惑。\n* 内容繁杂，但是却没有一个整合性质的官方网站，大都是通过 list 的形式列下来写在README的。\n* 目前比如动态加载等还存在着一些问题，和直接采用react配套工具写的效果有所区别。\n* 很多 issues 不知道为什么就被关闭了，作者在最后也并未给出合理的解释。\n* dva2 之后有点将 effects 和 actions 混淆，这一点我也并不是非常认同，当然原作者可能有自己的考虑，这里不过多评议。\n\n总之，作为一个个人主力的项目(主要开发者贡献了99%以上的代码)，可以看出作者的功底深厚，经验丰富，但是由于这样一个体系化的东西牵扯内容较多，并且非常受制于react、redux、react-router、redux-saga等的版本影响，**不建议具备一定规模的非阿里系团队在生产环境中使用**，但是如果是快速成型的中小型项目或者个人应用，使用起来还是有很大帮助的。\n\n### TODOS\n\n笔者也在准备做一个和 dva 处于同一性质，但是设计、实现和使用有所区别的框架，希望能够尽快落成。\n","tags":["前端框架"]},{"title":"构建利用Proxy和Reflect实现双向数据绑定的微框架","url":"/2018/04/09/构建利用Proxy和Reflect实现双向数据绑定的微框架/","content":">写在前面：这篇文章讲述了如何利用Proxy和Reflect实现双向数据绑定，个人系Vue早期玩家，写这个小框架的时候也没有参考Vue等源代码，之前了解过其他实现，但没有直接参考其他代码，如有雷同，纯属巧合。\n\n代码下载地址：[这里下载](https://github.com/aircloud/Polar.js)\n\n### 综述\n\n*关于Proxy和Reflect的资料推荐阮老师的教程:http://es6.ruanyifeng.com/ 这里不做过多介绍。*\n\n实现双向数据绑定的方法有很多，也可以参考本专栏之前的其他实现，我之所以选择用Proxy和Reflect，一方面是因为可以大量节约代码，并且简化逻辑，可以让我把更多的经历放在其他内容的构建上面，另外一方面本项目直接基于ES6，用这些内容也符合面向未来的JS编程规范，第三点最后说。\n\n由于这个小框架是自己在PolarBear这个咖啡馆在一个安静的午后开始写成，暂且起名Polar，日后希望我能继续完善这个小框架，给添加上更多有趣的功能。\n\n首先我们可以看整体功能演示：  \n[一个gif动图，如果不能看，请点击[这里的链接](https://www.10000h.top/images/data_img/gif1.gif)]\n\n![](https://www.10000h.top/images/data_img/gif1.gif)\n\n### 代码分析\n\n我们要做这样一个小框架，核心是要监听数据的改变，并且在数据的改变的时候进行一些操作，从而维持数据的一致。\n\n我的思路是这样的：\n\n* 将所有的数据信息放在一个属性对象中(this._data),之后给这个属性对象用Proxy包装set,在代理函数中我们更新属性对象的具体内容，同时通知所有监听者，之后返回新的代理对象(this.data)，我们之后操作的都是新的代理对象。\n* 对于input等表单，我们需要监听input事件，在回调函数中直接设置我们代理好的数据对象，从而触发我们的代理函数。\n* 我们同时也应该支持事件机制，这里我们以最常用的click方法作为例子实现。\n\n下面开始第一部分，我们希望我们之后使用这个库的时候可以这样调用:\n\n```\n<div id=\"app\">\n    <form>\n        <label>name:</label>\n        <input p-model = \"name\" />\n    </form>\n    <div>name:{{name}} age:{{age}}</div>\n    <i>note:{{note}}</i><br/>\n    <button p-click=\"test(2)\">button1</button>\n</div>\n<script>\n var myPolar = new Polar({\n        el:\"#app\",\n        data: {\n            name: \"niexiaotao\",\n            age:16,\n            note:\"Student of Zhejiang University\"\n        },\n        methods:{\n            test:function(e,addNumber){\n                console.log(\"e:\",e);\n                this.data.age+=Number(addNumber);\n            }\n        }\n});\n</script>\n```\n\n没错，和Vue神似吧，所以这种调用方式应当为我们所熟悉。\n\n我们需要建立一个Polar类，这个类的构造函数应该进行一些初始化操作:\n\n```\n constructor(configs){\n        this.root = this.el = document.querySelector(configs.el);\n        this._data = configs.data;\n        this._data.__bindings = {};\n        //创建代理对象\n        this.data = new Proxy(this._data, {set});\n        this.methods = configs.methods;\n\n        this._compile(this.root);\n}\n```\n\n这里面的一部份内容是直接将我们传入的configs按照属性分别赋值，另外就是我们创建代理对象的过程，最后的`_compile`方法可以理解为一个私有的初始化方法。\n\n实际上我把剩下的内容几乎都放在`_compile`方法里面了，这样理解起来方便，但是之后可能要改动。\n\n我们还是先不能看我们代理的set该怎么写，因为这个时候我们还要先继续梳理思路：\n\n假设我们这样`<div>name:{{name}}</div>`将数据绑定到dom节点，这个时候我们需要做什么呢，或者说，我们通过什么方式让dom节点和数据对应起来，随着数据改变而改变。\n\n看上文的`__bindings`。这个对象用来存储所有绑定的dom节点信息，`__bindings`本身是一个对象，每一个有对应dom节点绑定的数据名称都是它的属性，对应一个数组，数组中的每一个内容都是一个绑定信息，这样，我们在自己写的set代理函数中，我们一个个调用过去，就可以更新内容了：\n\n```\ndataSet.__bindings[key].forEach(function(item){\n       //do something to update...\n});\n```\n\n我这里创建了一个用于构造调用的函数，这个函数用于创建存储绑定信息的对象：\n\n```\nfunction Directive(el,polar,attr,elementValue){\n    this.el=el;//元素本身dom节点\n    this.polar = polar;//对应的polar实例\n    this.attr = attr;//元素的被绑定的属性值，比如如果是文本节点就可以是nodeValue\n    this.el[this.attr] = this.elementValue = elementValue;//初始化\n}\n```\n\n这样，我们的set可以这样写:\n\n```\nfunction set(target, key, value, receiver) {\n    const result = Reflect.set(target, key, value, receiver);\n    var dataSet = receiver || target;\n    dataSet.__bindings[key].forEach(function(item){\n        item.el[item.attr] = item.elementValue = value;\n    });\n    return result;\n}\n```\n\n接下来可能还有一个问题：我们的`{{name}}`实际上只是节点的一部分，这并不是节点啊，另外我们是不是还可以这么写：`<div>name:{{name}} age:{{age}}</div>`？\n\n关于这两个问题，前者的答案是我们将`{{name}}`替换成一个文本节点，而为了应对后者的情况，我们需要将两个被绑定数据中间和前后的内容，都变成新的文本节点，然后这些文本节点组成文本节点串。(这里多说一句，html5的normalize方法可以将多个文本节点合并成一个，如果不小心调用了它，那我们的程序就要GG了)\n\n所以我们在`_compile`函数首先：\n\n```\nvar _this = this;\n\n        var nodes = root.children;\n\n        var bindDataTester = new RegExp(\"{{(.*?)}}\",\"ig\");\n\n        for(let i=0;i<nodes.length;i++){\n            var node=nodes[i];\n\n            //如果还有html字节点，则递归\n            if(node.children.length){\n                this._compile(node);\n            }\n\n            var matches = node.innerHTML.match(bindDataTester);\n            if(matches){\n                var newMatches = matches.map(function (item) {\n                    return  item.replace(/{{(.*?)}}/,\"$1\")\n                });\n                var splitTextNodes  = node.innerHTML.split(/{{.*?}}/);\n                node.innerHTML=null;\n                //更新DOM，处理同一个textnode里面多次绑定情况\n                if(splitTextNodes[0]){\n                    node.append(document.createTextNode(splitTextNodes[0]));\n                }\n                for(let ii=0;ii<newMatches.length;ii++){\n                    var el = document.createTextNode('');\n                    node.appendChild(el);\n                    if(splitTextNodes[ii+1]){\n                        node.append(document.createTextNode(splitTextNodes[ii+1]));\n                    }\n                //对数据和dom进行绑定\n                let returnCode = !this._data.__bindings[newMatches[ii]]?\n                    this._data.__bindings[newMatches[ii]] = [new Directive(el,this,\"nodeValue\",this.data[newMatches[ii]])]\n                    :this._data.__bindings[newMatches[ii]].push(new Directive(el,this,\"nodeValue\",this.data[newMatches[ii]]))\n                }\n            }\n\n```\n\n这样，我们的数据绑定阶段就写好了，接下来，我们处理`<input p-model = \"name\" />`这样的情况。\n\n这实际上是一个指令，我们只需要当识别到这一个指令的时候，做一些处理，即可：\n\n```\nif(node.hasAttribute((\"p-model\"))\n                && node.tagName.toLocaleUpperCase()==\"INPUT\" || node.tagName.toLocaleUpperCase()==\"TEXTAREA\"){\n                node.addEventListener(\"input\", (function () {\n\n                    var attributeValue = node.getAttribute(\"p-model\");\n\n                    if(_this._data.__bindings[attributeValue]) _this._data.__bindings[attributeValue].push(new Directive(node,_this,\"value\",_this.data[attributeValue])) ;\n                    else _this._data.__bindings[attributeValue] = [new Directive(node,_this,\"value\",_this.data[attributeValue])];\n\n                    return function (event) {\n                        _this.data[attributeValue]=event.target.value\n                    }\n                })());\n}\n```\n\n请注意，上面调用了一个`IIFE`，实际绑定的函数只有返回的函数那一小部分。\n\n最后我们处理事件的情况：`<button p-click=\"test(2)\">button1</button>`\n\n实际上这比处理`p-model`还简单，但是我们为了支持函数参数的情况，处理了一下传入参数，另外我实际上将`event`始终作为一个参数传递，这也许并不是好的实践，因为使用的时候还要多注意。\n\n```\nif(node.hasAttribute(\"p-click\")) {\n                node.addEventListener(\"click\",function(){\n                    var attributeValue=node.getAttribute(\"p-click\");\n                    var args=/\\(.*\\)/.exec(attributeValue);\n                    //允许参数\n                    if(args) {\n                        args=args[0];\n                        attributeValue=attributeValue.replace(args,\"\");\n                        args=args.replace(/[\\(\\)\\'\\\"]/g,'').split(\",\");\n                    }\n                    else args=[];\n                    return function (event) {\n                        _this.methods[attributeValue].apply(_this,[event,...args]);\n                    }\n                }());\n}\n```\n\n现在我们已经将所有的代码分析完了，是不是很清爽？代码除去注释约100行，所有源代码可以在[这里下载](https://github.com/aircloud/Polar.js)。这当然不能算作一个框架了，不过可以学习学习，这学期有时间的话，还要继续完善，也欢迎大家一起探讨。\n\n一起学习，一起提高，做技术应当是直接的，有问题欢迎指出～\n\n---\n\n\n最后说的第三点：是自己还是一个学生，做这些内容也仅仅是出于兴趣，因为找暑期实习比较艰难，在等待鹅厂面试间隙写的这个程序，压压惊(然而并没有消息)。","tags":["MVVM"]},{"title":"[PWA实践]serviceWorker生命周期、请求代理与通信","url":"/2018/02/11/PWA实践-serviceWorker生命周期、请求代理与通信/","content":"\n本文主要讲 serviceWorker 生命周期和挂载、卸载等问题，适合对 serviceWorker 的作用有所了解但是具体细节不是特别清楚的读者\n\n**以下所有分析基于 Chrome V63**\n\n### serviceWorker的挂载\n\n先来一段代码感受serviceWorker注册:\n\n```\nif ('serviceWorker' in navigator) {\n      window.addEventListener('load', function () {\n          navigator.serviceWorker.register('/sw.js', {scope: '/'})\n              .then(function (registration) {\n                  // 注册成功\n                  console.log('ServiceWorker registration successful with scope: ', registration.scope);\n              })\n              .catch(function (err) {\n                  // 注册失败:(\n                  console.log('ServiceWorker registration failed: ', err);\n              });\n      });\n}\n```\n通过上述代码，我们定义在`/sw.js`里的内容就会生效(对于当前页面之前没有 serviceWorker 的情况而言，我们注册的 serviceWorker 肯定会生效，如果当前页面已经有了我们之前注册的 serviceWorker，这个时候涉及到 serviceWorker的更新机制，下文详述)\n\n如果我们在`sw.js`没有变化的情况下刷新这个页面，每次还是会有注册成功的回调以及相应的log输出，但是这个时候浏览器发现我们的 serviceWorker 并没有发生变化，并不会重置一遍 serviceWorker\n\n### serviceWorker更新\n\n我们如果想更新一个 serviceWorker，根据我们的一般web开发策略，可能会想到以下几种策略：\n\n* 仅变更文件名(比如把`sw.js`变成`sw-v2.js`或者加一个hash)\n* 仅变更文件内容(仅仅更新`sw.js`的内容，文件名不变)\n* 同时变更：同时执行以上两条\n\n在这里，我可以很负责的告诉你，**变更serviceWorker文件名绝对不是一个好的实践**，浏览器判断 serviceWorker 是否相同基本和文件名没有关系，甚至有可能还会造成浏览器抛出404异常(因为找不到原来的文件名对应的文件了)。\n\n所以我们只需要变更内容即可，实际上，我们每次打开或者刷新该页面，浏览器都会重新请求一遍 serviceWorker 的定义文件，如果发现文件内容和之前的不同了，这个时候:\n\n(*下文中，我们使用“有关 tab”来表示受 serviceWorker 控制的页面*，刷新均指普通刷新(F5/CommandR)并不指Hard Reload)\n\n* 这个新的 serviceWorker 就会进入到一个 “waiting to activate” 的状态，并且只要我们不关闭这个网站的所有tab(更准确地说，是这个 serviceWorker 控制的所有页面)，新的 serviceWorker 始终不会进入替换原有的进入到 running 状态(就算我们只打开了一个有关 tab，直接刷新也不会让新的替换旧的)。\n\n* 如果我们多次更新了 serviceWorker 并且没有关闭当前的 tab 页面，那么新的 serviceWorker 就会挤掉原先处于第二顺位(waiting to activate)的serviceWorker，变成`waiting to activate`状态\n\n也就是说，我们只有关闭当前旧的 serviceWorker 控制的所有页面 的所有tab，之后浏览器才会把旧的 serviveWorker 移除掉，换成新的，再打开相应的页面就会使用新的了。\n\n当然，也有一个特殊情况：如果我们在新的 serviceWorker 使用了`self.skipWaiting();`，像这样：\n\n```\nself.addEventListener('install', function(event) {\n    self.skipWaiting();\n});\n```\n\n这个时候，要分为以下两种情况：\n\n* 如果当前我们只打开了一个有关 tab，这个时候，我们直接刷新，发现新的已经替换掉旧的了。\n* 如果我们当前打开了若干有关 tab，这个时候，无论我们刷新多少次，新的也不会替换掉旧的，只有我们一个一个关掉tab(或者跳转走)只剩下最后一个了，这个时候刷新，会让新的替换旧的(也就是上一种情况)\n\nChrome 的这种机制，防止了同一个页面先后被新旧两个不同的 serviceWorker 接管的情况出现。\n\n#### 手动更新\n\n虽然说，在页面每次进入的时候浏览器都会检查一遍 serviceWorker 是否更新，但如果我们想要手动更新 serviceWorker 也没有问题：\n\n```\nnavigator.serviceWorker.register(\"/sw.js\").then(reg => {\n  reg.update();\n  // 或者 一段时间之后更新\n});\n```\n\n这个时候如果 serviceWorker 变化了，那么会重新触发 install 执行一遍 install 的回调函数，如果没有变，就不会触发这个生命周期。\n\n#### install 生命周期钩子\n\n我们一般会在 sw.js 中，添加`install`的回调，一般在回调中，我们会进行缓存处理操作，像这样：\n\n```\nself.addEventListener('install', function(event) {\n    console.log('[sw2] serviceWorker Installed successfully', event)\n\n    event.waitUntil(\n        caches.open('mysite-static-v1').then(function(cache) {\n            return cache.addAll([\n                '/stylesheets/style.css',\n                '/javascripts/common.39c462651d449a73b5bb.js',\n            ]);\n        })\n    )\n}    \n```\n\n如果我们新打开一个页面，如果之前有 serviceWorker，那么会触发`install`，如果之前没有， 那么在 serviceWorker 装载后会触发 `install`。\n\n如果我们刷新页面，serviceWorker 和之前没有变化或者 serviceWorker 已经处在 `waiting to activate`，不会触发`install`，如果有变化，会触发`install`，但不会接管页面(上文中提到)。\n\n#### activate 生命周期钩子\n\nactivate 在什么时候被触发呢？\n\n如果当前页面没有 serviceworker ，那么会在 install 之后触发。\n\n如果当前页面有 serviceWorker，并且有 serviceWorker更新，新的 serviceWorker 只会触发 install ，不会触发 activate\n\n换句话说，当前变成 active 的 serviceWorker 才会被触发这个生命周期钩子\n\n\n### serviceWorker 代理请求\n\nserviceWorker 代理请求相对来说比较好理解，以下是一个很简单的例子：\n\n```\nself.addEventListener('install', function(event) {\n    console.log('[sw2] serviceWorker Installed successfully', event)\n\n    event.waitUntil(\n        caches.open('mysite-static-v1').then(function(cache) {\n            return cache.addAll([\n                '/stylesheets/style.css',\n                '/javascripts/common.39c462651d449a73b5bb.js',\n            ]);\n        })\n    );\n});\n\nself.addEventListener('fetch', function(event) {\n    console.log('Handling fetch event for', event.request.url);\n    // console.log('[sw2]fetch but do nothing')\n\n    event.respondWith(\n        // caches.match() will look for a cache entry in all of the caches available to the service worker.\n        // It's an alternative to first opening a specific named cache and then matching on that.\n        caches.match(event.request).then(function(response) {\n            if (response) {\n                console.log('Found response in cache:', response);\n\n                return response;\n            }\n\n            console.log('No response found in cache. About to fetch from network...');\n\n            // event.request will always have the proper mode set ('cors, 'no-cors', etc.) so we don't\n            // have to hardcode 'no-cors' like we do when fetch()ing in the install handler.\n            return fetch(event.request).then(function(response) {\n                console.log('Response from network is:', response);\n\n                return response;\n            }).catch(function(error) {\n                // This catch() will handle exceptions thrown from the fetch() operation.\n                // Note that a HTTP error response (e.g. 404) will NOT trigger an exception.\n                // It will return a normal response object that has the appropriate error code set.\n                console.error('Fetching failed:', error);\n\n                throw error;\n            });\n        })\n    );\n});\n```\n\n有两点要注意的：\n\n我们如果这样代理了，哪怕没有 cache 命中，实际上也会在控制台写from serviceWorker，而那些真正由serviceWorker发出的请求也会显示，有一个齿轮图标，如下图：\n\n![](https://www.10000h.top/images/sw_1.png)\n\n第二点就是我们如果在 fetch 的 listener 里面 do nothing， 也不会导致这个请求直接假死掉的。\n\n另外，通过上面的代码我们发现，实际上由于现在我们习惯给我们的文件资源加上 hash，所以我们基本上不可能手动输入需要缓存的文件列表，现在大多数情况下，我们都是借助 webpack 插件，完成这部分工作。\n\n### serviceWorker 和 页面之间的通信\n\nserviceWorker向页面发消息：\n\n```\nsw.js:\n\nself.clients.matchAll().then(clients => {\n    clients.forEach(client => {\n        console.log('%c [sw message]', 'color:#00aa00', client)\n        client.postMessage(\"This message is from serviceWorker\")\n    })\n})\n\n主页面:\n\nnavigator.serviceWorker.addEventListener('message', function (event) {\n    console.log('[Main] receive from serviceWorker:', event.data, event)\n});\n```\n\n当然，这里面是有坑的：\n\n* 主界面的事件监听需要等serviceWorker注册完毕后，所以一般`navigator.serviceWorker.register`的回调到来之后再进行注册(或者延迟足够的时间)。\n* 如果在主界面事件监听还没有注册成功的时候 serviceWorker 发送消息，自然是收不到的。如果我们把 serviceWorker 直接写在 install 的回调中，也是不能被正常收到的。\n\n从页面向 serviceWorker 发送消息：\n\n```\n主页面:\n\nnavigator.serviceWorker.controller && navigator.serviceWorker.controller.postMessage('hello serviceWorker');\n\nsw.js:\nself.addEventListener('message', function (event) {\n    console.log(\"[sw from main]\",event.data); // 输出：'sw.updatedone'\n});\n```\n\n同样的，这也要求主界面的代码需要等到serviceWorker注册完毕后触发，另外还有一点值得注意， serviceWorker 的事件绑定代码要求主界面的serviceWorker已经注册完毕后才可以。\n\n也就是说，如果当前页面没有该serviceWorker 第一次注册是不会收到主界面接收到的消息的。\n\n记住，只有当前已经在 active 的 serviceWorker， 才能和主页面收发消息等。\n\n**以上就是和 serviceWorker 有关的一些内容，在下一篇文章中，我会对PWA 添加至主屏幕等功能进行总结**\n\n","tags":["PWA"]},{"title":"CentOS安装node8.x版本","url":"/2017/12/15/CentOS安装node8-x版本/","content":"### CentOS 安装 node 8.x 版本\n\n由于一些原因需要给CentOS服务器安装8.0以上版本的node, 本来直接通过yum管理安装管理，但是没找到好办法，在此记录一下自己最后使用的简单过程：\n\n安装之前删除原来的node和npm (我原来是用yum安装的，如果是第一次安装可以省略这一步):\n\n```\nyum remove nodejs npm -y\n```\n\n首先我们随便进入服务器的一个目录，然后从淘宝的源拉取内容:\n\n```\nwget https://npm.taobao.org/mirrors/node/v8.0.0/node-v8.0.0-linux-x64.tar.xz \n```\n\n解压缩:\n\n```\nsudo tar -xvf node-v8.0.0-linux-x64.tar.xz \n```\n\n进入解压目录下的 bin 目录，执行 ls 命令\n\n```\ncd node-v8.0.0-linux-x64/bin && ls \n```\n\n我们发现有node 和 npm\n\n这个时候我们测试:\n\n```\n./node -v\n```\n\n这个时候我们发现实际上已经安装好了，接下来就是要建立链接文件。\n\n这里还是，如果我们之前已经安装过了，那么我们要先删除之前建立的链接文件：\n\n```\nsudo rm -rf /usr/bin/node\nsudo rm -rf /usr/bin/npm\n```\n\n然后建立链接文件:\n\n```\nsudo ln -s /usr/share/node-v8.0.0-linux-x64/bin/node /usr/bin/node\nsudo ln -s /usr/share/node-v8.0.0-linux-x64/bin/npm /usr/bin/npm\n```\n\n注意这里的第一个路径不要直接复制粘贴，要写当前文件的真正的路径，这个可以通过pwd获取。\n\n然后我们可以通过`node -v`等测试已经安装成功。\n","tags":["centOS","Node.js"]},{"title":"深入浏览器web渲染与优化-续","url":"/2017/08/31/深入浏览器web渲染与优化-续/","content":">本篇文章接上一篇继续分析浏览器web渲染相关内容，但是更侧重优化工作。当然，主要还是基于X5来分析\n\n上一篇文章我们主要是从浏览器内核的线程角度来分析相关工作的，对整体流程没有宏观清晰的分析，这次我们从宏观到微观，从整体到局部，来进行分析和探究可以优化的地方。\n\n首先，一个网页的加载，需要什么工作呢？\n\n![](https://www.10000h.top/images/data_img/webRender2/P1.png)\n\n这个工作可以分为三部分：云(云端)、管(传输链路)、端(客户端)，从云经过管传到端，然后经过加载解析排版渲染，从而完成网页从请求到呈现的工作(当然，我们这里没有涉及协议的分析，实际上根据协议不同，这个传输可能是多次传输)。\n\n数据到端之后，又经过以下过程，才最终显示出来：\n\n![](https://www.10000h.top/images/data_img/webRender2/P2.png)\n\n在这个过程中，我们怎么衡量性能呢？\n\n固然，我们有诸多浏览器提供的API，这些API能让我们获取到较多信息并且记录上报：\n\n![](https://www.10000h.top/images/data_img/webRender2/P3.png)\n\n但是这些具体数值表达的含义有限，并且他们实际上也不等于用户体验。\n\n所以，找到一个科学并且可以检测的标准，并且这个标准可以和用户体验有正相关关系，这个是至关重要的。\n\n目前这个标准是**首屏时间**(就之前自己的了解，具体的还区分首屏展示时间和首屏可交互时间，但是这里讲师不做区分，就下文提供的测算方法而言，显然这里指的是首屏展示时间，*另外，展示后到用户的第一次操作都会有一个至少1s的延时，毕竟用户手指按下的动作是会比较慢的，这个时间js的交互都能完成了，所以首屏展示时间更加重要--from dorsywang*)\n\n那么**首屏时间**怎么测量呢？\n\n**拿摄像机快速拍照测量的**。这个答案可能有些吃惊，但是目前X5内核业务的相关开发人员的确就是采用这种方式测算的，通过高速相机不断拍照，然后辅助图像识别，判断首屏是否已经加载完成，最终再通过人工回归校对。  \n因为如果采用程序检测的话，基本上都会对过程本身造成一定的影响，所以没有采用这种方式。\n当然，通过摄像+图像识别的这种方式也是有一定的弊端，比如说，假设首屏有一个图片，而图片的加载通常比较慢并且不影响css、js的加载，这个时候直接通过图片识别的话就可能会有一定的误判。\n\n知道了怎么测算，那么接下来分析影响这个指标的一些原因：\n\n* 资源阻塞内核线程\n\n我们知道，一般情况下，css和JS是阻塞页面的，当然也会对首屏时间造成影响。\n\n对这个问题，X5内核有关键子资源(阻塞资源)缓存，这里的关键资源，指的是内核经过统计判断得出的业务常用的关键子资源。\n\n当然，这个统计也可能缺乏一定的准确性，所以相关团队也正在推进这方面的内容规范化(比如写入Web App Manifest)\n\n* 中文Layout的时间过长\n\n这个问题我之前没有听说过，但是的确是这样子，实际上，浏览器在绘制文字的时候经历的过程非常的多，其中有一个环节是找到文字的宽度和高度(因为在英文状态下，每一个字符的宽度是不同的，所以每一个字符都要查找，但是英文总共只有26个字符)，而中文由于字符比较多，常用得就有6000多个，完整的更是有2万个以上，所以这个过程需要花费更多的时间。\n\n为了解决这个问题，X5内核考虑到中文文字几乎都是等宽等高的，所以这个过程对一个文字串来说只需要查询一次即可，实际上是节约了这个环节。\n\n* 首次渲染太慢\n\n为了解决这个问题，可以采用先绘制首屏的方式，这个也就是基于第一篇文章中讲到的浏览器的分块渲染机制\n\n* 一次解析内容过多\n\n采用首屏探测机制，优先解析首屏内容。\n\n另外，这里可以前端配合去做首屏优化：\n\n\n在首屏的位置插入首屏标签，内核解析到标签后立即终止解析并且排版上屏\n\n```\n<meta name=‘x5-pagetype’ content=‘optpage'>\n```\n然后在首屏分界的地方：\n\n```\n<first-screen/>\n```\n\n有了这，可以专门去优化首屏标签之前的内容(这个标签前尽量展现耗时少和不需要阻塞解析的资源)。\n\n另外，X5内核也提供了主资源预拉取的接口，并且考虑到预拉取的cookie问题，还提供了preconnect预链接。  \n*TIP:主资源中关联的子资源预拉取不用主动调用*\n\n* 预先操作\n\n另外为了提供更加极致的优化，X5内核(QQ浏览器、手Q Webview)还提供了如下诸多预操作：\n\n* 在\"黏贴并转到\"之前就开始进行网络请求和预渲染\n* 经常访问的站点可以预解析DNS\n* 点击地址栏时进行搜索预连接\n* 点击链接时，先预链接，再做跳转。\n* ......\n\n### 其他方式优化\n\n实际上上文主要讲了客户端方面的优化工作，实际上对于\"云\"、\"管\"两端，还是有很多优化工作可以讲的，但是由于这个和前端关系不是特别密切，我挑一部分讲一讲。这些在我们前端做个人项目的后台时候也可以参考\n\n##### 后台提速\n\n* 直接使用IP，节省dns的查询时间\n* 维持长连接\n* HTTP1.1启用包头节省\n* 服务器缓存\n* 文本资源压缩传输GZIP(6)\n* 图片尺寸压缩、图片质量压缩、支持webp和sharpp/hevc格式。\n\n##### 降低网络时延\n\n* 就快接入和就近接入\n\n在选择接入点的时候，如果采用就近接入，可以保持路由稳定，有利于负载均衡，并且实现简单，便于维护。但是也有一定的缺点：经验判断，准确度不够高 ； 无法自动切换路由。\n\n相比较而言，选择就快接入，是一个能够提效的方式。\n\n##### 内容防劫持\n\n运营商劫持对我们来说已经是不陌生的话题了，但是X5内核有一个比较新的防劫持手段，就是客户端和云加速服务器同时采用轻量级http加密，虽然这种方式普适性不强，但是的确可以解决腾讯自身业务的防劫持问题。\n\n#### QUIC和http2\n\nQUIC 基于UDP的协议通讯方式，有这些优势：\n\n* 延迟少\n* 前向纠错\n* 没有**线头阻塞[注1]**的多路复用\n* 通信通道的定义基于ID而不是IP+端口，使得切换网络后继续转发链接成为可能\n\n——————\n\n注1：线头阻塞：\n\n![](https://www.10000h.top/images/data_img/webRender2/P4.png)\n\n——————\n\n附1: 带宽和延迟对网页加载的影响：\n\n![](https://www.10000h.top/images/data_img/webRender2/X1.png)\n","tags":["性能优化"]},{"title":"深入浏览器web渲染与优化","url":"/2017/08/27/深入浏览器web渲染与优化/","content":">本文主要分析和总结web内核渲染的相关内容，以及在这方面前端可以做的性能优化工作。\n\n文章主要分为以下几个部分：\n\n* blink内核的渲染机制\n* chrome内核架构变迁\n* 分层渲染\n* 动画 & canvas & WebGl\n\n*这里的前两部分可能会有些枯燥，如果是前端工程师并且想立即获得实际项目的建议的，可以直接阅读第三部分和第四部分*\n\n### blink内核的渲染机制\n\nblink内核是Google基于Webkit内核开发的新的分支，而实际上，目前Chrome已经采用了blink内核，所以，我们接下来的有关分析大多基于blink内核的浏览器(Chrome)，就不再详细指明，当然，部分内容也会涉及到腾讯研发的X5内核(X5内核基于安卓的WebView，目前已经在手机QQ等产品中使用，基于X5内核的项目累计有数亿UV，上百亿PV)。\n\n一个页面的显示，实际上主要经历了下面的四个流程：\n\n加载 => 解析 => 排版 => 渲染\n\n实际上，这里的渲染主要是指排版之后到最后的上屏绘制(这个时候内容已经排版好了)，一部分前端工程师通常会把一部分的排版工作理解到“渲染”的流程中(也就是下图中全部工作)，实际上这个理解是不准确的。\n\n![](https://www.10000h.top/images/data_img/webRender/P6.PNG)\n\n目前，浏览器的渲染采用的是分块渲染的机制，所谓的分块渲染的机制，其实应该这么理解：\n\n* 浏览器首先把整个网页分成一些低分辨率的块，再把网页分成高分辨率的块，然后给这些块排列优先级。\n* 处在可视区域内的低分辨率块的优先级会比较高，会被较先绘制。\n* 之后浏览器会把高分辨率的块进行绘制，同样也是先绘制处于可视区域内的，再绘制可视区域外的(由近到远)。\n\n以上讲的这些策略可以使可以使得浏览器优先展示可视区域内的内容，并且先展示大致内容，再展示高精度内容(当然，由于这个过程比较快，实际上我们大多时候是感受不到的)。\n\n另外这里值得提醒的一点是，分块的优先级是会根据到可视区域的距离来决定的，所以有些横着的内容(比如banner的滚动实现，通常会设置横向超出屏幕来表示隐藏)，也是会按照到可视区域的距离来决定优先级的。\n\n绘制的过程，可以被硬件加速，这里硬件加速的主要手段主要是指：\n\n* 硬件加速合成上屏\n* 2D Canvas、Video的硬件加速\n* GPU光栅化\n\t* GPU光栅化速度更快，内存和CPU的消耗更少\n\t* 目前还没有办法对包含复杂矢量绘制的页面进行GPU光栅化\n\t* GPU光栅化是未来趋势\n\n\n### chrome内核架构变迁\n\n在渲染架构上，chrome也是经历了诸多变迁，早期的Chrome是这样的：\n\n![](https://www.10000h.top/images/data_img/webRender/P1.PNG)\n\n早期的chrome的架构实际上有以下缺点：\n\n* Renderer线程任务繁重\n* 无法实时响应缩放滑动操作\n* 脏区域与滑动重绘区域有冲突\n\t* 这里举个场景，假设一个gif，这个时候如果用户滑动，滑动新的需要绘制的内容和gif下一帧内容就会产生绘制冲突\n\n当然，经过一系列的发展，Chrome现在是这样的：\n\n![](https://www.10000h.top/images/data_img/webRender/P2.PNG)\n\n在安卓上，Android 4.4的 Blink内核架构如下(4.4之前并不支持OpenGL)\n\n![](https://www.10000h.top/images/data_img/webRender/P3.PNG)\n\n当然，这种架构也有如下缺点：\n\n* UI线程过于繁忙\n* 无法支持Canvas的硬件加速以及WebGL\n\n所以，后期发展成了这样：\n\n![](https://www.10000h.top/images/data_img/webRender/P4.PNG)\n\n总结看来，内核发展的趋势是：\n\n* 多线程化(可以充分利用多核心CPU)\n* 硬件加速(可以利用GPU)\n\n### 分层渲染\n\n在阅读这一章之前，我建议读者先去亲自体验一下所谓的“分层渲染”：\n\n>打开Chrome浏览器，打开控制台，找到\"Layers\"，如果没有，那么在控制台右上角更多的图标->More tools 找到\"Layers\"，然后随便找个网页打开即可\n\n网页的分层渲染流程主要是下面这样的：\n\n![](https://www.10000h.top/images/data_img/webRender/P7.PNG)\n\n(*注意：多个RenderObject可能又会对应一个或多个RenderLayer*)\n\n既然才用了分层渲染，那么肯定可以来分层处理，分层渲染有如下优点：\n\n* 减少不必要的重新绘制\n* 可以实现较为复杂的动画\n* 能够方便实现复杂的CSS样式\n\n当然，分层渲染是会很影响渲染效率的，可以有好的影响，使用不当也会有差的影响，我们需要合理的控制和使用分层：\n\n* 如果小豆腐块分层较多，页面整体的分层数量较大，会导致每帧渲染时遍历分层和计算分层位置耗时较长啊(比较典型的是腾讯网移动端首页)。\n* 如果可视区域内分层太多且需要绘制的面积太大，渲染性能非常差，甚至无法达到正常显示的地步(比如有一些全屏H5)。\n* 如果页面几乎没有分层，页面变化时候需要重绘的区域较多。元素内容无变化只有位置发生变化的时候，可以利用分层来避免重绘。\n\n那么，是什么原因可以导致分层呢？目前每一个浏览器或者不同版本的浏览器分层策略都是有些不同的(虽然总体差不太多)，但最常见的几个分层原因是：transform、Z-index；还有可以使用硬件加速的video、canvas；fixed元素；混合插件(flash等)。关于其他更具体的内容，可以见下文。\n\n```\n//注:Chrome中符合创建新层的情况：\nLayer has 3D or perspective transform CSS properties(有3D元素的属性)\nLayer is used by <video> element using accelerated video decoding(video标签并使用加速视频解码)\nLayer is used by a <canvas> element with a 3D context or accelerated 2D context(canvas元素并启用3D)\nLayer is used for a composited plugin(插件，比如flash)\nLayer uses a CSS animation for its opacity or uses an animated webkit transform(CSS动画)\nLayer uses accelerated CSS filters(CSS滤镜)\nLayer with a composited descendant has information that needs to be in the composited layer tree, such as a clip or reflection(有一个后代元素是独立的layer)\nLayer has a sibling with a lower z-index which has a compositing layer (in other words the layer is rendered on top of a composited layer)(元素的相邻元素是独立layer)\n```\n\n最后，我们总结一下如何合理的设计分层：分层总的原则是，减少渲染重绘面积与减少分层个数和分层总面积：\n\n* 相对位置会发生变化的元素需要分层(比如banner图、滚动条)\n* 元素内容更新比较频繁的需要分层(比如页面中夹杂的倒计时等)\n* 较长较大的页面注意总的分层个数\n* 避免某一块区域分层过多，面积过大\n\n(*如果你给一个元素添加上了-webkit-transform: translateZ(0);或者 -webkit-transform: translate3d(0,0,0);属性，那么你就等于告诉了浏览器用GPU来渲染该层，与一般的CPU渲染相比，提升了速度和性能。(我很确定这么做会在Chrome中启用了硬件加速，但在其他平台不做保证。就我得到的资料而言，在大多数浏览器比如Firefox、Safari也是适用的)*)\n\n另外值得一提的是，X5对分层方面做了一定的优化工作，当其检测到分层过多可能会出现显示问题的时候会进行层合并，牺牲显示性能换取显示正确性。\n\n最后再提出一个小问题：\n\n以下哪种渲染方式是最优的呢？\n\n![](https://www.10000h.top/images/data_img/webRender/P8.PNG)\n\n这里实际上后者虽然在分层上满足总体原则，但是之前讲到浏览器的分块渲染机制，是按照到可视区域的距离排序的，考虑到这个因素，实际上后者这种方式可能会对分块渲染造成一定的困扰，并且也不是最优的。\n\n### 动画 & canvas & WebGl\n\n讲最后一部分开始，首先抛出一个问题：CSS动画 or JS动画?\n\n对内核来说，实际上就是Renderer线程动画还是Compositor线程动画，二者实际上过程如下：\n\n![](https://www.10000h.top/images/data_img/webRender/P9.PNG)\n\n所以我们可以看出，Renderer线程是比Compositor线程动画性能差的(在中低端尤其明显)\n\n另外，无论是JS动画还是CSS动画，动画过程中的重绘以及样式变化都会拖慢动画执行以及引起卡顿\n以下是一些不会触发重绘或者排版的CSS动画属性：\n\n* cursor\n* font-variant\n* opacity\n* orphans\n* perspective\n* perspecti-origin\n* pointer-events\n* transform\n* transform-style\n* widows\n\n想要了解更多内容，可以参考[这里](https://csstriggers.com/)\n\n这方面最终的建议参考如下：\n\n* 尽量使用不会引起重绘的CSS属性动画，例如transform、opacity等\n* 动画一定要避免触发大量元素重新排版或者大面积重绘\n* 在有动画执行时，避免其他动画不相关因素引起排版和重绘\n\n\n#### requestAnimationFrame\n\n另外当我们在使用动画的时候，为了避免出现掉帧的情况，最好采用requestAnimationFrame这个API，这个API迎合浏览器的流程，并且能够保证在下一帧绘制的时候上一帧一定出现了：\n\n![](https://www.10000h.top/images/data_img/webRender/P11.PNG)\n\n### 3D canvas\n\n还有值得注意的是，有的时候我们需要涉及大量元素的动画(比如雪花飘落、多个不规则图形变化等)，这个时候如果用CSS动画，Animation动画的元素很多。，导致分层个数非常多，浏览器每帧都需要遍历计算所有分层，导致比较耗时、\n\n这个时候该怎么办呢？\n\n2D canvas上场。 \n\n和CSS动画相比，2D canvas的优点是这样的：\n\n* 硬件加速渲染\n* 渲染流程更优\n\n其渲染流程如下：\n\n![](https://www.10000h.top/images/data_img/webRender/P10.PNG)\n\n实际上以上流程比较耗时的是JS Call这一部分，执行opengl的这一部分还是挺快的。\n\nHTML 2D canvas 主要绘制如下三种元素：\n\n* 图片\n* 文字\n* 矢量\n\n这个过程可以采用硬件加速，硬件加速图片绘制的主要流程：\n\n![](https://www.10000h.top/images/data_img/webRender/P12.PNG)\n\n硬件加速文字绘制的主要流程：\n\n![](https://www.10000h.top/images/data_img/webRender/P13.PNG)\n\n但对于矢量绘制而言，简单的图形，比如点、直线等可以直接使用OpenGL渲染，复杂的图形，如曲线等，无法采用OpenGL绘制。\n\n对于绘制效率来说，2D Canvas对绘制图片效率较高，绘制文字和矢量效率较低(**所以建议是，我们如果能使用贴图就尽量使用贴图了**)\n\n还有，有的时候我们需要先绘制到离屏canvas上面，然后再上屏，这个可以充分利用缓存。\n\n### 3D canvas(WebGL)\n\n目前，3D canvas(WebGL)的应用也越来越多，对于这类应用，现在已经有了不少已经成型的庫:\n\n\n* 通用引擎：threeJS、Pixi\n* VR视频的专业引擎：krpano、UtoVR\n* H5游戏引擎：Egret、Layabox、Cocos\n\nWebGL虽然包含Web，但本身对前端的要求最低，但是对OpenGL、数学相关的知识要求较高，所以如果前端工程师没有一定的基础，还是采用现在的流行庫。\n\nX5内核对于WebGl进行了性能上和耗电上的优化，并且也对兼容性错误上报和修复做了一定的工作。\n\n___\n\n本文参考腾讯内部讲座资料整理而成，并融入一部分笔者的补充，谢绝任何形式的转载。\n\n其他优质好文：\n\n[Javascript高性能动画与页面渲染](http://qingbob.com/javascript-high-performance-animation-and-page-rendering/)\n\n\n","tags":["性能优化"]},{"title":"JS的静态作用域、子程序引用环境与参数传递类型","url":"/2017/01/11/JS的静态作用域、子程序引用环境与参数传递类型/","content":"#### 静态作用域\n\n我们先来看下面这个小程序：\n\n```\n //JS版本：\n function sub1() {\n        var x;\n        function sub2() { alert(x); }\n        function sub3() { var x; x=3; sub4(sub2); }\n        function sub4(subx) { var x; x=4; subx(); }\n        x = 1;\n        sub3();\n    }\n\n    sub1();\n    \n #Python版本\ndef sub1():\n    def sub2():\n        print x\n    def sub3():\n        x=3\n        sub4(sub2)\n    def sub4(subx):\n        x=4\n        subx()\n    x = 1\n    sub3()\n\nsub1()   \n```\n\n不用亲自运行，实际上输出结果都是1，这可能不难猜到，但是需要解释一番，鉴于Python和JS在这一点上表现的类似，我就以JS来分析。\n\n我们知道，JS是静态作用域的，所谓静态作用域就是作用域在编译时确定，所以sub2中引用的x，实际上和x=3以及x=4的x没有任何关系，指向第二行的var x;\n\n#### 子程序的引用环境\n\n实际上这里面还有一个子程序(注：子程序和函数不是很一样，但我们可以认为子程序包括函数，也约等于函数)的概念，sub2、sub3、sub4都是子程序，对于允许嵌套子程序的语言，应该如何使用执行传递的子程序的引用环境？\n\n* 浅绑定：如果这样的话，应该输出4，这对动态作用域的语言来说比较自然。\n* 深绑定：也就是输出1的情况，这对静态作用域的语言来说比较自然。\n* Ad hoc binding: 这是第三种，将子程序作为实际参数传递到调用语句的环境。\n\n#### 参数传递类型\n\n参数传递类型我们普遍认为有按值传递和按引用传递两种，实际上不止。\n\n下面是一张图：\n\n![](https://www.10000h.top/images/call.png)\n\n这张图对应的第一种传递方式，叫做Pass-by-Value(In mode)，第二种是Pass-by-Result(Out mode)，第三种是Pass-by-Value-Result(Inout mode),图上说的比较明白，实际上如果有result就是说明最后把结果再赋值给参数。\n\n第二种和第三种编程语言用的少，原因如下：\n>Potential problem: sub(p1, p1)   \nWith the two corresponding formal parameters having different names, whichever formal parameter is copied back last will represent current value of p1\n\n","tags":["javascript"]},{"title":"CentOS7下安装和配置redis","url":"/2016/10/04/CentOS7下安装和配置redis/","content":"Redis是一个高性能的，开源key-value型数据库。是构建高性能，可扩展的Web应用的完美解决方案，可以内存存储亦可持久化存储。因为要使用跨进程，跨服务级别的数据缓存，在对比多个方案后，决定使用Redis。顺便整理下Redis的安装过程，以便查阅。\n\n\n 1 . 下载Redis\n目前，最新的Redist版本为3.0，使用wget下载，命令如下：\n```\n\n# wget http://download.redis.io/releases/redis-3.0.4.tar.gz\n\n```\n 2 . 解压Redis\n下载完成后，使用tar命令解压下载文件：\n```\n\n# tar -xzvf redis-3.0.4.tar.gz\n```\n3 . 编译安装Redis\n切换至程序目录，并执行make命令编译：\n```\n# cd redis-3.0.4\n# make\n```\n执行安装命令\n```\n# make install\n```\nmake install安装完成后，会在/usr/local/bin目录下生成下面几个可执行文件，它们的作用分别是：\n\n* redis-server：Redis服务器端启动程序\n* redis-cli：Redis客户端操作工具。也可以用telnet根据其纯文本协议来操作\n* redis-benchmark：Redis性能测试工具\n* redis-check-aof：数据修复工具\n* redis-check-dump：检查导出工具\n\n备注\n\n有的机器会出现类似以下错误：\n```\nmake[1]: Entering directory `/root/redis/src'\nYou need tcl 8.5 or newer in order to run the Redis test\n……\n```\n这是因为没有安装tcl导致，yum安装即可：\n```\nyum install tcl\n```\n4 . 配置Redis\n复制配置文件到/etc/目录：\n```\n# cp redis.conf /etc/\n```\n为了让Redis后台运行，一般还需要修改redis.conf文件：\n```\nvi /etc/redis.conf\n```\n修改daemonize配置项为yes，使Redis进程在后台运行：\n```\ndaemonize yes\n```\n5 . 启动Redis\n配置完成后，启动Redis：\n```\n# cd /usr/local/bin\n# ./redis-server /etc/redis.conf\n```\n检查启动情况：\n```\n# ps -ef | grep redis\n```\n看到类似下面的一行，表示启动成功：\n```\nroot     18443     1  0 13:05 ?        00:00:00 ./redis-server *:6379 \n```\n6 . 添加开机启动项\n让Redis开机运行可以将其添加到rc.local文件，也可将添加为系统服务service。本文使用rc.local的方式，添加service请参考：Redis 配置为 Service 系统服务 。\n\n为了能让Redis在服务器重启后自动启动，需要将启动命令写入开机启动项：\n```\necho \"/usr/local/bin/redis-server /etc/redis.conf\" >>/etc/rc.local\n```\n7 . Redis配置参数\n在 前面的操作中，我们用到了使Redis进程在后台运行的参数，下面介绍其它一些常用的Redis启动参数：\n```\ndaemonize：是否以后台daemon方式运行\npidfile：pid文件位置\nport：监听的端口号\ntimeout：请求超时时间\nloglevel：log信息级别\nlogfile：log文件位置\ndatabases：开启数据库的数量\nsave * *：保存快照的频率，第一个*表示多长时间，第三个*表示执行多少次写操作。在一定时间内执行一定数量的写操作时，自动保存快照。可设置多个条件。\nrdbcompression：是否使用压缩\ndbfilename：数据快照文件名（只是文件名）\ndir：数据快照的保存目录（仅目录）\nappendonly：是否开启appendonlylog，开启的话每次写操作会记一条log，这会提高数据抗风险能力，但影响效率。\nappendfsync：appendonlylog如何同步到磁盘。三个选项，分别是每次写都强制调用fsync、每秒启用一次fsync、不调用fsync等待系统自己同步\n```\n","tags":["centOS","redis"]},{"title":"腾讯云北美服务器搭建ShadowSocks代理","url":"/2016/08/08/腾讯云北美服务器搭建ShadowSocks代理/","content":"\n注：本教程适合centos系列和red hat系列\n\n登陆SSH \n新的VPS可以先升级\n\n```\nyum -y update\n```\n\n有些VPS 没有wget \n这种要先装\n\n```\nyum -y install wget\n```\n\n输入以下命令：（可以复制）\n\n```\nwget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh\nchmod +x shadowsocks.sh\n./shadowsocks.sh 2>&1 | tee shadowsocks.log\n```\n\n第一行是下载命令，下载东西，第二行是修改权限，第三行是安装命令\n\n下面是按照配置图\n\n```\n配置：\n密码：（默认是teddysun.com）\n端口：默认是8989\n然后按任意键安装，退出按 Ctrl+c\n```\n\n安装完成会有一个配置\n\n```\nCongratulations, shadowsocks install completed!Your Server IP:  ***** VPS的IP地址Your Server Port:  *****  你刚才设置的端口Your Password:  ****  你刚才设置的密码Your Local IP:  127.0.0.1 Your Local Port:  1080 Your Encryption Method:  aes-256-cfb Welcome to visit:https://teddysun.com/342.htmlEnjoy it!\n```\n\n然后即可以使用\n\n卸载方法：\n\n使用 root 用户登录，运行以下命令：\n\n```\n./shadowsocksR.sh uninstall\n```\n\n安装完成后即已后台启动 ShadowsocksR ，运行：\n\n```\n/etc/init.d/shadowsocks status\n```\n","tags":["ShadowSocks"]},{"title":"centOS7.2搭建nginx环境以及负载均衡","url":"/2016/08/03/centOS7-2搭建nginx环境以及负载均衡/","content":" 之所以要整理出这篇文章，是因为1是搭建环境的过程中会遇到大大小小各种问题，2是网上目前也没有关于centos7.2搭建nginx环境的问题整理，因此在这里记录。\n\n前置工作就不赘述了，首先`ssh root@115.29.102.81` (换成你们自己的公网IP)登陆进入到自己的服务器命令行，之后开始基本的安装：\n\n**1.添加资源**\n\n添加CentOS 7 Nginx yum资源库,打开终端,使用以下命令(没有换行):\n\n```\nsudo rpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm\n\n```\n\n**2.安装Nginx**\n\n在你的CentOS 7 服务器中使用yum命令从Nginx源服务器中获取来安装Nginx：\n>*这里有一个需要注意的地方，尽量不要用网上的下载源码包然后再传到服务器上的方式进行安装，因为nginx已经不算是简单的Linux了，做了很多扩展，这个时候如果你用源码包安装会出现各种各样的问题，尽量用已经封装好的rpm\\yum进行安装*\n```\nsudo yum install -y nginx\n```\nNginx将完成安装在你的CentOS 7 服务器中。\n\n**3.启动Nginx**\n\n刚安装的Nginx不会自行启动。运行Nginx:\n```\nsudo systemctl start nginx.service\n```\n如果一切进展顺利的话，现在你可以通过你的域名或IP来访问你的Web页面来预览一下Nginx的默认页面\n\n>当然，这里一般很可能会无法访问的。\n\n我们先不急于解决我们的问题，先看看nginx的基本配置：\n\n\nNginx配置信息\n```\n网站文件存放默认目录\n\n/usr/share/nginx/html\n网站默认站点配置\n\n/etc/nginx/conf.d/default.conf\n自定义Nginx站点配置文件存放目录,自己在这里也可以定义别的名字的.conf，这个的作用以后再说。\n\n/etc/nginx/conf.d/\nNginx全局配置\n\n/etc/nginx/nginx.conf\n在这里你可以改变设置用户运行Nginx守护程序进程一样,和工作进程的数量得到了Nginx正在运行,等等。\n```\nLinux查看公网IP\n\n您可以运行以下命令来显示你的服务器的公共IP地址:(这个其实没用，不是公网IP)\n```\nip addr show eth0 | grep inet | awk '{ print $2; }' | sed 's/\\/.*$//'\n```\n___\n好了，这个时候我们再来看看可能遇到的问题：无法在公网访问。\n\n这个时候首先看看配置文件default.conf对不对，一个正确的例子：\n(域名要先进行解析到响应的IP)\n```\nserver {\n    listen       80;\n    server_name  nginx.310058.cn;\n\n    #charset koi8-r;\n    #access_log  /var/log/nginx/log/host.access.log  main;\n\n    location / {\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n    }\n\n    #error_page  404              /404.html;\n\n    # redirect server error pages to the static page /50x.html\n    #\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n\n    # proxy the PHP scripts to Apache listening on 127.0.0.1:80\n    #\n    #location ~ \\.php$ {\n    #    proxy_pass   http://127.0.0.1;\n    #}\n\n    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000\n    #\n    #location ~ \\.php$ {\n    #    root           html;\n    #    fastcgi_pass   127.0.0.1:9000;\n    #    fastcgi_index  index.php;\n    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;\n    #    include        fastcgi_params;\n    #}\n\n    # deny access to .htaccess files, if Apache's document root\n    # concurs with nginx's one\n    #\n    #location ~ /\\.ht {\n    #    deny  all;\n    #}\n}\n```\n\n确定文件没问题了，看看这个时候是不是开启了nginx进程：\n\n```\n ps -ef | grep nginx\n```\n\n应该会输出一个或者多个进程，如果没有的话就开启或者重启试试看。\n\n这个时候接下来再试试在服务器上：\n```\nping  115.29.102.81\ntelnet 115.29.102.81 80\nwget nginx.310058.cn\n```\n如果有的命令没有就直接yum安装下:\n```\nyum -y install telnet\n```\n如果都可以的话，之后在本机尝试以上三行。如果没有命令也要安装下：\n```\nbrew install wget\n```\n\n发现很可能本机telnet不通，而服务器telnet通。\n这个时候就是**防火墙**的问题。\n\n####centos7.2防火墙\n\n由于centos 7版本以后默认使用firewalld后，网上关于iptables的设置方法已经不管用了，所以根本就别想用配置iptables做啥，根本没用。\n\n查看下防火墙状态：\n```\n[root@iZ28dcsp7egZ conf.d]# systemctl status firewalld  \n● firewalld.service - firewalld - dynamic firewall daemon\n   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled)\n   Active: active (running) since Wed 2016-08-03 12:06:44 CST; 2h 49min ago\n Main PID: 424 (firewalld)\n   CGroup: /system.slice/firewalld.service\n           └─424 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid\n\nAug 03 12:06:41 iZ28dcsp7egZ systemd[1]: Starting firewalld - dynamic firewall daemon...\nAug 03 12:06:44 iZ28dcsp7egZ systemd[1]: Started firewalld - dynamic firewall daemon.\n```\n\n增加80端口的权限：\n```\nfirewall-cmd --zone=public --add-port=80/tcp --permanent  \n```\n \n 别忘了更新防火墙的配置：\n```\nfirewall-cmd --reload\n```\n这个时候再`restart  nginx.service` 一下就会发现应该好了。\n\n\nnginx 停止：\n\n```\nservice nginx restart\n也可以重启nginx\n\nkill -QUIT 进程号  \n#从容停止\n\nkill -TERM 进程号\n#或者\nkill -INT 进程号\n#快速停止\n\np-kill -9 nginx\n强制停止\n\nnginx -t \n#验证配置文件 前提是进入相应的配置的目录（自己实际测试的时候发现没有进入相应的配置目录也是可以的）\n\nnginx -s reload\n#重启\n\nkill -HUP 进程号\n#重启的另外一种方式\n```\n\n官方文档地址：\nhttps://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Security_Guide/sec-Using_Firewalls.html#sec-Introduction_to_firewalld\n\n附1:一个简单的负载均衡的实现:\nweight默认是1，自己也可以更改。\n```\nupstream mypro {\n\t\t\t\tip_hash;\n                server 111.13.100.92 weight=2;\n                server 183.232.41.1;\n                server 42.156.140.7;\n                }\n\n        server {\n                listen 8090;\n                location / {\n                proxy_pass http://mypro;\n                }\n        }\n\n```\n\n\n附2:防火墙基本学习：\n\n``` \n\n1、firewalld简介\nfirewalld是centos7的一大特性，最大的好处有两个：支持动态更新，不用重启服务；第二个就是加入了防火墙的“zone”概念\n \nfirewalld有图形界面和工具界面，由于我在服务器上使用，图形界面请参照官方文档，本文以字符界面做介绍\n \nfirewalld的字符界面管理工具是 firewall-cmd \n \nfirewalld默认配置文件有两个：/usr/lib/firewalld/ （系统配置，尽量不要修改）和 /etc/firewalld/ （用户配置地址）\n \nzone概念：\n硬件防火墙默认一般有三个区，firewalld引入这一概念系统默认存在以下区域（根据文档自己理解，如果有误请指正）：\ndrop：默认丢弃所有包\nblock：拒绝所有外部连接，允许内部发起的连接\npublic：指定外部连接可以进入\nexternal：这个不太明白，功能上和上面相同，允许指定的外部连接\ndmz：和硬件防火墙一样，受限制的公共连接可以进入\nwork：工作区，概念和workgoup一样，也是指定的外部连接允许\nhome：类似家庭组\ninternal：信任所有连接\n对防火墙不算太熟悉，还没想明白public、external、dmz、work、home从功能上都需要自定义允许连接，具体使用上的区别还需高人指点\n \n2、安装firewalld\nroot执行 # yum install firewalld firewall-config\n \n3、运行、停止、禁用firewalld\n启动：# systemctl start  firewalld\n查看状态：# systemctl status firewalld 或者 firewall-cmd --state\n停止：# systemctl disable firewalld\n禁用：# systemctl stop firewalld\n \n4、配置firewalld\n查看版本：$ firewall-cmd --version\n查看帮助：$ firewall-cmd --help\n查看设置：\n                显示状态：$ firewall-cmd --state\n                查看区域信息: $ firewall-cmd --get-active-zones\n                查看指定接口所属区域：$ firewall-cmd --get-zone-of-interface=eth0\n拒绝所有包：# firewall-cmd --panic-on\n取消拒绝状态：# firewall-cmd --panic-off\n查看是否拒绝：$ firewall-cmd --query-panic\n \n更新防火墙规则：# firewall-cmd --reload\n                            # firewall-cmd --complete-reload\n    两者的区别就是第一个无需断开连接，就是firewalld特性之一动态添加规则，第二个需要断开连接，类似重启服务\n \n将接口添加到区域，默认接口都在public\n# firewall-cmd --zone=public --add-interface=eth0\n永久生效再加上 --permanent 然后reload防火墙\n \n设置默认接口区域\n# firewall-cmd --set-default-zone=public\n立即生效无需重启\n \n打开端口（貌似这个才最常用）\n查看所有打开的端口：\n# firewall-cmd --zone=dmz --list-ports\n加入一个端口到区域：\n# firewall-cmd --zone=dmz --add-port=8080/tcp\n若要永久生效方法同上\n \n打开一个服务，类似于将端口可视化，服务需要在配置文件中添加，/etc/firewalld 目录下有services文件夹，这个不详细说了，详情参考文档\n# firewall-cmd --zone=work --add-service=smtp\n \n移除服务\n# firewall-cmd --zone=work --remove-service=smtp\n \n还有端口转发功能、自定义复杂规则功能、lockdown，由于还没用到，以后再学习\n\n```\n","tags":["centOS","nginx"]}]